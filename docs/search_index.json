[
["index.html", "Mathematical Demography Chapter 1 Introduction", " Mathematical Demography Josh R. Goldstein 2020-12-23 Chapter 1 Introduction Mathematical demography book transcribed and coded from class notes by Andrea Miranda-González (andrea.mirgon@berkeley.edu) and Felipe Menares (fmenares@berkeley.edu). Special thank you to the Spring 2020 Mathematical Demography students for the problem set answers. "],
["intro.html", "Chapter 2 Introduction to Demographic Heterogeneity 2.1 Outline 2.2 Part I. Conceptual Introduction 2.3 Part II. Formal Analysis 2.4 Conclusions 2.5 Questions 2.6 Solutions", " Chapter 2 Introduction to Demographic Heterogeneity 2.1 Outline What demographic heterogeneity is (and isn’t) Dynamics of population growth with two sub-groups Keyfitz’s result \\(\\bar{r}&#39;(t) = \\sigma^2_r(t)\\). Ken’s model of Poisson heterogeneity 2.2 Part I. Conceptual Introduction 2.2.1 What is Demographic Heterogeneity? If we see different outcomes (e.g., people dying at different ages), is this Demographic Heterogeneity? NO. Demographic heterogeneity \\(=\\) different rates for different folks. In a demographically heterogeneous population, people are of different types, with different type-specific rates. (These types can be discrete, with individuals being homogeneous within their type, or they can be continuous with possibly no individual having exactly the same risk as another.) 2.2.1.1 An example Let’s draw 10 individuals from a homogeneous population and heterogeneous population. ## Homogeneous hazard of 1/10 set.seed(13) x.homo &lt;- rexp(10, rate = 1/10) ## Heterogeneous hazard (half 1/6 and half 1/13) ## Note: I didn&#39;t pick these particular numbers for any specific reason x.hetero &lt;- c(rexp(5, rate = 1/6), rexp(5, rate = 1/13)) par(mfrow = c(1,2)) dotchart(x.homo, main = &quot;homogenous variation&quot;) dotchart(x.hetero, main = &quot;heterogeneous variation&quot;) Figure 2.1: Homogeneity and Heterogeneity Can you tell which is which? Homogeneous: Chance only Heterogeneous: Chance + group variation in risk Would we expect to see a difference if we increased sample? A good question. We suspect that with a large enough sample we might be able to tell the difference between a mixture of two types and a single type. We can try a sample of, say, 1 million, and see if we can tell which is which. ## Homogeneous hazard of 1/10 set.seed(13) n = 10^6 x.homo &lt;- rexp(n, rate = 1/10) ## Heterogeneous hazard (half 1/6 and half 1/13) ## Note: I didn&#39;t pick these particular numbers for any specific reason x.hetero &lt;- c(rexp(n/2, rate = 1/6), rexp(n/2, rate = 1/13)) ## Look at histograms par(mfrow = c(1,2)) hist(x.homo, main = &quot;homogenous variation&quot;) hist(x.hetero, main = &quot;heterogeneous variation&quot;) Figure 2.2: Homogeneity and Heterogeneity (N = 1 million) ## we don&#39;t see much at this resolution ## To see in log scale, try par(mfrow = c(1,2)) out.hom = hist(x.homo, breaks = 100) out.het = hist(x.hetero, breaks = 100) Figure 2.3: Homogeneity and Heterogeneity (N = 1 million) plot(out.het$breaks[-1], out.het$counts, log = &#39;y&#39;) ## Warning in xy.coords(x, y, xlabel, ylabel, log): 8 y values &lt;= 0 omitted from logarithmic ## plot plot(out.hom$breaks[-1], out.hom$counts, log = &#39;y&#39;) ## Warning in xy.coords(x, y, xlabel, ylabel, log): 10 y values &lt;= 0 omitted from logarithmic ## plot Figure 2.4: Homogeneity and Heterogeneity (N = 1 million) ## And now we can see a bit of curvature in the heterogeneous case. ## So our conclusion is that it can be possible to detect the difference but it is not easy or sure. 2.2.2 Analogies Social inequality: equal opportunity vs. equal outcomes Analysis of variance: \\(\\mbox{total variance} = \\mbox{within group} + \\mbox{between group}\\) Statistical models \\(y = a + b x + \\epsilon\\) 2.2.3 What’s new? Dynamics. Heterogeneous populations evolve differently. Aggregates \\(\\neq\\) Individuals Rates of growth (or decline) Changes over time or age or duration The trajectory of even the individual differs from population average Relative positions, change of groups, may be misleading. Terminology Heterogeneity Unobserved heterogeneity Selection Selective survival Big Caveat: Fundamental Unidentifiability Same data of \\(N\\) observations \\(N\\) draws from 1 distribution \\(1\\) draw from \\(N\\) distributions Something in-between Abel (66) and Beth (76) example. 2.2.3.1 A 2nd example: Exponential growth, two countries Two countries start equal size, but grow at different rates. What happens to aggregate growth rate? rA = .03 ## growth rate of A rB = .01 ## growth rate of A KA = 100 ## starting pop size KB = 100 t = 0:200 KA.t = KA*exp(rA*t) ## exp growth of A KB.t = KB*exp(rB*t) ## exp growth of B K &lt;- KA.t + KB.t ## combined pop r.bar = diff(log(K)) ## growth rate plot(t[-1], r.bar, type = &quot;l&quot;, ylim = c(0, 0.04), ylab = &quot;r.bar&quot;, xlab = &quot;time&quot;) abline(h = c(rA, rB), lty = 2) Figure 2.5: Aggregate growth rate of sub-populations A + B Questions What determines growth rate? How does it change over time? Does the process converge? 2.2.3.2 More examples to work Differential, constant mortality (\\(\\mu_A = .03\\); \\(\\mu_B =.01\\)) Differential, time-varying mortality or growth. ``Movers and Stayers’’ (Migration) ``Movers and Stayers’’ (Marriage) Fecundity: aging or heterogeneity? Divorce: duration or heterogeneity? Duration of unemployment: duration or heterogeneity? Recidivism by time out of prison 2.2.4 Application Can you create a plateau? Can you create a crossover? Can you get aggregate rate to decline? Anything else? 2.3 Part II. Formal Analysis 2.3.1 Outline Keyfitz result Keyfitz USA-Mexico example Ken’s Poisson-Exponential Model 2.3.2 Keyfitz result \\[{d \\over dt}\\bar{r}(t) = \\sigma^2_r(t)\\] When group-specific growth rates are constant the rate of change of the aggregate growth rate equals the variance of the growth rates. Derivation By definition, \\[ \\bar{K}(t) = \\sum_i K_i(t) = \\sum_i K_i e^{r_i t} \\] and \\[\\bar{r}(t) = {{d \\over dt} \\bar{K}(t) \\over \\bar{K}(t)}\\] Let’s take derivatives and simplify, recalling definition of variance. SOLVE? 2.3.3 US-Mexico Example rm = 3.5/100 ru = .75/100 Km = 50 Ku = 100 t &lt;- -50:150 ## go back in time to see rise and fall of variance Kt = Km * exp(t*rm) + Ku * exp(t*ru) bar.rt &lt;- diff(log(Kt)) par(mfrow = c(2,2)) plot(t, Kt, lwd = 2, type = &#39;l&#39;) title(&#39;Total pop size (solid)\\n Group m (dashed)&#39;) lines(t, Km * exp(t*rm), lty = 2, col = &quot;red&quot;) lines(t, Ku * exp(t*ru), lty = 2, col = &quot;blue&quot;) my.v = 26 abline(v = my.v) plot(t, Kt, lwd = 2, type = &#39;l&#39;, log = &#39;y&#39;, ylim = c(.5, max(Kt))) lines(t, Km * exp(t*rm), lty = 2, col = &quot;red&quot;) lines(t, Ku * exp(t*ru), lty = 2, col = &quot;blue&quot;) abline(v = my.v) title(&quot;Total pop size (solid)\\n Group &#39;m&#39; (dashed): Log-scale&quot;) plot(t[-1], bar.rt, type = &#39;l&#39;, main = &#39;Aggregate growth rate&#39;) plot(t[-(1:2)], diff(bar.rt), type = &#39;l&#39;, main = &#39;Change in aggregate growth rate&#39;) Figure 2.6: Keyfitz result for US-Mexico 2.3.3.1 Commentary on Keyfitz result Growth rates in heterogeneous populations start at pop average and then increase. Heterogeneity pop growth We will extend to cover non-constant growth But Doesn’t tell us how much bigger \\(\\bar{K}(t)\\) is projection using constant aggregate rate \\(\\bar{r}(0)\\). Doesn’t give us a formula for time path of aggregate \\(\\bar{K}(t)\\) or \\(\\bar{r}(t)\\) Note: our homework will try to address some of this using Taylor approximation. 2.3.4 The Origin of Professor Wachter’s Poisson-Exponential Model Given a world with many sub-populations, each growing expontentially at their own rate, what can we say about the time-path of world population growth? From an email: Josh asks: Suppose we have a discrete mix of subpopulations growing at different intrinsic rates r whose maximum is r0. Is there a handy approximation for the growth path of the aggregate populations? The assumption of a discrete mix is essential here. Otherwise Tauberian theorems apply and, with a vanishingly small portion of the population close to the maximum growth rate, we do not obtain long-run exponential growth. I recommend modeling the discrete distribution of growth rates as a mixture of Poisson distributions. We are considering \\[\\begin{equation} \\label{mixture} \\bar{K}(t) = \\sum_i e^{r_i t} K_i(0). \\end{equation}\\] Ken suggests \\[\\begin{equation} \\label{ri_def} r_i = r_0 - s(\\lambda) \\cdot a, \\end{equation}\\] \\(r_0\\) growth rate of the fastest growing sub-population \\(s\\) a non-negative Poisson distributed integer \\(\\lambda\\) the parameter of the Poisson distribution (also it’s mean and variance) \\(a\\) gap between adjacent growth rates. Example: sub-populations have growth rates 3, 2, 1, 0, -1, \\(\\ldots\\) percent, then \\(r_0 = 0.03\\) and \\(a = 0.01\\). Sizes of sub-pops determined by Poisson dis’n 2.3.4.1 Closed-form result \\[ K(t) = K(0) e^{r_0 t} e^{-\\lambda (1 - e^{-at})}. \\] To derive: Write out mixture to get \\[ K(t) = K(0) e^{r_0 t} \\sum_i e^{-sat} f(s) \\] Substitute for \\(f(s)\\): \\(Pois ~ {\\lambda^s e^{-\\lambda} \\over s!}\\) Recognize that our mixture contains the series representation of \\(e^{-at}\\) Interpretation \\[ K(t) = K(0) e^{r_0 t} e^{-\\lambda (1 - e^{-at})}. \\] Dominant term contains the maximum population growth rate \\(r_0\\), Second term gives the diminishing effect of the sub-populations with smaller population growth rates over time. Some further analysis, What is the closed-form expression for \\(\\bar{r}(t)\\)? 2.3.5 Some commentary Poisson and Exponential “fit” We’ll this complementarity again (e.g., with Gamma) Tractable models are super powerful for enhancing our understanding. But be careful. Avoid extremes: the model is right/wrong. A BIG caveat, are disaggregated models necessarily better? Some potential problems: Aggregate constraints? Interacting sub-populations? Illusion of precision? 2.4 Conclusions Heterogeneity as variation in risk (not just outcome) Constantly growing parts \\(\\neq\\) constantly growth whole Keyfitz result: Change in growth rate \\(=\\) variance of growth rates Poisson growth gives us a closed-form solution. 2.5 Questions True or False? “If every part grows exponentially at its own rate, then the whole will also grow exponentially.” Explain your answer briefly. List what you think are two of the best arguments in favor of doing a disaggregated projection? What are two of the best arguments in favor of doing an aggregated projection? Let there be two countries: USA (\\(u\\)) and Mexico (\\(m\\)). Assume that in 1970, their population size (in millions) is \\(K_u(1970) = 200\\), \\(K_m(1970) = 50\\) and that their growth rates are \\(r_u = .0075\\) and \\(r_m = 0.035\\), respectively. Project the first few years and verify that the rate of change in the aggregate growth rate equals the variance of the growth rate. Does it matter what time points and period you consider? Using the information from question 3, notice that the growth rate changes over the course of the 50 years, but there is a constant growth rate that will produce the exact same population after 50 years. A reasonable choice of the constant growth rate to apply is the value of the changing growth rate at year 25 (half-way through the period). We can estimate this using a Taylor series approximation: \\[ \\bar{r}(25) \\approx \\bar{r}(0) + 25\\bar{r}&#39;(0) + (25)^2 \\bar{r}&#39;&#39;(0) \\] Show that \\(\\bar{r}&#39;&#39;(t) = \\bar{r}_3(t) - \\bar{r}_2(t) \\bar{r}(t) - 2 \\bar{r}(t) \\sigma^2_r(t)\\) \\ Calculate the combined US-Mexico population after 50 years according to the following five (5) methods, plot the total population after 50 years according to these 5 methods on a graph. Dissaggregated (“true”) forecast, with each country growing at its own rate Aggregated forecast, pretending it’s one country, growing at \\(\\bar{r}(0)\\)) for 50 years Aggregated forecast, growing at the “true” value of \\(\\bar{r}(25)\\) for the whole period. (Use the value of \\(\\bar{r}(25)\\)) that you calculate from the disaggregated forecast) Aggregated forecast, growing at the first-order Taylor series estimate of \\(\\bar{r}(25)\\) for the whole period Aggregated forecast, growing at the second-order Taylor series estimate of \\(\\bar{r}(25)\\) for the whole period For Ken’s Poisson-Exponential model, What is the closed-form expression for \\(\\hat{r}(t)\\) What is the variance of the growth rate? Write down an expression for the distortion index. What variables and parameters in the model does it depend on? Are there any variables or parameters that it doesn’t depend on? (difference of \\(\\bar{r}(t)\\) and \\(\\bar{r}(0)\\)) 2.6 Solutions True or False? “If every part grows exponentially at its own rate, then the whole will also grow exponentially.” Explain your answer briefly. False. From Keyfitz we know that the average growth rate of a heterogeneous population is: \\[\\bar{r}(t)=\\frac{\\sum_i{Q_i}{r_i}e^{r_i{t}}}{\\sum_i{Q_i}e^{r_i{t}}}\\] Here, \\(\\bar{r}(t)\\) is not constant for all t as there is a compositional effect. This should be read as “If every part grows at a constant exponential rate, then the whole will also grow exponentially”. We could argue that only in the long term it is true. List what you think are two of the best arguments in favor of doing a disaggregated projection? What are two of the best arguments in favor of doing an aggregated projection? Disaggregated projections: Reveal the “true” path, patterns of individuals different from that of the aggregate. Take into account size of each sub-population, in particular the smaller ones. Are more precise. Growth rates for sub-populations reflect their intrinsic characteristics, such that projections that do not use appropriate rates can lead to adverse social/policy implications. Aggregated projections: May used if a population is homogeneous rather than projecting many models for sub-populations. Provide a straightforward method of obtaining overall rates rather than the group-specific rates. Are easier to implement as more data available. There are two countries, \\(u\\) and \\(m\\), each with growth rates \\(r_u = .0075\\), \\(r_m = 0.035\\), and population sizes in 1970 of \\(K_u(1970) = 200\\), \\(K_m(1970) = 50\\). Use the first few years of the projection to verify that rate of change in the aggregate growth rate equals the variance of the growth rate. Does it matter what time points and period you consider? From the information given, we can obtain \\(\\bar{r}(t)\\) and \\(\\sigma_r^2(t)\\) by projecting each country’s population using individual rates and then obtaining the total population, \\[\\bar{K}(t)= \\sum_{i\\in\\{u,m\\}}K_{i}(t) = \\sum_{i\\in\\{u,m\\}}K_{i}e^{r_{i} t}\\] Applying the formula for aggregate growth rate to the USA-Mexico case we get: \\[\\begin{aligned} \\bar{r}(t) &amp; = \\frac{\\frac{d}{dt}\\bar{K}(t)}{\\bar{K}(t)}\\\\ &amp; = \\frac{K_u(0) r_u(t) e^{r_u(t) t} + K_m(0) r_m(t) e^{r_m(t) t}}{K_u(0) e^{r_u(t) t} + K_m(0) e^{r_m (t) t}} \\end{aligned}\\] For simplicity, time 0 is the year 1970 such that the proyection goes from 1971 (t=1) until 2020 (t=50). Then, we can calculate the variance of the growth rates as: \\[\\begin{aligned} \\sigma_r^2(t) &amp;= \\frac{{K_u(0) e^{r_u(t) t}(r_u(t) - \\bar{r}(t))^2 + K_m(0) e^{r_m(t) t}(r_m(t) - \\bar{r}(t))^2}} { {K_u(0) e^{r_u(t) t} + K_m(0) e^{r_m(t) t}}} \\\\ &amp;= \\frac{K_u(t) r_u(t)^2 + K_m(t) r_u(t)^2}{K_u(t)+K_m(t)}-\\bar{r}(t)^2 \\end{aligned}\\] The table below show these results for projections at the beginning and ending of a 50 year period. Overall, the time points do not matter and we can verify that \\(\\frac{d\\bar{r}(t)}{d(t)}=\\sigma_r^2(t)\\) \\(t\\) \\(\\sigma^2_r(t)\\) \\(K_u(t)\\) \\(K_m(t)\\) \\(\\bar{K}(t)\\) \\(\\bar{K}(t)-\\bar{K}(t-1)\\) \\(\\bar{r}(t)\\) \\(\\bar{r}&#39;(t)\\) 0 0.00021 200 50 250 l 0.000123 201.506 51.781 253.287 3.2866 0.0131 2 0.000125 203.023 53.625 256.648 3.3614 0.0132 0.0001 3 0.000127 204.551 55.536 260.087 3.4385 0.0133 0.0001 \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) 49 0.000189 288.824 277.833 566.658 50 0.000189 290.998 287.730 578.728 12.071 0.0211 51 0.000189 293.189 297.979 591.168 12.440 0.0213 0.0002 Using the information from question 3, notice that the growth rate changes over the course of the 50 years, but there is a constant growth rate that will produce the exact same population after 50 years. A reasonable choice of the constant growth rate to apply is the value of the changing growth rate at year 25 (half-way through the period). We can estimate this using a Taylor series approximation: \\[ \\bar{r}(25) \\approx \\bar{r}(0) + 25\\bar{r}&#39;(0) + (25)^2 \\bar{r}&#39;&#39;(0) \\] Show that \\(\\bar{r}&#39;&#39;(t) = \\bar{r}_3(t) - \\bar{r}_2(t) \\bar{r}(t) - 2 \\bar{r}(t) \\sigma^2_r(t)\\) From before, we know that for \\(i\\in\\{u,m\\}\\): \\[\\begin{aligned} \\sigma_r^2(t) &amp;= \\bar{r}&#39;(t) \\\\ &amp; = \\frac{d}{dt}\\left[ \\frac{ \\sum K_i r_i e^{r_i t}} {\\sum K_i e^{r_i t}} \\right]\\\\ &amp; = \\frac{\\sum K_i(0)r_i^2e^{r_it}} {\\sum K_i(0)e^{r_it}} - \\left(\\frac{ \\sum K_i(0)r_ie^{r_it}} {\\sum K_i(0)e^{r_it}}\\right)^2 \\\\ &amp; = \\frac{\\sum K_i(0)r_i^2e^{r_it}} {\\sum K_i(0)e^{r_it}} - \\bar{r}^2(t) \\end{aligned}\\] Then, we take the second derivative of the growth rate by using the quotient rule \\(\\left(\\frac{u}{v}\\right)&#39;= \\frac{u&#39;v-vu&#39;}{v^2}\\): \\[\\begin{aligned} \\bar{r}&#39;&#39;(t) &amp;= { \\frac{\\left(\\sum K_i(0)e^{r_it}\\right)(\\sum K_i(0)r_i^3e^{r_it}) -(\\sum K_i(0)r_i^2e^{r_it})(\\sum K_i(0)r_i e^{r_it})} {(\\sum K_i(0)e^{r_it})^2 }} - 2\\bar{r}(t)\\times\\bar{r}&#39;(t)\\\\ &amp;= \\frac{ \\sum K_i(0)r_i^3e^{r_it}} {\\sum K_i(0)e^{r_it} } - \\frac{ \\sum K_i(0)r_i^2e^{r_it}} {\\sum K_i(0)e^{r_it}}\\times \\frac{\\sum K_i(0)r_i e^{r_it}}{\\sum K_i(0)e^{r_it} } - 2\\bar{r}(t)\\sigma^2_r(t) \\\\ &amp;= \\bar{r}_3 (t) - \\bar{r}_2(t)\\bar{r}(t) - 2\\bar{r}(t)\\sigma^2_r(t) \\end{aligned}\\] where \\(\\bar{r}_n\\) is the \\(n\\)th moment of \\(\\bar{r}(t)\\), and it is known that \\(\\bar{r}&#39;(t) = \\sigma^2_r(t)\\). Calculate the combined US-Mexico population after 50 years according to the following five (5) methods, plot the total population after 50 years according to these 5 methods on a graph. For the following exercises, the population is in millions. Dissaggregated (“true”) forecast, with each country growing at its own rate: \\[\\begin{aligned} \\bar{K}(2020) &amp;= K_u(2020) + K_m(2020)\\\\ &amp;=K_u(1970) e^{(2020-1970)r_u} + K_m(1970) e^{(2020-1970)r_m}\\\\ &amp;=200e^{.0075\\times 50} + 50e^{.035\\times 50}\\\\ &amp;= 578.728 \\end{aligned}\\] Aggregated forecast, pretending it’s one country, growing at \\(\\bar{r}(0)\\)) for 50 years: \\[\\begin{aligned} \\overline{r}(1970) &amp;= \\frac{\\sum K_i(1970)r_i e^{r_i (1970-1970)}} {\\sum K_i(1970)e^{r_i (1970-1970) }}\\\\ &amp;=\\frac{K_u(1970)r_u + K_m(1970)r_m }{K_u(1970) + K_m(1970) }\\\\ &amp; = \\frac{ 200\\times .0075 + 50\\times.035} {200+50 } = 0.013 \\end{aligned}\\] \\[\\begin{aligned} \\bar{K}(2020) &amp;= \\bar{K}(1970)e^{\\bar{r}(1970) (2020-1970)}\\\\ &amp;= 250 e^{.013\\times 50} \\approx 478.8852 \\end{aligned}\\] Aggregated forecast, growing at the “true” value of \\(\\bar{r}(25)\\) for the whole period. (Use the value of \\(\\bar{r}(25)\\)) that you calculate from the disaggregated forecast): Translating \\(\\bar{r}(25)\\) onto the 1970 timeline, we should look at \\(\\bar{r}(1995)\\) \\[\\begin{aligned} \\bar{r}(1995) &amp;= \\sum K_i(1970)r_i e^{r_i (1995-1970)} \\over \\sum K_i(1970)e^{r_i (1995-1970) }\\\\ &amp; = \\frac{K_u(1970)r_u e^{r_u (25)} + K_m(1970)r_m e^{r_m (25)} }{K_u(1970)e^{r_u (25)} + K_m(1970)e^{r_m (25)} }\\\\ &amp; =\\frac{200\\times.0075 e^{.0075\\left(25\\right)}+50\\times.035 e^{.035\\left(25\\right)}}{200 e^{.0075\\left(25\\right)}+50 e^{.035\\left(25\\right)}} \\approx 0.0176632\\\\ \\bar{K}(2020) &amp;= 250e^{0.016632(50)} \\approx 574.25316 \\end{aligned}\\] Aggregated forecast, growing at the first-order Taylor series estimate of \\(\\bar{r}(25)\\) for the whole period: \\[\\begin{aligned} \\sigma^2_r(1970) &amp;= \\frac{K_u(1970)r_u^2 + K_m(1970)r_m^2} {K_u(1970) + K_m(1970)} - \\bar{r}^2(0) \\\\ &amp; = \\frac{(200)(0.0075)^2 + (50)(0.035)^2}{250}-(0.013)^2 \\\\ &amp; = 0.000121 \\\\ \\hat{\\bar{r}}(1995) &amp; \\approx \\bar{r}(1970) + 25\\sigma^2_r(1970) = 0.016025 \\\\ \\bar{K}(2020) &amp;= 250 e^{0.016025(50)} \\approx 557.0811485 \\end{aligned}\\] Aggregated forecast, growing at the second-order Taylor series estimate of \\(\\bar{r}(25)\\) for the whole period: For this exercise we need to first calculate the extra second-order term from the Taylor series, \\(25^2\\bar{r}&#39;&#39;(0)\\): \\[\\begin{aligned} \\bar{r}&#39;&#39;(1970) &amp;= \\frac{200(0.0075)^3+50(0.035)^3}{250} - \\frac{200(0.0075)^2+50(0.035)^2}{250} \\times (0.013) - 2(0.013)(0.000121)\\\\ \\hat{\\bar{r}}(1995) &amp; \\approx \\bar{r}(1970) + 25\\sigma^2_r(1970) +(25)^2\\bar{r}&#39;&#39;(1970) \\\\ &amp; = 0.01664891\\\\ \\bar{K}(2020) &amp;= 250 e^{0.01664891(50)} \\\\ &amp; \\approx 574.73337 \\\\ \\end{aligned}\\] Graphs There are many methods to project populations. For Ken’s Poisson-Exponential model, What is the closed-form expression for \\(\\hat{r}(t)\\) \\[\\begin{aligned} \\hat{r}(t) &amp;= \\frac{d}{dt}log(\\hat{k})\\\\ &amp;= r_0 - \\alpha \\lambda e^{-\\alpha t} \\end{aligned}\\] What is the variance of the growth rate? The variance of the growth rate is \\(\\sigma_r^2(t)\\): \\[ \\bar{r}&#39;(t)= \\sigma^2_r(t) = \\alpha^2\\lambda e^{-\\alpha t} \\] Write down an expression for the distortion index. What variables and parameters in the model does it depend on? Are there any variables or parameters that it doesn’t depend on? (difference of \\(\\bar{r}(t)\\) and \\(\\bar{r}(0)\\)) Distortion index: \\[\\begin{aligned} \\bar{r}(t) - \\bar{r}(0) &amp; = r_0 - \\lambda \\alpha e^{-\\alpha t} - (r_0 - \\lambda \\alpha e^{0}) \\\\ &amp; = \\lambda \\alpha - \\lambda \\alpha e^{-\\alpha t}\\\\ &amp; = \\lambda \\alpha(1-e^{-\\alpha t}) \\end{aligned}\\] Depends on \\(\\lambda\\), \\(\\alpha\\), \\(t\\), but not \\(r_0\\) or \\(s\\). That is, it depends on the the gap between growth rates, the relative population sizes, fastest growth rate, the poisson distribution parameter, but not the poisson distributed integers. "],
["frailty.html", "Chapter 3 Multiplicative Fixed Frailty 3.1 Outline 3.2 Part I. Results from Fixed Frailty 3.3 Part II. Introduction to Gamma Frailty 3.4 Conclusions 3.5 Questions 3.6 Solutions", " Chapter 3 Multiplicative Fixed Frailty 3.1 Outline Review of Mortality Mathematics Multiplicative-fixed-frailty and alternatives. Population Survival and Hazards under fixed frailty Gamma frailty Additional resources Vaupel and Missov (2014): Rodriguez (2001): detailed hand-out for Princeton class. Many of the same results as Vaupel and Missov (2014), but with alternative derivations and notation. Also includes inversion formula and extensions beyond Gamma frailty such as “Inverse Gaussian Frailty”. 3.1.1 Review of mortality mathematics \\(\\ell(x)\\) or \\(S(x)\\) probability of survival to age \\(x\\) \\(\\mu(x)\\) or \\(h(x)\\) hazard rate at age \\(x\\) (“minus the exponential rate of change in survival”) Let’s treat \\(\\mu\\) as a definition. \\[ \\mu(x) \\equiv -{d \\over dx} \\log \\ell(x) \\] Can anti-differentiate (integrate) to solve for survival: \\[ \\ell(x) = s(x) = e^{-\\int_0^x \\mu(a)\\, da} \\] 3.1.2 Application: what is \\(\\ell&#39;(x)\\)? in words? taking derivative of \\(\\ell(x)\\) interpretation 3.1.2.1 Two special cases Constant hazards \\(\\mu(x) = \\mu\\). What’s \\(\\ell(x)\\)? Gompertz hazards \\(\\mu(x) = a e^{b x}\\). What’s \\(\\ell(x)\\)? 3.1.3 Extending Keyfitz to mortality \\[ {d \\over dx} \\bar{\\mu}(x) = \\mbox{average rate of change} - \\sigma_\\mu^2 \\] What is \\(\\bar{\\mu}\\)? It’s a weighted average: \\[ \\bar{\\mu}(x) = {\\int \\mu(x | z) \\ell(x | z) p(z) \\, dz \\over \\int \\ell(x | z) p(z) \\, dz} \\] To derive Keyfitz extension, differentiate with respect to age \\(x\\). (See Vaupel and Missov (2014) (Eq. 13). A good exercise. 3.1.4 Multiplicative Fixed frailty For individual \\(i\\), \\[ \\mu_i(x) = z_i \\mu_0(x). \\] \\(z_i\\) “frailty” of the \\(i\\)th individual. (Usually thought of as a random variable with mean \\(1\\).) \\(\\mu_0(x)\\) “Baseline hazard” schedule. (Also, the schedule of a person with \\(z = 1\\)). Let’s think of at least three. (\\(\\beta\\), \\(i\\), \\(\\Delta\\)) Which look like multiplicative fixed frailty? Figure 3.1: Multiplicative fixed frailty 3.2 Part I. Results from Fixed Frailty 3.2.1 A simulation Our questions How do we do a micro-simulation, with individuals? How does fixed frailty fit in? How do we compute pop survival, hazards, etc. How does life table of heterogeneous pop differ from baseline? 3.2.2 Let’s derive pop survival (Note: \\(\\bar{s} = \\bar{\\ell}\\)) Pop survival will be a weighted average of group survival curves \\[ \\bar{s}(x) = {p(z_1) s_1(x) + p(z_2) s_2(x) + \\ldots \\over p(z_1) + p(z_2) + \\ldots} \\] With continuous \\(z\\) (what are limits of integration?) \\[ \\bar{s}(x) = \\int s(x|z) p(z) \\, dz \\] Under Multiplicative Fixed Frailty use \\[ \\mu(x|z) = z \\mu_0(x) \\] to derive \\[\\bar{s}(x) = \\int s_0(x)^z p(z) \\,dz.\\] 3.2.3 Now population hazards (stepping stones) Definition of hazards: \\[ \\bar{\\mu}(x) = - {d \\over dx} \\log \\bar{s}(x) \\] \\[ \\bar{\\mu}(x) = \\mu_0(x) {\\int z s_0(x)^z p(z) \\, dz \\over \\int s_0(x)^z p(z) \\, dz} \\] \\[ \\bar{\\mu}(x) = \\mu_0(x) \\bar{z}(x) \\] Let’s fill in steps. 3.2.4 Rodriguez question Why isn’t population hazard a (simple) average of individual hazards? Answer: selected survival means that the distribution of frailty at age \\(x\\) differs from the starting frailty distribution at age \\(0\\). The rate of increase in hazards (AKA “LAR: Lifetable Aging Rate”) \\[ \\beta(x) = {d \\over dx} \\log \\mu(x) \\] Example: What is \\(\\beta(x)\\) for Gompertz: \\(\\mu(x) = a e^{bx}\\)? Vaupel’s result \\[ \\bar{\\beta}(x) = \\beta_0(x) - \\bar{\\mu}(x) CV_z^2(x) \\] Hazards rise less slowly in pop than in baseline If pop hazards plateau, then \\(\\bar{\\beta}(x) = 0\\) Two special cases Homogeneous pop and plateau in baseline Gompertz and constant \\(CV_z\\) (e.g., from Gamma) 3.3 Part II. Introduction to Gamma Frailty 3.3.1 The Gamma distribution What do we want in a frailty distribution? positive? a single dimension summarizing multiple factors? (Normal?) flexible? tractable? What’s the Gamma? \\[ p(z | k, \\lambda) = {\\lambda^k \\over \\Gamma(k)} z^{k-1} e^{-\\lambda z} \\] \\(z\\) the random variable representing frailty \\(k, \\lambda\\) parameters \\(\\Gamma(k)\\) A normalizing constant. 3.3.2 Gamma in R Mean: \\(k / \\lambda\\) Variance: \\(k / \\lambda^2\\) ## with k and lambda k = 3; lambda = 6 x &lt;- rgamma(10000, shape = k, rate= lambda) mean(x) ## [1] 0.5017978 sd(x) ## [1] 0.2889426 Alternate parameterization ## with mean 1, sigma.sq sigma.sq &lt;- .25 z &lt;- rgamma(10000, shape = 1/sigma.sq, rate = 1/sigma.sq) mean(z) ## [1] 0.9996 var(z) ## [1] 0.2527649 3.3.3 Population Survival of Gamma Frailty Big picture \\[ \\bar{s}(x) = \\int s_0(x)^z p(z) \\, dz \\] Or, using our definition of survival, \\[ \\bar{s}(x) = \\int e^{-z H_0(x)} p(z) \\, dz \\] Completing the gamma \\[ \\bar{s}(x) = \\int e^{-z H_0(x)} {\\lambda^k \\over \\Gamma(k)} z^{k-1} e^{-\\lambda z} \\, dz \\] Rearranging, \\[ \\bar{s}(x) = \\lambda^k \\int { 1 \\over \\Gamma(k)} z^{k-1} e^{-z (H_0(x)+\\lambda)} \\, dz \\] Integral is like a \\(Gamma(z | k, H_0(x) + \\lambda)\\), but missing something. What? Our Result \\[ \\bar{S}(x) = {\\lambda^k \\over \\left[H_0(x) + \\lambda\\right]^k} \\] If mean = 1.0, then we can let \\(\\lambda = k = 1/\\sigma^2\\), \\[ \\bar S(x) = {1/\\sigma^2 \\over (H_0(x) + 1/\\sigma^2)^{1/ \\sigma^2}} = {1 \\over \\left(1 + \\sigma^2 H_0(x)\\right)^{1/ \\sigma^2}} \\] 3.3.4 Interpreting Gamma-frailty survival \\[ \\bar S(x) = {1 \\over \\left(1 + \\sigma^2 H_0(x)\\right)^{1/ \\sigma^2}} \\] Older ages, smaller survival. Variance not so clear, need a picture. (What if \\(\\sigma^2 = 0\\)?) x &lt;- 0:100 a = 10^-4 b = 1/10 mx.0 &lt;- a * exp(b*x) Hx.0 &lt;- cumsum(mx.0) Sx.0 &lt;- exp(-Hx.0) ## small sigma sigma.sq = .5^2 bar.S.small.sigma &lt;- 1 / (1 + sigma.sq *Hx.0)^(1/sigma.sq) ## big sigma sigma.sq = 1^2 bar.S.big.sigma &lt;- 1 / (1 + sigma.sq *Hx.0)^(1/sigma.sq) plot(x, Sx.0, lty = 2, type = &quot;l&quot;, ylim = c(0,1), ylab = &quot;Survival&quot;) lines(x, bar.S.small.sigma, col = &quot;blue&quot;) lines(x, bar.S.big.sigma, col = &quot;red&quot;) legend(&quot;bottomleft&quot;, c(&quot;Pop big.sigma&quot;, &quot;Pop small.sigma&quot;, &quot;Baseline&quot;), lty = c(1, 1, 2), bty = &quot;n&quot;, col = c(&quot;red&quot;, &quot;blue&quot;, &quot;black&quot;)) Figure 3.2: Gamma-frailty population survival 3.4 Conclusions Multiplicative Fixed Frailty is one option for modeling Gave us analytical expressions for population survival and hazards including \\(\\bar{\\mu}(x) = \\mu_0(x) \\bar{z}(x)\\) Extended Keyfitz result to age-changing hazards Survival curve for Gamma 3.5 Questions True/False: The variance of the population distribution of deaths will always be larger than that of the baseline. Explain your answer briefly. Use the frailty simulator to produce plots of the uniform, gamma, and U-shaped beta distribution. Describe in a sentence, each, how the population hazard behaves at older ages. Does the behavior of the uniform at older ages look like a population with two (proportional) sub-groups? What do you think is driving this? (This is an open-ended question. You should feel free to use mathematics, intuition, or any other approach to answer.) Does the behavior of the beta at older ages look like the gamma at older ages? What do you think is driving this? (Also open ended) At what age do population hazards start to diverge from the baseline in the the three models? Is it fair to say that half the cohort has to have died before unobserved heterogeneity plays a role? Extend the simulation code to include life expectancy at age x (Shown above.) Extend the simulation code to include the average frailty of the surviving at age x, z(x). (Note: this requires some more difficulty programming, and I would recommend keeping your N fairly small.) Extend the simulation code to histograms of frailty of survivors at different ages. Does the uniform stay uniform? How about the other distributions? Use the method of completing the gamma to get the mean of the gamma distribution. (Hint: I believe there are youtube examples of this). Derive V&amp;M equation 13, extending Keyfitz’s result. Did your derivation require you to assume proportional hazards; if so, where? Derive V&amp;M equation 20, extending Keyfitz’s result to proportional changes in the population hazard. Did your derivation require you to assume proportional hazards; if so, where? Describe a strategy for simulating cross-overs in the aggregate hazards of two groups, which have baseline hazards that don’t cross. If you want, write code and produce a plot. 3.6 Solutions True/False: The variance of the population distribution of deaths will always be larger than that of the baseline. Explain your answer briefly. True. If each individual has their own hazard schedule proportional to baseline \\(z\\), there will be more variation in the distribution of deaths than if each person had the baseline case. The variation for homogeneous populations comes from to chance only, while the variation for heterogeneous populations comes from chance and group variation in risk. Therefore, the variance of the population distribution of deaths will always be larger than that of the baseline (unless the variance is 0). Use the fraily simulator code to produce plots of the uniform, gamma, and U-shaped beta distribution. Describe in a sentence, each, how the population hazard behaves at older ages. For simplicity, we take the code and convert it into a function that can use frailty draws from different distributions. We also extend it to include life expectancy calculation. source(&quot;functions/gomp_funs.R&quot;) frailty_sim &lt;- function( N, z, base.a, base.b ){ ## (1) simulate ages at death from h0*z using the gompertz as our baseline## ## note: we call the continuous ages of death &quot;y&quot; ## but we&#39;ll make a table of deaths at age &quot;x&quot; and ## using life table notation call the count &quot;Dx&quot; y &lt;- rgomp(N, b = base.b, ## doesn&#39;t vary a = base.a * z) ## multiplicative fixed frailty ## (2) Lifetables: first define age at death as floor(y) and then ## make a table of deaths at each age (&quot;Dx&quot;) Dx &lt;- get.Dx(y) x &lt;- as.numeric(names(Dx)) lx &lt;- rev(cumsum(rev(Dx))) ## lx by reverse-survival lxpn &lt;- c(lx[-1], 0) ## Person-years as average of adjacent lx Lx &lt;- (lx + lxpn)/2 mx &lt;- Dx/Lx ## Hazards Tx &lt;- rev(cumsum(rev(Lx))) ## Remaining person-years ex &lt;- Tx/lx ## Life expectancy at age x ## Baseline lifetable lx.base &lt;- N * (1- pgomp(x, b = base.b, a = base.a)) Dx.base &lt;- round(-diff(c(lx.base,0))) mx.base &lt;- base.a * exp(base.b * (x + .5)) ## x + .5 lxpn.base &lt;- c(lx.base[-1], 0) Lx.base &lt;- (lx.base + lxpn.base)/2 Tx.base &lt;- rev(cumsum(rev(Lx.base))) ex.base &lt;- Tx.base/lx.base # exported tables lifetables &lt;- list() lifetables$sim &lt;- y lifetables$z &lt;- z lifetables$baseline &lt;- tibble(Dx.base, lx.base,lxpn.base, Lx.base, mx.base, Tx.base, ex.base) lifetables$frailty &lt;- tibble(x,Dx, lx,lxpn, Lx, mx, Tx, ex) return(lifetables) } Uniform distribution: We find that the uniform-distributed frailty begins to increase more slowly after age 60 compared to baseline. # Parameters million = 10^6 N &lt;- million base.a &lt;- 10^-4 base.b &lt;- 1/9 set.seed(1047) # for reproducibility #Uniform distribution w &lt;- .3 ## try smaller if you want z &lt;- runif(N, min = 1 - w , max = 1 + w) uniform_frailty &lt;- frailty_sim(N, z, base.a, base.b) Figure 3.3: Uniform Distribution Gamma frailty distribution: Gamma-distributed frailty begins to increase more slowly after age 60 compared to baseline.This is similar to the uniform frailty distribution. # Parameters million = 10^6 N &lt;- million base.a &lt;- 10^-4 base.b &lt;- 1/9 set.seed(1047) # for reproducibility #Gamma distribution my.sd &lt;- .5 sigma.sq &lt;- my.sd^2 z &lt;- rgamma(N, shape = 1/sigma.sq, scale = sigma.sq) gamma_frailty &lt;- frailty_sim(N, z, base.a, base.b) Figure 3.4: Gamma Distribution Beta frailty distribution: Beta-distributed frailty begins to increase more slowly after age 60 compared to baseline and eventually stops increasing at age 100. # Parameters million = 10^6 N &lt;- million base.a &lt;- 10^-4 base.b &lt;- 1/9 set.seed(1047) # for reproducibility #Beta distribution z &lt;- rbeta(N, shape1 = .5, shape2 = .5) beta_frailty &lt;- frailty_sim(N, z, base.a, base.b) Figure 3.5: Beta Distribution Does the behavior of the uniform at older ages look like a population with two (proportional) sub-groups? What do you think is driving this? It doesn’t look like two proportional subgroups. It looks like the frailty is drawn from a single distribution. Does the behavior of the beta at older ages look like the gamma at older ages? What do you think is driving this? The behavior is somewhat similar, as the hazards are increasing more slowly at older ages. However, the beta hazards stops increasing at a certain point. The uniform and the gamma are more similar. For the parameters we used, beta-distributed frailty generates many very-frail or very-robust individuals and fewer medium-frail individuals. Gamma-distributed frailty generates many medium-frail individuals but fewer very-frail or very-robust individuals. At what age do population hazards start to diverge from the baseline in the the three models? Is it fair to say that half the cohort has to have died before unobserved heterogeneity plays a role? Generally around age 65, but if frailty is beta distributed (with our set of parameters) then we observe a divergence earlier. For the gamma and uniform frailty models roughly half the cohort has to die before unobserved heterogeneity plays a role, but for the beta model we observe divergence in the survival curve much earlier. Extend the simulation code to include life expectancy at age x. Within the frailty function, we include the steps to calculate life expectancy. We also limit the ages up to 100 for each simulation, to avoid extreme and non-realistic results. This is particularly relevant for the beta frailty distribution which leads to ages above 110 to be sampled. Tx&lt;- rev(cumsum(rev(Lx))) ex &lt;- Tx/lx par(mfrow = c(2,2), oma=c(0.1,0.1,0.1,0.1), mar=c(3,4,3,1)) ## Uniform plot(uniform_frailty$frailty$x, uniform_frailty$frailty$ex, main = &quot;Uniform&quot;, type = &quot;l&quot;, ylim = range(uniform_frailty$frailty$ex, na.rm = T, finite = TRUE), xlab = &quot;Age&quot;, ylab =&quot;ex&quot;) lines(uniform_frailty$frailty$x, uniform_frailty$base$ex.base, lty = 2) legend(&quot;topright&quot;, legend = c(&quot;pop&quot;, &quot;baseline&quot;), lty = c(1, 2), cex = .8, bty = &quot;n&quot;) ## Gamma plot(gamma_frailty$frailty$x, gamma_frailty$frailty$ex, main = &quot;Gamma&quot;, type = &quot;l&quot;, ylim = range(gamma_frailty$frailty$ex, na.rm = T, finite = TRUE), xlab = &quot;Age&quot;, ylab =&quot;ex&quot;) lines(gamma_frailty$frailty$x, gamma_frailty$base$ex.base, lty = 2) legend(&quot;topright&quot;, legend = c(&quot;pop&quot;, &quot;baseline&quot;), lty = c(1, 2), cex = .8, bty = &quot;n&quot;) ## Beta plot(beta_frailty$frailty$x, beta_frailty$frailty$ex, main = &quot;Beta&quot;, type = &quot;l&quot;, ylim = range(beta_frailty$frailty$ex, na.rm = T, finite = TRUE), xlim = c(0, 110), xlab = &quot;Age&quot;, ylab =&quot;ex&quot;) lines(beta_frailty$frailty$x, beta_frailty$base$ex.base, lty = 2) legend(&quot;topright&quot;, legend = c(&quot;pop&quot;, &quot;baseline&quot;), lty = c(1, 2), cex = .8, bty = &quot;n&quot;) Figure 3.6: Life expectancy comparison Extend the simulation code to include the average frailty of the surviving at age x, z(x). (Note: this requires some more difficulty programming, and I would recommend keeping your N fairly small.) avg_hazard_uniform &lt;- tibble(age = floor(uniform_frailty$sim),z = uniform_frailty$z) %&gt;% group_by(age) %&gt;% summarize(z_mean = mean(z), n = n()) %&gt;% mutate(z_bar_num = cumsum(rev(z_mean*n)), z_bar_denom = cumsum(rev(n))) %&gt;% mutate(z_bar = rev(z_bar_num/z_bar_denom) ) avg_hazard_beta &lt;- tibble(age = floor(beta_frailty$sim),z = beta_frailty$z) %&gt;% group_by(age) %&gt;% summarize(z_mean = mean(z), n = n()) %&gt;% mutate(z_bar_num = cumsum(rev(z_mean*n)), z_bar_denom = cumsum(rev(n))) %&gt;% mutate(z_bar = rev(z_bar_num/z_bar_denom) ) avg_hazard_gamma &lt;- tibble(age = floor(gamma_frailty$sim),z = gamma_frailty$z) %&gt;% group_by(age) %&gt;% summarize(z_mean = mean(z), n = n()) %&gt;% mutate(z_bar_num = cumsum(rev(z_mean*n)), z_bar_denom = cumsum(rev(n))) %&gt;% mutate(z_bar = rev(z_bar_num/z_bar_denom) ) ggplot(data=avg_hazard_uniform , aes(x = age, y = z_bar)) + geom_point() + theme_minimal() + ylab(&quot;&quot;) Figure 3.7: Uniform Hazards Average Frailty ggplot(data=avg_hazard_gamma , aes(x = age, y = z_bar)) + geom_point() + theme_minimal() + ylab(&quot;&quot;) Figure 3.8: Gamma Hazards Average Frailty ggplot(data=avg_hazard_beta , aes(x = age, y = z_bar)) + geom_point() + theme_minimal() + ylab(&quot;&quot;) Figure 3.9: Beta Hazards Average Frailty Extend the simulation code to histograms of frailty of survivors at different ages. Does the uniform stay uniform? How about the other distributions? The uniform does not remain uniform. This matches our intuition that people with higher frailty will die off first. This leaves an exponentially decreasing distribution of frailty for survivors age 75+. The gamma remains a gamma but the parameters change. The beta, similar to the uniform, does not remain beta. There is an exponentially decreasing distribution of frailty for survivors age 75+. avg_hazard_uniform_age &lt;- tibble(age = floor(uniform_frailty$sim),z = uniform_frailty$z) %&gt;% filter(age &gt; 0) %&gt;% mutate(age_group = case_when( age &lt; 25 ~ &quot;(0-25]&quot;, age &lt; 50 ~&quot;(25, 50]&quot;, age &lt; 75 ~ &quot;(50, 75]&quot;, age &gt;= 75 ~&quot;75+&quot; )) %&gt;% ggplot()+ geom_histogram(aes(x = z))+ theme_minimal() + facet_grid( ~age_group, margins = T) avg_hazard_uniform_age Figure 3.10: Uniform Hazards Frailty avg_hazard_gamma_age &lt;- tibble(age = floor(gamma_frailty$sim),z = gamma_frailty$z) %&gt;% filter(age &gt; 0) %&gt;% mutate(age_group = case_when( age &lt; 25 ~ &quot;(0-25]&quot;, age &lt; 50 ~&quot;(25, 50]&quot;, age &lt; 75 ~ &quot;(50, 75]&quot;, age &gt;= 75 ~&quot;75+&quot; )) %&gt;% ggplot()+ geom_histogram(aes(x = z))+ theme_minimal() + facet_grid( ~age_group, margins = T) avg_hazard_gamma_age Figure 3.11: Gamma Hazards Frailty avg_hazard_beta_age &lt;- tibble(age = floor(beta_frailty$sim),z = beta_frailty$z) %&gt;% filter(age &gt; 0) %&gt;% mutate(age_group = case_when( age &lt; 25 ~ &quot;(0-25]&quot;, age &lt; 50 ~&quot;(25, 50]&quot;, age &lt; 75 ~ &quot;(50, 75]&quot;, age &gt;= 75 ~&quot;75+&quot; )) %&gt;% ggplot()+ geom_histogram(aes(x = z))+ theme_minimal() + facet_grid( ~age_group, margins = T) avg_hazard_beta_age Figure 3.12: Beta Hazards Frailty Use the method of completing the gamma to get the mean of the gamma distribution. \\[\\begin{aligned} \\mu &amp; = \\int_0^{\\infty} \\frac{1}{\\Gamma(k) \\lambda^k} z^{k - 1} e^{-\\frac{z}{\\lambda}} \\\\ &amp; = \\frac{\\Gamma(k+1) \\lambda^{k+1}}{\\Gamma(k+1) \\lambda^{k+1}} \\cdot \\int_0^{\\infty} \\frac{1}{\\Gamma(k) \\lambda^k} z^{k - 1} e^{-\\frac{z}{\\lambda}} \\\\ &amp; = \\frac{\\Gamma(k+1) \\lambda^{k+1}}{\\Gamma(k) \\lambda^{k}} \\cdot \\int_0^{\\infty} \\frac{1}{\\Gamma(k+1) \\lambda^{k+1}} z^{k - 1} e^{-\\frac{z}{\\lambda}} \\\\ &amp; = k \\lambda \\cdot 1 \\\\ &amp; = k \\lambda \\end{aligned}\\] Derive V&amp;M equation 13, extending Keyfitz’s result. Did your derivation require you to assume proportional hazards; if so, where? Derive V&amp;M equation 20, extending Keyfitz’s result to proportional changes in the population hazard. Did your derivation require you to assume proportional hazards; if so, where? Describe a strategy for simulating cross-overs in the aggregate hazards of two groups, which have baseline hazards that don’t cross. If you want, write code and produce a plot. References "],
["gamma-frailty-with-applications.html", "Chapter 4 Gamma Frailty with Applications 4.1 From survival to hazards 4.2 CenSoc: Selection and observed frailty 4.3 Questions 4.4 Solutions", " Chapter 4 Gamma Frailty with Applications 4.1 From survival to hazards We have \\[ \\bar S(x) = {1 \\over \\left(1 + \\sigma^2 H_0(x)\\right)^{1/ \\sigma^2}} \\] Let’s compute \\(\\bar\\mu(x)\\). \\[ \\bar\\mu(x) = {\\mu_0 \\over 1 + \\sigma^2 H_0(x)} \\] 4.1.1 What happens to frailty of survivors? Recall that pop hazards = baseline \\(\\times \\bar{z}(x)\\). So, \\[ \\bar\\mu(x) = \\mu_0(x) { 1 \\over 1 + \\sigma^2 H_0(x)} \\] Sketch \\(\\bar{z}(x)\\). Hint: what form does \\(H_0(x)\\) have? (see next Example) 4.1.1.1 Example: Gamma-Gompertz If \\(H_0(x)\\) be Gompertz, we have closed-form expression. What is it? Does \\(\\bar{z}\\) have the form \\[{1 \\over 1 + v*e^{w x}}\\] This is a backwards S, going down. sigma.sq = .2 x = 0:100 a = 5 * 10^-4 b = 1/8 H0.x = (a/b) * (exp(b*x) - 1) bar.z = 1 / (1 + sigma.sq * H0.x) plot(x, bar.z) Figure 4.1: Gamma-Gompertz Look at the apparent exponential decline in tail. Homework: what is proportional rate of change in \\(\\bar{z}\\) as \\(x\\) gets big? Is it close to Gompertz \\(b\\)? 4.1.2 Average frailty in terms of survival \\[ \\bar{z}(x) = [\\bar{S}(x)]^{\\sigma^2}\\] Let’s derive? In real life, we observe \\(\\bar{S}(x)\\). So this allows us to say something about implied \\(\\bar{z}\\) from hazards. Reversing the logic: if we see a characteristic changing with age, then we can estimate “\\({\\sigma^2}\\)” (I put in quotes because its the variance of the proportional effect of the observed characteristic.) 4.2 CenSoc: Selection and observed frailty We have a large matched sample from the 1940 census to Social Security death data observed from 1975 to 2004. This means that we can compute the survival curves of extinct cohorts and see how mortality selection changes the composition of the cohort as it ages. In this example, we use observed wage income in 1940 for the cohort born 1895 to 1900. We look at how wages of survivors increase with age as a result of selective mortality and we see if the gamma-frailty model can produce similar results. 4.2.1 Data Read in the data and transform the variables to what we want. We produce a variable \\(y\\) (in this case a standardized version of log wage income) to be transformed into a frailty score. ## read in dat library(data.table) dt &lt;- fread(&quot;/data/josh/CenSoc/archive/censoc_bfdw.csv&quot;) ## Clean wage data dt[, incwage := INCWAGE] dt[incwage == 999998, incwage := NA] dt[incwage == 0, incwage := NA] hist_incwage &lt;- dt[, hist(incwage, main =&quot;&quot;, xlab = &quot;Income-Wage&quot;)] Figure 4.2: Histogram of Income-Wage hist_ln_incwage &lt;- dt[, hist(log(incwage),main =&quot;&quot;, xlab = &quot;Log(Income-Wage)&quot;)] Figure 4.3: Histogram of LOG(Income-Wage) ## Do age at death for 1895-1900 cohorts dt[, age.at.death := dyear + dmonth/12 - (byear + bmonth/12)] my.dt &lt;- dt[byear %in% 1895:1900 &amp; dyear %in% 1975:2004] ## now limits to deaths younger than 105 my.dt[, max(age.at.death), by = byear] ## byear V1 ## 1: 1900 104.9167 ## 2: 1898 106.8333 ## 3: 1897 107.0833 ## 4: 1895 109.4167 ## 5: 1899 105.6667 ## 6: 1896 107.9167 nrow(my.dt[age.at.death &gt;= 105]) ## [1] 177 nrow(my.dt[floor(age.at.death) == 104]) ## [1] 253 ## now we have same age range for every cohort my.dt &lt;- my.dt[age.at.death &lt; 105] my.dt &lt;- my.dt[!is.na(incwage)] ## keep only non-missing Log-wages look reasonable, unimodal, kind of symmetric. We now center our variable to 0 before estimating the effect on mortality. Our model exponentiates this 0 to become 1, which is where we want our frailty measure to be centered. ## standardized log income ## log_inc_stan = log(y_orig) - mean(log(y_orig)) ## note: control for byear, since different ages in 1940 my.dt[, y_orig := incwage] my.dt[, log_inc := log(incwage)] my.dt[, log_inc_mean := mean(log_inc), by = byear] my.dt[, y := log_inc - log_inc_mean] hist_y &lt;- my.dt[, hist(y)] Figure 4.4: Histogram of standardized Log(Income-Wage) my.dt[, summary(y, main=&quot;&quot;, xlab = &quot;Standardized Log(Income-Wage)&quot;)] ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -7.0542 -0.4159 0.1661 0.0000 0.5660 4.2460 Now we’re centered at 0. Show how our (life-long fixed) characteristic of interest changes by age because of mortality selection. par(mfrow = c(1,2)) my.dt[, plot(x, y_orig.bar)] ## NULL title(&quot;Wage income by surviving age&quot;, cex.main = .7) my.dt[, plot(x, y.bar)] ## NULL title(&quot;Standardized log of Wage income by surviving age&quot;, cex.main = .7) Figure 4.5: Wage Income by age So we see annual wage income in 1940 increases by about $100 or so, or about 5% from age 75 to age 95. And more after that. Is this what we would expect from our Gamma frailty model? 4.2.2 Estimation Estimate an observed frailty for each person, call this \\(z_{obs}\\) To do this we first use Cox regression to estimate the proportional effect of \\(y\\) on hazards. The Cox model has the form \\[ \\mu_i(x) = \\mu_0(x) e^{\\beta y} \\] We can then transform \\(y\\) into a frailty score \\(z_{obs}\\), letting \\[ z_{obs} = e^{\\hat\\beta y} \\] ## now get z&#39;s library(survival) my.dt[, event := 1] m &lt;- coxph(Surv(age.at.death, event) ~ y, data = my.dt) (summary(m)) ## Call: ## coxph(formula = Surv(age.at.death, event) ~ y, data = my.dt) ## ## n= 402797, number of events= 402797 ## ## coef exp(coef) se(coef) z Pr(&gt;|z|) ## y -0.03073 0.96974 0.00177 -17.36 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## exp(coef) exp(-coef) lower .95 upper .95 ## y 0.9697 1.031 0.9664 0.9731 ## ## Concordance= 0.512 (se = 0.001 ) ## Likelihood ratio test= 298 on 1 df, p=&lt;2e-16 ## Wald test = 301.5 on 1 df, p=&lt;2e-16 ## Score (logrank) test = 301.5 on 1 df, p=&lt;2e-16 ## coef exp(coef) se(coef) z Pr(&gt;|z|) ## y -0.03073 0.96974 0.00177 -17.36 &lt;2e-16 *** ## so a 10% increase in income reduces mortality by .3% (quite a tiny effect!) beta &lt;- coef(m) The effect is very small. Any ideas why? Now estimate our z’s. my.dt[, z := exp(beta * y)] hist_z &lt;- my.dt[, hist(z, xlim = c(0, 3))] Figure 4.6: Histogram of Fraility Does this look gamma-like? Calculating the variance of \\(z_{obs}\\) to be used for estimating \\(\\bar{z}_{obs}\\). (Also plotting the histogram to see if it looks gamma-like) sigma.sq &lt;- var(my.dt$z) print(sigma.sq) ## [1] 0.000745355 print(sqrt(sigma.sq)) ## [1] 0.02730119 Check SD against histogram. Does it look right? Extinct cohort method to estimate survivorship \\(\\bar{S}(x)\\) Dx &lt;- my.dt[, table(floor(age.at.death))] par(mfrow = c(1,2)) plot(Dx) lx &lt;- rev(cumsum(rev(Dx))) lxpn &lt;- c(lx[-1],0) Lx &lt;- (lx + lxpn)/2 mx &lt;- Dx/Lx x &lt;- as.numeric(names(Dx)) plot(x, log(mx), type = &quot;p&quot;) ## gomp fit from ages 80 to 95 m &lt;- lm (log(mx) ~ x, subset = x %in% 80:100) lines(80:100, predict(m), lwd = 2) axis(2) Figure 4.7: Deaths and Mortality ## no slowdown in mortality!! How does Dx look? Plausible? How about hazards? They are Gompertzian for a while, but how do we explain tails? plot(x, lx) Figure 4.8: Survirship Estimation of \\(\\hat{\\bar{z}}(x)\\) using the gamma-frailty result: \\[ \\bar{z}(x) = \\bar{S}(x)^{\\sigma^2} \\] sx.bar &lt;- lx/lx[1] z.bar.hat &lt;- sx.bar^sigma.sq Comparing this to our observed \\(\\bar{z}\\) x &lt;- 74:104 z.bar &lt;- NULL for (i in 1:length(x)) { z.bar[i] &lt;- my.dt[age.at.death &gt; x[i], mean(z)] } Plotting comparison plot(x, z.bar.hat, ylim = c(.995, 1.001), type = &quot;l&quot;, lty = 2) lines(x, z.bar) Figure 4.9: Frailty comparison How did we do? Showing plots for observed mortality selection and the gamma-frailty based estimate of mortality selection. Do this for several measures including \\(y\\), and raw (unstandardized) income. y.bar.hat &lt;- log(z.bar.hat)/beta plot(x, y.bar, ylab = &quot;log(inc) - mean(log(inc))&quot;) lines(x, y.bar.hat) title(&quot;Mean standardized log-income&quot;) legend(&quot;topleft&quot;, legend = c(&quot;observed&quot;, &quot;fitted&quot;), pch = c(1, -1), lty = c(-1, 1)) Figure 4.10: Frailty comparison ## bar.log.y = mean(log(my.dt$y_orig)) y_orig.bar.hat.wrong &lt;- exp(y.bar.hat) * exp( bar.log.y) ## this is geometric mean y_orig.bar.hat.right &lt;- exp(y.bar.hat)*y_orig.bar[1] plot(x, y_orig.bar, ylab = &quot;$ per year&quot;) title(&quot;Mean income&quot;) legend(&quot;topleft&quot;, legend = c(&quot;observed&quot;, &quot;fitted&quot;), pch = c(1, -1), lty = c(-1, 1)) lines(x, y_orig.bar.hat.wrong, lty = 2) lines(x, y_orig.bar.hat.right, lty = 1) Figure 4.11: Frailty comparison 4.2.3 Discuss our conclusions and possible future directions to follow. How did we do? Does our gamma frailty model give basically the right prediction? How come it appears that wage income matters so little? How could we improve the measurement of wage income? What other variables could we look at? How would we expect the gamma model do with another variable, e.g. educational attainment? What is the relationship between “observed” and “unobserved” frailty? IMPORTANT: Is our work here a validation of the model’s applicability to real life? If so what are we validating? That our transformed covariate is roughly gamma distributed? Are we assuming multiplicative fixed frailty – or are we validating it’s applicability? 4.3 Questions Under gamma frailty, we obtained an explicit expression for average frailty by age for any baseline hazard schedule. \\[ \\bar{z}=\\frac{1}{1+\\sigma^2 H_0(x)}\\] Assume baseline mortality is Gompertz (say with a = \\(10^{-4}\\) and b = 1/12). Try a couple of different values of \\(\\sigma^2\\) (but make sure one of these values is 1/7 for comparability with the next problem). Describe what happens to average frailty at older ages. Does it decrease exponentially? If so, is there an age at which the rate of decrease equals (or at least comes very close to) the exponential rate of increase in baseline hazards b? Does this age depend on \\(\\sigma^2\\)? Obtain from the Human Mortality Database a schedule of single-year-of-age, cohort mortality rates for females born in 1880 in Italy. Use the “inversion formula” for the gamma distribution to obtain the baseline hazards implied by \\(\\sigma^2= 1/7\\). Plot the observed and implied baseline schedule. Plot the average frailty by age. Do your results resemble or differ from the Gompertz case above ? Derive V&amp;M ’s result (5E):\\[\\overline{R}(x) \\equiv \\frac{\\bar{\\mu}_2(x)}{\\bar{\\mu}_1(x)} = \\frac{R + R \\sigma_1^2 H_1(x)}{1 + R \\sigma_2^2 H_1(x)} \\] Use mathematics to say what the determinants of the age of crossover are in terms of the respective frailty variances, R, and a baseline Gompertz schedule. Simulate this cross over with two proportional Gompertz schedules, with different frailty variances. Can you get a cross-over? If so, does it occur when cumulative hazard satisfy the condition (in small font) at the end of 5E? Use simulation to say what the determinants of the age of crossover are in terms of the respective frailty variances, R, and the baseline Gompertz schedule. Get two Italian cohorts 20 years apart and calculate the rate of mortality improvement by age \\(\\rho(x)\\) that you observe and that which you would have observed had there been no frailty. For frailty, assume gamma-distributed with \\(\\sigma^2 = 1/5\\). Extend the CenSoc demonstration of changing characteristics with age in at least one of the following ways Use years of education instead of wage income. Use both years of education and wage income. Analyze Blacks and Whites separately using wage income? Is the variance of “observed heterogeneity” (\\(\\hat{z}_{obs}\\)) larger for one group. Discuss briefly. 4.4 Solutions Under gamma frailty, we obtained an explicit expression for average frailty by age for any baseline hazard schedule. \\[ \\bar{z}=\\frac{1}{1+\\sigma^2 H_0(x)}\\] Assume baseline mortality is Gompertz (say with a = \\(10^{-4}\\) and b = 1/12). Try a couple of different values of \\(\\sigma^2\\) (but make sure one of these values is 1/7 for comparability with the next problem). Describe what happens to average frailty at older ages. Does it decrease exponentially? If so, is there an age at which the rate of decrease equals (or at least comes very close to) the exponential rate of increase in baseline hazards \\(b\\)? Does this age depend on \\(\\sigma^2\\)? Let \\(H_0\\) be a gompertz curve with parameters a = \\(10^{-4}\\) and b = 1/12. The average frailty over age depends on the level of \\(\\sigma^2\\) as seen by the left handside graph. As \\(\\sigma^2\\) increases, average fraily decreases at an exponential rate at earlier ages. That is, when \\(\\sigma^2\\) is very large (ie, 50) the exponential decrease begins almost instantly. However, with a very small \\(\\sigma^2\\) of 0.01 the average frailty is almost constant except at older ages. Therefore \\(\\sigma^2\\) determines when average frailty starts to decrease. The graph on the right shows the derivative over ages of each of the average frailty curves as well as the \\(b\\) parameter of the baseline Gompertz mortality (in blue). Regardless of the the value of \\(\\sigma^2\\), none of the derivatives are close enough to equal the \\(b\\) parameter.Analytically, the derivative of average frailty is always going to be negative and very small. \\[\\frac{d}{dx}\\bar{z}= -\\sigma^2ae^{bx}\\bar{z}(x)^2\\]. sigma.sq1 &lt;- c(0.01, 1/7, 0.5, 0.75,4,50) a &lt;- 10^-4 b &lt;- 1/12 x &lt;- 0:100 H0x &lt;- (a/b)*(exp(b*x) -1) z.bar.fun &lt;- function(variance) { z.bar &lt;- 1 / (1 + H0x*variance) return(z.bar) } #Average gamma frailty z1 &lt;- z.bar.fun(0.01) z2 &lt;- z.bar.fun(1/7) z3 &lt;- z.bar.fun(0.5) z4 &lt;- z.bar.fun(0.75) z5 &lt;- z.bar.fun(4) z6 &lt;- z.bar.fun(50) #Derivatives z1_d &lt;- center.diff(z1) z2_d &lt;- center.diff(z2) z3_d &lt;- center.diff(z3) z4_d &lt;- center.diff(z4) z5_d &lt;- center.diff(z5) z6_d &lt;- center.diff(z6) #Graphs graph_colors &lt;- c(&quot;black&quot;,&quot;blue&quot;,&quot;darkred&quot;,&quot;darkgreen&quot; ,&quot;darkgoldenrod&quot;,&quot;gray&quot;,&quot;red&quot;) par(mfrow=c(1,2), oma=c(0.1,0.1,0.1,0.1), mar=c(3,4,3,1)) plot(x, z1 ,type = &quot;l&quot;, ylim =c(0,1.5), xlab=&quot;Age&quot;, ylab=&quot;Average frailty (z)&quot;) lines(x, z2, col=graph_colors[2]) lines(x, z3, col=graph_colors[3]) lines(x, z4, col=graph_colors[4]) lines(x, z5, col=graph_colors[5]) lines(x, z6, col=graph_colors[6]) legend (&quot;topright&quot;, legend = round(sigma.sq1, 3),col=graph_colors, lty=rep(1,6), ncol = 2) plot(x, z1_d ,type = &quot;l&quot;, lty=1, ylim =c(-1/12, 2/12), xlab=&quot;Age&quot;, ylab=&quot;D(Average frailty (z))/dage&quot;) lines(x, z2_d, col=graph_colors[2]) lines(x, z3_d, col=graph_colors[3]) lines(x, z4_d, col=graph_colors[4]) lines(x, z5_d, col=graph_colors[5]) lines(x, z6_d, col=graph_colors[6]) abline(h= b, col= graph_colors[7]) legend (&quot;topright&quot;, legend = c(round(sigma.sq1, 3),&quot;b&quot;),col=graph_colors, lty=rep(1,7) ,ncol = 2) Figure 4.12: Average frailty by age Obtain from the Human Mortality Database a schedule of single-year-of-age, cohort mortality rates for females born in 1880 in Italy. Use the “inversion formula” for the gamma distribution to obtain the baseline hazards implied by \\(\\sigma^2= 1/7\\). Plot the observed and implied baseline schedule. Plot the average frailty by age. Do your results resemble or differ from the Gompertz case above ? In order to get the baseline hazards implied by \\(\\sigma^2\\) = 1/7, we can use the inversion formula \\[\\mu_0 (x) = \\bar{\\mu}(x)e^{\\sigma^2\\bar{H}(x)}\\] Taking logs, this gives us \\[log(\\mu_0 (x)) = log(\\bar{\\mu}(x))+{\\sigma^2log(\\bar{H}(x))}\\] \\(H(x)\\) is equal to the summation of \\(\\mu(x)\\) in continuous time, so we can take the cumulative sum of these mortality rates to get the cumulative hazards. We can then use this to calculate the baseline hazards schedule. italy2 &lt;- read_table2(&quot;data/italycMx_1x1.txt&quot;, skip=2) %&gt;% filter(Year == 1880) %&gt;% select(Year, Age, Female) italy2$Age[italy2$Age == &quot;110+&quot;] &lt;- 110 italy2$mux &lt;- as.numeric(italy2$Female) sigma.sq.it &lt;- 1/7 italy2$H0 &lt;- cumsum(italy2$mux) italy2$Hbar &lt;- (1/sigma.sq.it)*log(1+sigma.sq.it*italy2$H0) italy2$mu0 &lt;- log(italy2$mux)+sigma.sq.it*italy2$Hbar plot(italy2$Age, log(italy2$mux), type = &quot;l&quot;, xlab = &quot;Age&quot;, ylab = &quot;Hazards&quot;) lines(italy2$Age, italy2$mu0, col = &quot;red&quot;, lty = 2) legend(&quot;topleft&quot;,legend = c(&quot;Observed&quot;, &quot;Implied&quot;), lty = c(1,2)) Figure 4.13: Observed and implied hazards Now let’s plot average frailty by age. While the shape of the mean frailty graph is the same in both cases, average frailty seems to decline more rapidly here than in the Gompertz case (this is driven by early ages.) italy2$zbar &lt;- (1/(1+sigma.sq.it*italy2$H0)) plot(italy2$Age, italy2$zbar, type = &quot;l&quot;, xlab = &quot;Age&quot;, ylab = &quot;Average frailty&quot;) Figure 4.14: Observed and implied hazards Derive V&amp;M ’s result (5E) Since \\(\\mu_2(x) = R\\mu_1(x)\\) and frailty is distributed gamma with variances \\(\\sigma_1^2\\) and \\(\\sigma_2^2\\), respectively, we can rewrite \\[\\bar{R}(x) = \\frac{\\bar{\\mu_2}(x)}{\\bar{\\mu_1(x)}}\\] as \\[\\begin{aligned} \\bar{R}(x) &amp; = {\\mu_2(x) \\over 1+\\sigma^2_2H_2(x)} \\times{1+H_1(x)\\sigma^2_1 \\over \\mu_1(x)} \\\\ &amp; = { \\bar{\\mu}_2(x) \\over \\bar{\\mu}_1(x) }\\times { 1+H_1(x)\\sigma^2_1 \\over 1+H_2(x)\\sigma^2_2 } \\end{aligned}\\] Since \\(H_2 = R*H_1\\), \\[\\begin{aligned} &amp; = {R} \\times { 1+\\sigma^2_1 H_1(x) \\over 1+R\\sigma^2_2 H_1(x) }\\\\ &amp; = { R+R\\sigma^2_1 H_1(x) \\over 1+R\\sigma^2_2 H_1(x) } \\end{aligned}\\] Use mathematics to say what the determinants of the age of crossover are in terms of the respective frailty variances, R, and a baseline Gompertz schedule. The age crossover occurs at \\(\\bar{u_1} = \\bar{u_2}\\), which occurs at \\(\\bar{R} = 1\\). Rearranging 5E after equating it to 1 gives us \\[1+R\\sigma_2^2(H_1(x_c)) = R+R\\sigma_1^2(H_1(x_c))\\] \\[H_1(x_c)(R\\sigma_1^2 - R\\sigma_2^2) = 1-R\\] \\[H_1(x_c) = { R -1 \\over R(\\sigma_2^2 - \\sigma_1^2)}\\] Assuming a baseline hazard schedule \\(H_1(x)\\) that is Gompertzian, we can solve to get the age of crossover \\(x_c\\). \\[ \\begin{aligned} {a \\over b}(e^{bx_c} -1) &amp; = { R -1 \\over R(\\sigma_2^2 - \\sigma_1^2)} \\\\ x_c &amp; = {1 \\over b} \\log \\bigg({ {(b/a)(R-1)}\\over R(\\sigma^2_2-\\sigma^2_1)} +1\\bigg) \\end{aligned}\\] Simulate this cross over with two proportional Gompertz schedules, with different frailty variances. Can you get a cross-over? If so, does it occur when cumulative hazard satisfy the condition (in small font) at the end of 5E? We borrow the frailty simulation function from problem set 2 and use it to create two schedules with Gamma frailty distributions (with different variances) and where the scales of the gompertz curves are proportional. source(&quot;functions/gomp_funs.R&quot;) source(&quot;functions/frailty_sim_function.R&quot;) #Let&#39;s choose different variances for the two Gompertz schedules. sigmasq.1 &lt;- 0.02 sigmasq.2 &lt;- 0.25 N &lt;- 1000000 #Now let&#39;s generate the zs for this using the rgamma function. z1 &lt;- rgamma(N, shape = 1/sigmasq.1, scale = sigmasq.1) z2 &lt;- rgamma(N, shape = 1/sigmasq.2, scale = sigmasq.2) #Since these are proportional Gompertzian schedules, they will have the same b but different alphas, scaled by R beta1 &lt;- 1/9 alpha1 &lt;- 10^-4 R &lt;- 1.5 schedule1 &lt;- frailty_sim(N, z1, base.a = alpha1, base.b =beta1) schedule2 &lt;- frailty_sim(N, z2, base.a = R*alpha1, base.b =beta1) Now we can graph this to observe the crossover. In Problem 4, we calculate an age where this crossover would occur based on 5E, and here, graphing that line in grey, we see that the crossover occurs at exactly that point. x.crossover &lt;- (1/beta1)*log( (((beta1/alpha1)*(R-1)) / (R*(sigmasq.2-sigmasq.1))) - 1 ) plot(schedule1$frailty$x, log(schedule1$frailty$mx), main = &quot;Crossover in Log Hazards&quot;, type = &quot;l&quot;, lty = 1, lwd = 2, col = &quot;black&quot;, xlab = &quot;Age&quot;, ylab = &quot;log hx&quot;) lines(schedule2$frailty$x, log(schedule2$frailty$mx), type = &quot;l&quot;, col = &quot;red&quot;, lty = 1, lwd = 2) #abline(v = x.crossover, col =&quot;gray&quot;, lty = 2) legend(x = 5, y = -1, title = &quot;Variance&quot;, legend = c(&quot;0.25&quot;, &quot;0.02&quot;), col = c(&quot;black&quot;, &quot;red&quot;), lwd = 2,lty = 1) Figure 4.15: Mortality crossover Use simulation to say what the determinants of the age of crossover are in terms of the respective frailty variances, R, and the baseline Gompertz schedule. If we alter any of the parameters here, it would change the age of crossover in accordance with that observed in Problem 4. We can simulate this by writing the previous code as a function and running it with different parameters. get.crossover.plot &lt;- function( N, sigmasq.1.fun, sigmasq.2.fun, beta.fun, alpha.fun, R.fun) { #Now let&#39;s generate the zs for this using the rgamma function. z1.fun &lt;- rgamma(N, shape = 1/sigmasq.1, scale = sigmasq.1) z2.fun &lt;- rgamma(N, shape = 1/sigmasq.2, scale = sigmasq.2) #Since these are proportional Gompertzian schedules, they will have the same b but different alphas, scaled by R #We can use the frailty simulation function from now onwards schedule1 &lt;- frailty_sim(N, z1.fun, base.a = alpha.fun, base.b =beta.fun) schedule2 &lt;- frailty_sim(N, z2.fun, base.a = R*alpha.fun, base.b =beta.fun) #Crossover plots plot(schedule1$frailty$x, log(schedule1$frailty$mx), type = &quot;l&quot;, lty = 1, lwd = 2, col = &quot;black&quot;, xlab = &quot;Age&quot;, ylab = &quot;log hx&quot;) lines(schedule2$frailty$x, log(schedule2$frailty$mx), type = &quot;l&quot;, col = &quot;red&quot;, lty = 1, lwd = 2) legend(&quot;topleft&quot;, title = &quot;Variance&quot;, legend = c(sigmasq.1.fun, sigmasq.2.fun ), col = c(&quot;black&quot;, &quot;red&quot;), lwd = 2,lty = 1) mtext(paste0(&quot;R= &quot;, R.fun,&quot; Base a = &quot;, alpha.fun, &quot; Base b = &quot;, round(beta.fun,2) ), side=3) } Now let’s run this for different values of alpha, beta, R, and the two variances. In the first set of graphs, changing the two variances to compare when they are very different and when they are very similar. Age of crossover does not seem to change very much. N &lt;- 1000000 par(mfrow = c(1,2)) get.crossover.plot(N, sigmasq.1.fun = 0.001, sigmasq.2.fun = 0.7, alpha.fun = 10^-4, beta.fun = 1/9 , R.fun = 1.6 ) get.crossover.plot(N, sigmasq.1.fun = 0.3, sigmasq.2.fun = 0.25, alpha.fun = 10^-4, beta.fun = 1/9 , R.fun = 1.6 ) Figure 4.16: Crossover: changing variances Then, when changing alpha so that we can compare a very small alpha with a large one, a crossover occurs earlier with a larger value. par(mfrow = c(1,2)) get.crossover.plot(N, sigmasq.1.fun = 0.03, sigmasq.2.fun = 0.25, alpha.fun = 10^-6, beta.fun = 1/9 , R.fun = 1.6 ) get.crossover.plot(N, sigmasq.1.fun = 0.03, sigmasq.2.fun = 0.25, alpha.fun = 10^-3, beta.fun = 1/9 , R.fun = 1.6 ) Figure 4.17: Crossover: changing Gompertz \\(a\\) parameter By changing beta to compare a very small beta and a large one, we get a crossover very early with a large beta. par(mfrow = c(1,2)) get.crossover.plot(N, sigmasq.1.fun = 0.03, sigmasq.2.fun = 0.25, alpha.fun = 10^-4, beta.fun = 1/20 , R.fun = 1.6 ) get.crossover.plot(N, sigmasq.1.fun = 0.03, sigmasq.2.fun = 0.25, alpha.fun = 10^-4, beta.fun = 1/4 , R.fun = 1.6 ) Figure 4.18: Crossover: changing Gompertz \\(b\\) parameter Finally, if we compare a large and small r, there does not seem to be a difference in the crossover ages. par(mfrow = c(1,2)) get.crossover.plot(N, sigmasq.1.fun = 0.03, sigmasq.2.fun = 0.25, alpha.fun = 10^-4, beta.fun = 1/9 , R.fun = 0.7) get.crossover.plot(N, sigmasq.1.fun = 0.03, sigmasq.2.fun = 0.25, alpha.fun = 10^-4, beta.fun = 1/9 , R.fun = 2.0) Figure 4.19: Crossover: changing \\(R\\) Get two Italian cohorts 20 years apart and calculate the rate of mortality improvement by age \\(\\rho(x)\\) that you observe and that which you would have observed had there been no frailty. For frailty, assume gamma-distributed with \\(\\sigma^2 = 1/5\\). We obtain the Italian cohort female lifetable (1x1) from the Human Mortality Database (HMD). italy &lt;- read_table2(&quot;data/italy_fltcoh_1x1.txt&quot;, skip=1) %&gt;% #HMD Italy cohort data, female lifetable (1x1) filter(Year == 1880|Year == 1900) italy$Age[italy$Age == &quot;110+&quot;] &lt;- 110 italy$Age &lt;- as.numeric(italy$Age) italy$mx &lt;- as.numeric(italy$mx) italy$lx &lt;- italy$lx/100000 italy &lt;- italy %&gt;% select(Year, Age, mx, lx) italy1880 &lt;- italy %&gt;% filter(Year == 1880) #1880 cohort italy1900 &lt;- italy %&gt;% filter(Year == 1900) #1900 cohort The observed rate of mortality improvement can be calculated using \\[ \\bar{\\rho}(x,t) = - {1 \\over t} \\log {m_{t2}(x) \\over m_{t1}(x) }\\] and the version with frailty can be calculated using: \\[ \\rho(x,t) = \\bar{\\rho}(x,t) + \\sigma^2\\ {d \\over dt}\\bar{S}_c (x,t) \\] Now we can calculate the rates of improvement in mortality and compare them. When we assume frailty, we get a higher rate of improvement at the older ages than in the observed case. sigma.sq.ct &lt;- 1/5 ages &lt;- 0:110 rho_bar &lt;- (-1/20)*log(italy1900$mx/italy1880$mx) #hazard component sc_bar &lt;- (1/20)*log(italy1900$lx/italy1880$lx) #survivorship component rho &lt;- rho_bar+sigma.sq.ct*sc_bar plot(ages, rho_bar, type = &quot;l&quot;, lty = 1, xlab = &quot;Age&quot;, ylab = &quot;Mortality Improvement Rate&quot;) lines(ages, rho, lty = 2, col = &quot;red&quot;) legend(&quot;topright&quot;, legend = c(&quot;Observed&quot;, &quot;With Frailty&quot;), lty = c(1,2), col = c(&quot;black&quot;, &quot;red&quot;)) title(&quot;Mortality Improvement for the Cohorts of 1880 and 1900&quot;) Figure 4.20: Mortality improvement Extend the CenSoc demonstration of changing characteristics with age in at least one of the following ways Use years of education instead of wage income. Use both years of education and wage income. Analyze Blacks and Whites separately using wage income? Is the variance of “observed heterogeneity” (\\(\\hat{z}_{obs}\\)) larger for one group. Discuss briefly. dt &lt;- fread(&quot;/data/josh/CenSoc/working_files/censoc_dmf_demo.csv&quot;) # censoc &lt;- fread(&quot;/data/josh/CenSoc/working_files/censoc_dmf_demo.csv&quot;) # write.csv(censoc, file=&quot;data/censoc_dmf_demo&quot;) #Death and age variables dt[, age.at.death := dyear + dmonth/12 - (byear + bmonth/12)] dt &lt;- dt[byear %in% 1895:1900 &amp; dyear %in% 1975:2004,] dt &lt;- dt[age.at.death &lt; 105] #Education variables dt &lt;- dt[!is.na(educyrs)] dt[, y_orig_educ := educyrs] dt[, educyrs_mean := mean(educyrs), by = byear] dt[, y_educ := educyrs - educyrs_mean] x &lt;- 74:104 y.bar.educ &lt;- NULL y_orig.bar.educ &lt;- NULL for (i in 1:length(x)){ y.bar.educ[i] &lt;- dt[age.at.death &gt; x[i], mean(y_educ)] y_orig.bar.educ[i] &lt;- dt[age.at.death &gt; x[i], mean(y_orig_educ)] } #Income variables dt[incwage == 999998, incwage := NA] dt[incwage == 0, incwage := NA] dt &lt;- dt[!is.na(incwage)] dt[, y_orig_inc := incwage] dt[, log_inc := log(incwage)] dt[, log_inc_mean := mean(log_inc), by = byear] dt[, y_inc := log_inc - log_inc_mean] Let’s see how this changes for education. The easiest way to compare both income and education is to compare income (on the y-axis) while letting education vary. For simplicity we took 4 education bins: 0-5 years, 5-10 years, 10-15 years and more than 15 years: as well as their standardized analoges. The intensity of colors increases with the number of years of education. x &lt;- 74:104 y_std.bar.both1 &lt;- NULL y_std.bar.both2 &lt;- NULL y_std.bar.both3 &lt;- NULL y_std.bar.both4 &lt;- NULL y_orig.bar.both1 &lt;- NULL y_orig.bar.both2 &lt;- NULL y_orig.bar.both3 &lt;- NULL y_orig.bar.both4 &lt;- NULL for (i in 1:length(x)) { #Original y_orig.bar.both1[i] &lt;- dt[age.at.death &gt; x[i] &amp; educyrs&gt;=0 &amp; educyrs &lt;5 , mean(y_orig_inc)] y_orig.bar.both2[i] &lt;- dt[age.at.death &gt; x[i] &amp; educyrs&gt;=5 &amp; educyrs &lt;10, mean(y_orig_inc)] y_orig.bar.both3[i] &lt;- dt[age.at.death &gt; x[i] &amp; educyrs&gt;=10 &amp; educyrs &lt;15, mean(y_orig_inc)] y_orig.bar.both4[i] &lt;- dt[age.at.death &gt; x[i] &amp; educyrs &gt;=15, mean(y_orig_inc)] #Standardized y_std.bar.both1[i] &lt;- dt[age.at.death &gt; x[i] &amp; y_educ &gt;= -10 &amp; y_educ &lt; -5, mean(y_inc)] y_std.bar.both2[i] &lt;- dt[age.at.death &gt; x[i] &amp; y_educ &gt;= -5 &amp; y_educ &lt;0, mean(y_inc)] y_std.bar.both3[i] &lt;- dt[age.at.death &gt; x[i] &amp; y_educ &gt;= 0 &amp; y_educ &lt;5, mean(y_inc)] y_std.bar.both4[i] &lt;- dt[age.at.death &gt; x[i] &amp; y_educ &gt;= 5, mean(y_inc)] } par(mfrow = c(1,2)) colors &lt;- gray((4:0)/5) plot(x, y_orig.bar.both1, col=colors[1], ylim=c(min(y_orig.bar.both1), max(y_orig.bar.both4)), type=&quot;l&quot;, ylab = &quot;log wage&quot;, xlab = &quot;Age at death&quot;) lines(x, y_orig.bar.both2, col=colors[2]) lines(x, y_orig.bar.both3, col=colors[3]) lines(x, y_orig.bar.both4, col=colors[4]) title(&quot;Education and wage by surviving age&quot;, cex.main = .7) plot(x, y_std.bar.both1, col=colors[1], ylim=c(-2,2), type=&quot;l&quot;, ylab = &quot;standardized log wage&quot;, xlab = &quot;Age at death&quot;) lines(x, y_std.bar.both2, col=colors[2]) lines(x, y_std.bar.both3, col=colors[3]) lines(x, y_std.bar.both4, col=colors[4]) title(&quot;Education and wage by surviving age&quot;, cex.main = .7) We’ll run the wage income comparison for Blacks and Whites separately. dt.new &lt;-dt x &lt;- 74:104 y.bar.inc.white &lt;- NULL y_orig.bar.inc.white &lt;- NULL dt.white &lt;-dt.new[race == &quot;White&quot;] for (i in 1:length(x)) { y.bar.inc.white[i] &lt;- dt.white[age.at.death &gt; x[i], mean(y_inc)] y_orig.bar.inc.white[i] &lt;- dt.white[age.at.death &gt; x[i], mean(y_orig_inc)] } x &lt;- 74:104 y.bar.inc.black &lt;- NULL y_orig.bar.inc.black &lt;- NULL dt.black &lt;-dt.new[race== &quot;Black/African American&quot;] for (i in 1:length(x)) { y.bar.inc.black[i] &lt;- dt.black[age.at.death &gt; x[i], mean(y_inc)] y_orig.bar.inc.black[i] &lt;- dt.black[age.at.death &gt; x[i], mean(y_orig_inc)] } Now let&#39;s graph these two. We can see a decline in log wages with age for Blacks that we do not observe for Whites, for whom this tends to increase by age. This suggests that we may observe greater variance in heterogeneity for blacks than for Whites. par(mfrow = c(1,2)) plot(x, y_orig.bar.inc.white, type=&quot;l&quot;, ylab = &quot;log wage&quot;, xlab = &quot;Age at death&quot;) title(&quot;Wage income by surviving age: Whites&quot;, cex.main = .7) plot(x, y.bar.inc.white, type=&quot;l&quot;, ylab = &quot;standardized log wage&quot;, xlab = &quot;Age at death&quot;) title(&quot;Standardized log wages by surviving age: Whites&quot;, cex.main = .7) par(mfrow = c(1,2)) plot(x, y_orig.bar.inc.black, type=&quot;l&quot;, ylab = &quot;log wage&quot;, xlab = &quot;Age at death&quot;) title(&quot;Wage income by surviving age: Blacks&quot;, cex.main = .7) plot(x, y.bar.inc.black, type=&quot;l&quot;, ylab = &quot;standardized log wage&quot;, xlab = &quot;Age at death&quot;) title(&quot;Standardized log wages by surviving age: Blacks&quot;, cex.main = .7) "],
["convergence-and-cross-overs.html", "Chapter 5 Convergence and cross-overs 5.1 Outline 5.2 What happens to mortality disparities at older ages? 5.3 Student Presentation", " Chapter 5 Convergence and cross-overs 5.1 Outline Concepts Student Presentation Additional resources: Coale and Kisker (1986): Non-technical overview of data issues that could create the appearance of mor-tality cross-overs. Manton and Stallard (1981): interesting discussion on parameter choice of the Gamma and the empirical results. 5.2 What happens to mortality disparities at older ages? Cumulative disadvantage Age as a leveler Individual adaptation/plasticity, gov support, separation from unequal structures like labor market Bad data / measurement Unreliable ages, institutionalization changes sample, etc. Nothing It’s all selection (“frailty”), pop hazards but individual hazards would have remained “parallel”. Our goal is to examine this last “null hypothesis”. What can frailty explain, and what can’t it 5.2.1 A possible null-model 2 groups, each with internal gamma-frailty proportional baseline hazards \\[ \\mu_2(x) = R \\mu_1(x) \\] see Vaupel and Missov (2014) (Eq 38) \\[ \\mu_1(x |z_1) = \\mu_1 z_1 \\\\ \\mu_2(x |z_2) = \\mu_2 z_2 \\] And, frailty terms are each gamma, with mean 1 and own variances. 5.2.2 A result: (5E - Vaupel and Missov (2014) (Eq 38)) \\[ \\bar{R}(x) \\equiv {\\bar\\mu_2(x) \\over \\bar\\mu_1(x)} = {R + R\\sigma_1^2 H_1(x) \\over 1 + R \\sigma_2^2 H_1(x)} \\] Questions: If variances are equal. What happens at age 0? What happens at very old ages? If the higher mortality group has bigger frailty variance. What happens at older ages? If higher mortality group has smaller frailty variance? What happens at older ages? Homework: prove this, simulate this. see if cross of is when cumulative hazards satisfy the condition at the end of 5E). (* problem. can you solve for x0 in temrs of variances 1 and 2 and R with gamma gompertz? 5.2.3 Inversion Given observed hazards, how do we get baseline? (Impossible without assumptions; but what if we have gamma-frailty with \\(\\sigma^2\\)?) Our challenge is to invert a not easy pop hazards formula \\[ \\bar{\\mu}(x) = {\\mu_0(x) \\over 1 + \\sigma^2 H_0(x)} \\] because we have both hazards and cumulative hazards on right. A solution: Hazards are slope of log survival Therefore, recall for Gamma, \\[ \\bar{S}(x) = { 1 \\over (1 + \\sigma^2 H_0(x))^{1/\\sigma^2}} \\] We write down the hazard as the derivative of log survival \\[ \\bar{\\mu}(x) = {1 \\over \\sigma^2} {d \\over dx} \\log(1 + \\sigma^2 H_0(x)). \\] The anti-derivative of both sides, gives \\[ \\bar{H}(x) = {1 \\over \\sigma^2} \\log(1 + \\sigma^2 H_0(x)). \\] And now we have only 1 expression involving the baseline hazards on the right. Solving \\[ \\bar{H}(x) = {1 \\over \\sigma^2} \\log(1 + \\sigma^2 H_0(x)). \\] gives us the cumulative hazard \\[ H_0(x) = {1 \\over \\sigma^2} \\left(e^{\\sigma^2 \\bar{H}(x)} - 1 \\right). \\] And differencing, gives us a remarkably simple expression for the baseline hazard in terms of the observed popualtion hazard \\[ \\mu_0(x) = \\bar\\mu(x) e^{\\sigma_2 \\bar{H}(x)} \\] We don’t observe underlying baseline hazard \\(\\mu_0\\) on left What is observed (and unobserved) on right? 5.2.4 An example library(data.table) dt &lt;- fread(&quot;/hdir/0/fmenares/Book/bookdown-master/data/ITA.cMx_1x1.txt&quot;, na.string = &quot;.&quot;) my.dt &lt;- dt[Year == 1915] my.dt[, H.f := cumsum(Female)] my.dt[, H.m := cumsum(Male)] my.dt[, h.f := Female] my.dt[, h.m := Male] sigma.sq &lt;- .5^2 my.dt[, h0.f.5 := h.f * exp(sigma.sq *H.f)] my.dt[, h0.m.5 := h.m * exp(sigma.sq *H.m)] sigma.sq &lt;- .2^2 my.dt[, h0.f.2 := h.f * exp(sigma.sq *H.f)] my.dt[, h0.m.2 := h.m * exp(sigma.sq *H.m)] sigma.sq &lt;- 1^2 my.dt[, h0.f1 := h.f * exp(sigma.sq *H.f)] my.dt[, h0.m1 := h.m * exp(sigma.sq *H.m)] par(mfrow = c(1,2)) foo &lt;- my.dt[, plot(Age, H.f, col = &quot;red&quot;)] title(&quot;Cumulative Hazards\\n Italian Females born 1915&quot;) foo &lt;- my.dt[, plot(Age, log(h.f), type = &quot;l&quot;, ylim = c(-7, 2), col = &quot;red&quot;, main = &quot;Observed vs. implied baseline&quot;)] foo &lt;- my.dt[, lines(Age, log(h0.f.2), lty = 2, col = &quot;red&quot;)] foo &lt;- my.dt[, lines(Age, log(h0.f.5), lty = 3, col = &quot;red&quot;)] foo &lt;- my.dt[, lines(Age, log(h0.f1), lty = 4, col = &quot;red&quot;)] legend(&quot;topleft&quot;, legend = c(&quot;baseline&quot;, &quot;obs if s2 = .2^2&quot;, &quot;obs if s2 = .5^2&quot;, &quot;obs if s2 = 1^2&quot;), col = &quot;red&quot;, lty = 1:4) Figure 5.1: Italian Females vs Males, born 1915 \\(\\sigma^2=.5^2=.2^2=1^2\\) par(mfrow = c(1,2)) ## title(&quot;Cumulative Hazards\\n Italian Females born 1915&quot;) foo &lt;- my.dt[, plot(Age, log(h.f), type = &quot;l&quot;, ylim = c(-7, 2), col = &quot;red&quot;, main = &quot;Observed vs. implied baseline&quot;)] foo &lt;- my.dt[, lines(Age, log(h0.f.5), lty = 2, col = &quot;red&quot;)] ugh &lt;- my.dt[, lines(Age, log(h.m), type = &quot;l&quot;, col = &quot;blue&quot;)] ugh &lt;- my.dt[, lines(Age, log(h0.m.5), lty = 2, col = &quot;blue&quot;)] legend(&quot;topleft&quot;, legend = c(&quot;female observed&quot;, &quot;female baseline&quot;, &quot;male observed&quot;, &quot;male baseline&quot;), col = c(&quot;red&quot;,&quot;red&quot;, &quot;blue&quot;, &quot;blue&quot;), lty = c(1,2, 1,2)) ## now do difference foo &lt;- my.dt[, plot(Age, h.m/h.f, type = &quot;l&quot;, col = &quot;black&quot;, ylab = c(&quot;h.m/h.f&quot;), main = &quot;Male-female hazard ratio&quot;)] foo &lt;- my.dt[, lines(Age, h0.m.5/h0.f.5, lty = 2)] legend(&quot;topright&quot;, legend = c(&quot;observed&quot;, &quot;implied baseline&quot;), ## col = c(&quot;red&quot;,&quot;blue&quot;), lty = 1:2) Figure 5.2: Italian Females vs Males, born 1915 \\(\\sigma^2=.5^2\\) Much bigger convergence in “observed” than in baseline 5.2.5 Application German Rodriguez App for Black-White Crossover 5.3 Student Presentation References "],
["mortality-plateaus.html", "Chapter 6 Mortality plateaus 6.1 Outline 6.2 Heterogeneity slows mortality improvement 6.3 Conclusions 6.4 Hazards and Plateaus by Professor Ken Wachter 6.5 Key points", " Chapter 6 Mortality plateaus 6.1 Outline Mathematical background Ken’s class Presentation 6.2 Heterogeneity slows mortality improvement Define \\(\\rho(x,t)\\) be the rate of mortality \\[ \\rho(x,t) = - {d \\over dt} \\log \\bar\\mu(x,t) \\] Extending our gamma result for 1 cohort to the surface, \\[ \\bar\\mu(x,t) = \\mu_0(x,t) \\bar{S}_c(x,t)^{\\sigma^2} \\] We take the log and the time-derivative of hazards give Vaupel and Missov (2014) (Eq. 39*) \\[ \\rho(x,t) = \\rho_0(x,t) - \\sigma^2 {d \\over dt} \\log \\bar{S}_c(x,t)^{\\sigma^2} \\] Note: this formula should be correct. Vaupel and Missov (2014) contains a mistake: an extra minus sign in the definition of \\(\\bar{S}_c(x,t)\\). We take the log and the time-derivative of hazards give Vaupel and Missov (2014) (Eq. 39*) \\[ \\rho(x,t) = \\rho_0(x,t) - \\sigma^2 {d \\over dt} \\log \\bar{S}_c(x,t) \\] So individual risks from one cohort to the next are going down faster it seems. Intuition? Reversing perspective, \\[ \\rho_0(x,t) = \\rho(x,t) + \\sigma^2 {d \\over dt} \\log \\bar{S}_c(x,t) \\] 6.2.1 An example Assume \\(\\sigma^2 = .2\\). library(data.table) sigma.sq = .2 dt &lt;- fread(&quot;/hdir/0/fmenares/Book/bookdown-master/data/ITA.bltcoh_1x1.txt&quot;, na.string = &quot;.&quot;) mx.80.c1880 &lt;- dt[Year == 1880 &amp; Age == &quot;80&quot;]$mx mx.80.c1900 &lt;- dt[Year == 1900 &amp; Age == &quot;80&quot;]$mx (rho.bar.80 &lt;- -log(mx.80.c1900/mx.80.c1880)/20) ## about 0.8% ## [1] 0.008729961 Sx.80.c1880 &lt;- dt[Year == 1880 &amp; Age == &quot;80&quot;]$lx Sx.80.c1900 &lt;- dt[Year == 1900 &amp; Age == &quot;80&quot;]$lx (d.log.Sx &lt;- log(Sx.80.c1900/Sx.80.c1880)/20) ## [1] 0.02177952 (rho.0.80 = rho.bar.80 + sigma.sq * d.log.Sx) ## about 1.3% ## [1] 0.01308586 So individual-level mortality progress is nearly 50% faster (1.3% vs. 0.9%) than it appears! 6.3 Conclusions Gamma frailty gives simple expressions for population survival, hazard, and average frailty. Gamma frailty gives a plateau. Gamma frailty gives us a predicted rate of convergence and cross-over with age. All of this means it is a useful null model. Takes us away from “it could be selection” to “what if it were selection”. 6.4 Hazards and Plateaus by Professor Ken Wachter 6.4.1 Outline Extremes of Longevity in Humans and Other Species Gamma-Gompertz Fixed Frailty Hazards Less Restrictive Frailty Models Mutation Accumulation, Gompertz Hazards with Plateaus Note: we thank Professor Kenneth Wachter for letting us use the presentation and code from his class on Hazards and Plateaus on February 20, 2020 at Demography UC Berkeley. 6.4.2 Extremes of Longevity in Humans and Other Species Figure 6.1: Estimated plateau for cohort of Italian women from 1904. Source: Barbi et al. (2018) What is the importance of plateaus? They encourage optimism that future progress against old-age mortality is feasible. Our bodies are not facing an endlessly mounting set of things going wrong. They point to commonalities with the life-course demography of other species. The shared genetic heritage of advanced organisms is permissive. For instance, we can compare human hazard to that of other species: Figure 6.2: Hazards across selected species. Source: Horiuchi (2003) 6.4.3 Gamma-Gompertz Fixed Frailty Hazards The Gamma-Gompertz model of Vaupel, Manton, and Stallard (1979) is familiar from this course and Chapter 8 of Essential Demographic Methods (Wachter 2014). Gamma Gompertz models are one way of generating plateaus for population hazards out of increasing individual hazards. We fit parameters to the data in Barbi et al. (2018) and look for a predicted plateau, starting from age 60 onwards. We need formulas for the individual hazard \\(h_x\\) , for the individual cumulative hazard \\(H_x\\), and for the aggregate population hazard \\(\\mu_x\\) implied by Gamma-distributed frailty with shape parameter \\(k\\) and rate parameter \\(\\theta = k\\). Does the prediction show a plateau? Does the level of the plateau fit plateau observed in the Italian cohorts over age 105? To answer these questions, we create the process below to calculate the aggregate population hazard function predicted from Gompertz hazards for individuals combined with a Gamma distribution for fixed proportional frailty, using parameters matched to the Italian cohort data for Barbi et al. (2018). # Parameters for Gompertz and Gamma beta &lt;- 0.088 # Gompertz slope parameter, Barbi et al. alpha60 &lt;- 0.01340671 # Gompertz intercept parameter at age 60 asymp &lt;- 0.620 # Observed asymptote, for comparisons in plots khat &lt;- 7.045455 # Gamma shape parameter, to fit plateau theta &lt;- 1/khat # Gamma rate parameter, for unit mean at 60 # Age range, starting to observe cohorts at age 60, reaching up to 130 xxx &lt;- c(0:200) # set of values of x, years past 60 age &lt;- 60 + xxx # age # Hazards: ### Gompertz formula to calculate individual hazards hx at x: hx &lt;- alpha60 *exp(beta*xxx) ##also noted as mu_0(x) in course material ### Individual cumulative hazard Hx formula Hx &lt;- cumsum(hx) ## another way of getting it is (a/b)(exp(bx)-1) ### Aggregate population hazard mu_x with Gamma frailty: mux &lt;- hx *khat/ (khat + Hx) #Plot: plot(age, log(hx), type= &quot;l&quot;, col=&quot;blue&quot;, xlim = c(60,130), ylim =c(min(log(hx)),4), xlab= &quot;Ages for estimated Gompertz&quot;, ylab=&quot;Log hazard&quot;) #individual hazard lines(age, log(mux), col=&quot;red&quot;) #predicted population hazard segments(x0 = 104, x1 =117, y0 = log(asymp) ) #estimated plateau from Barbi et al. legend(&quot;topleft&quot;, legend=c(expression(&quot;Individual hazard, h&quot;[x]), &quot;Predicted population hazard, &quot;~ mu [x], &quot;Plateau estimate Barbi et al. (2018)&quot;), col=c( &quot;blue&quot;,&quot;red&quot;, &quot;black&quot;), lty=rep(1,3)) Figure 6.3: Hazards and plateau with Gamma frailty Note that the x-axis shows the ages for the estimated Gompertz, that is for a population of ages 60 and above. \\(\\mu_x\\) appears to reach its own plateau due to the chosen parameters from the Gamma-Gompertz model. In this case, we get a plateau further along than in the italian case of Barbi et al. (2018). Gamma gompertz models are good at fitting plateaus mathematically but may not be aplicable with the data. 6.4.3.1 How does Gamma Gompertz Make a Plateau? Try alternative values for \\(k\\) and for \\(\\beta\\). Guess a formula for the level of the plateau. beta_vals &lt;- c(0.001, 0.1, beta, 0.5,1,10) k_vals &lt;- c(0.1, 1, 3, khat,10) plateau_beta_nolegend &lt;- function(beta_vals, k_vals){ hx &lt;- alpha60 *exp(beta_vals*xxx) ##also noted as mu_0(x) in course material Hx &lt;- cumsum(hx) ## another way of getting it is (a/b)(exp(bx)-1) mux &lt;- hx *k_vals/ (k_vals + Hx) #Plot: plot(age, log(hx), type= &quot;l&quot;, col=&quot;blue&quot;, xlim = c(60,130), ylim =c(min(log(hx)),4), xlab= &quot;Ages for estimated Gompertz&quot;, ylab=&quot;Log hazard&quot;, main=bquote(beta == .(beta_vals))) #individual hazard lines(age, log(mux), col=&quot;red&quot;) #predicted population hazard segments(x0 = 104, x1 =117, y0 = log(asymp) ) #estimated plateau from Barbi et al. } plateau_beta_legend &lt;- function(beta_vals, k_vals){ hx &lt;- alpha60 *exp(beta_vals*xxx) ##also noted as mu_0(x) in course material Hx &lt;- cumsum(hx) ## another way of getting it is (a/b)(exp(bx)-1) mux &lt;- hx *k_vals/ (k_vals + Hx) #Plot: plot(age, log(hx), type= &quot;l&quot;, col=&quot;blue&quot;, xlim = c(60,130), ylim =c(min(log(hx)),4), xlab= &quot;Ages for estimated Gompertz&quot;, ylab=&quot;Log hazard&quot;, main=bquote(beta == .(beta_vals))) #individual hazard lines(age, log(mux), col=&quot;red&quot;) #predicted population hazard segments(x0 = 104, x1 =117, y0 = log(asymp) ) #estimated plateau from Barbi et al. legend(&quot;bottomright&quot;, legend=c(expression(&quot;Individual hazard, h&quot;[x]), &quot;Predicted population hazard, &quot;~ mu [x], &quot;Plateau estimate Barbi et al. (2018)&quot;), col=c( &quot;blue&quot;,&quot;red&quot;, &quot;black&quot;), lty=rep(1,3), cex=0.7) } plateau_k_nolegend &lt;- function(beta_vals, k_vals){ hx &lt;- alpha60 *exp(beta_vals*xxx) ##also noted as mu_0(x) in course material Hx &lt;- cumsum(hx) ## another way of getting it is (a/b)(exp(bx)-1) mux &lt;- hx *k_vals/ (k_vals + Hx) #Plot: plot(age, log(hx), type= &quot;l&quot;, col=&quot;blue&quot;, xlim = c(60,130), ylim =c(min(log(hx)),4), xlab= &quot;Ages for estimated Gompertz&quot;, ylab=&quot;Log hazard&quot;, main=bquote(k == .(k_vals))) #individual hazard lines(age, log(mux), col=&quot;red&quot;) #predicted population hazard segments(x0 = 104, x1 =117, y0 = log(asymp) ) #estimated plateau from Barbi et al. } plateau_k_legend &lt;- function(beta_vals, k_vals){ hx &lt;- alpha60 *exp(beta_vals*xxx) ##also noted as mu_0(x) in course material Hx &lt;- cumsum(hx) ## another way of getting it is (a/b)(exp(bx)-1) mux &lt;- hx *k_vals/ (k_vals + Hx) #Plot: plot(age, log(hx), type= &quot;l&quot;, col=&quot;blue&quot;, xlim = c(60,130), ylim =c(min(log(hx)),4), xlab= &quot;Ages for estimated Gompertz&quot;, ylab=&quot;Log hazard&quot;, main=bquote(k == .(k_vals))) #individual hazard lines(age, log(mux), col=&quot;red&quot;) #predicted population hazard segments(x0 = 104, x1 =117, y0 = log(asymp) ) #estimated plateau from Barbi et al. legend(&quot;topleft&quot;, legend=c(expression(&quot;Individual hazard, h&quot;[x]), &quot;Predicted population hazard, &quot;~ mu [x], &quot;Plateau estimate Barbi et al. (2018)&quot;), col=c( &quot;blue&quot;,&quot;red&quot;, &quot;black&quot;), lty=rep(1,3), cex=0.7) } Here, we change the values of \\(\\beta\\) while fixing the \\(k\\) shape factor of the Gamma frailty distribution. As \\(\\beta\\) increases, the individual and population hazards rise (or shift upwards). For comparison, the third panel contains the \\(\\beta=0.088\\) and \\(k=7.045455\\) values used in the previous excercise. par(mfrow=c(2,3)) plateau_beta_nolegend(beta_vals[1],khat) plateau_beta_nolegend(beta_vals[2],khat) plateau_beta_nolegend(beta_vals[3],khat) plateau_beta_nolegend(beta_vals[4],khat) plateau_beta_legend(beta_vals[5],khat) Figure 6.4: Changing values of beta in Gompertz hazards The following graphs fix \\(\\beta=0.088\\) but use different values of \\(k\\). Contrary to what happens when \\(\\beta\\) varies, when the shape parameter of the Gamma frailty distribution changes, only the population hazards appear to change. Population hazards expand upwards with increases in \\(k\\). The fourth panel uses the baseline values for \\(\\beta=0.088\\) and \\(k=7.045455\\). par(mfrow=c(2,3)) plateau_k_nolegend(beta,k_vals[1] ) plateau_k_nolegend(beta,k_vals[2] ) plateau_k_nolegend(beta,k_vals[3] ) plateau_k_nolegend(beta,k_vals[4] ) plateau_k_legend(beta,k_vals[5] ) Figure 6.5: Changing values of k (Gamma shape parameter) This formula can be proved by showing that \\(h_{x}/H_{x}\\) goes to \\(\\beta\\) in a Gompertz model and plugging into the formula for Gamma Gompertz aggregate hazards. (Note for Josh: I don’t think Ken really explained this in class and I’m confused on how to answer this.) What happens to the mean frailty of survivors as \\(x\\) increases? What has to balance what in order for a plateau to appear? First, the mean frailty among survivors is the ratio of \\(\\mu_x\\) to \\(h_x\\). In other words, the mean frailty among the people that remain is the population hazard divided by the individual hazard. The mean frailty falls across ages, such that around 105 years, the mean frailty is about 0.5. It continues decreasing until it reaches a plateau of about 0.1 starting from age 130 onwards. Survivors past 130 have a low mean frailty but at a higher hazard, as seen by the plateau from previous graph. The plateau comes from the people that are low frailty but that die. This loss balances out the increase that everyone is experiencing. Selection is balancing senescence. plot( age, mux/hx, xlim = c(60, 200), type = &quot;l&quot; , xlab = &quot;&quot;, ylab = &quot;Mean Frailty&quot; ) abline( h = 0.5, lty = 3 ) # vertical age 105 abline( h = 0.1, lty = 3 ) # vertical age 105 Figure 6.6: Mean frailty 6.4.3.2 Troubles with Gamma Gompertz: Poor fits to observed cohort plateaus. Unrealistic mortality rates at younger ages for those who do survive out onto the plateau. (The frailty distribution reaches down to zero frailty). Individual centenarians still experience exponentially increasing hazards under the model. Why should frailty remain fixed across life? The model assumes rather than explains an underlying Gompertz. There is no full genetic or evolutionary story. 6.4.3.3 Mathematics of Frailty as a Gamma Random Variable: Probability density: \\(\\left(\\frac{\\theta^{k}}{\\Gamma(k)}\\right)z^{k-1}e^{-\\theta z}\\) Mean: \\(\\frac{k}{\\theta}\\) Variance: \\(\\frac{k}{\\theta^2}\\) \\(\\mathbb{E}e^{-ZH}= \\left(\\frac{\\theta}{\\theta H}\\right)^{k}\\) Exponential and Gamma Random Variables: When U has a uniform distribution on \\([0, 1]\\), then \\(Y = −log(U)/\\theta\\) has an exponential probability distribution on \\((0,\\infty)\\) with mean \\(1/\\theta\\) and variance \\(1/\\theta^2\\). The sum of \\(k\\) independent exponential random variables with the same mean \\(1/\\theta\\) has a gamma probability distribution with shape \\(k\\), scale \\(\\theta\\), rate \\(1/\\theta\\), mean \\(k/\\theta\\) and variance \\(k/(\\theta^2)\\). With an exponential variable Y, we have \\(\\mathbb{E}e^{-YH}=\\int e^{-yH}p(y)dy= \\frac{\\theta}{\\theta+H}\\). Because expectation values of independent random variables multiply, with a gamma variable \\(Z = Y_1 + Y_2 + · · ·Y_k\\), we have \\(\\mathbb{E}e^{-ZH}= \\left(\\frac{\\theta}{\\theta+H}\\right)^k\\). 6.4.3.4 Vaupel, Manton, and Stallard (1979) Lifelong Fixed Frailty Z. The Gamma distribution has \\(\\mathbb{E}e^{-ZH}= \\left(\\frac{\\theta}{\\theta+H}\\right)^k\\) For starting mean frailty equal to 1, we have \\(k = \\theta\\). The aggregate population hazard is minus the slope of the logarithm of survivorship: \\(\\mu_x = -\\frac{d}{dx}\\left(k log(\\theta)- k log(\\theta+H_x)\\right)= \\left(\\frac{k}{\\theta+H_x}\\right)h_x\\) For the Gamma Gompertz, we insert Gompertz individual hazards \\(h_x\\) and individual cumulative hazards \\(H_x\\) into the formula. 6.4.4 Less Restrictive Frailty Models The key property of the Gamma Gompertz model is a frailty distribution that extends all the way down to zero frailty. With any initial frailty distribution that extends down to zero and looks like a Gamma near zero, the frailty distribution among survivors comes to look like a Gamma. If you do assume a Gamma distribution for frailty, then a plateau in the aggregate population hazard function entails an individual hazard function tending toward a Gompertz. However: Frailties near zero are unrealistic. With frailties bounded away from zero, plateaus in aggregate hazards require plateaus in individual hazards Plateaus in individual hazards can arise naturally, for instance from genetic models. Consider a “semi-circle” frailty whose probability density function is, for instance, \\(p(z) = (6)(z − 0.7)(1.3 − z)\\) on \\([0.7, 1.3]\\), zero else. If the individual hazard were Gompertz, would there be a plateau? Suppose the individual hazard were given by \\(\\frac{x}{(1 + x)}\\). Would there be a plateau in the individual hazard? If so, at what level? Would there be a plateau in the aggregate population hazard? If so, at what level? We ask what genetic processes might shape individual hazards into having stretches that look Gompertz and old-age forms looking like plateaus. 6.4.5 Mutation Accumulation, Gompertz Hazards with Plateaus We turn to alternative models with plateaus in individual hazards, not just in aggregate population hazards. The genetic evolutionary theory of “mutation accumulation” suggests one story to account both for Gompertzian increases over a stretch of adult ages and for plateaus beyond them. We each inherit genetic variants or “alleles” in our DNA originating in mutations thousands of generations in the past. Picture, say, the time of the cave painters, 40,000 B.C., when people died in their 30s and 40s and 50s rather than their 70s, 80s, and 90s, losing some of their chance to bear and raise offspring. 6.4.5.1 Mutation-Selection Equilibrium Go back to basic stable (stationary) population theory. Write \\(\\rho(a)\\) for the size of the group of individuals (e.g. women) who carry a certain mutant allele indexed by the letter \\(a\\). The NRR for members of the group is assumed to be \\(1 − S(a)\\) for some small “selective cost” \\(S(a)\\) due to effects of the “deleterious” allele. In the next generation, there are \\(\\rho(a)(1 − S(a))\\) daughters. There are also \\(\\nu(a)\\) new arrivals due to new mutations. The group keeps growing until it reaches equilibrium, when losses are balanced by new arrivals, and \\(\\rho(a) = \\rho(a)(1 − S(a)) + \\nu(a)\\). Then, \\(\\rho(a)\\) as a function of \\(S(a)\\) is: \\(\\rho(a)= \\frac{\\nu(a)}{S(a)}\\) 6.4.5.2 Deleterious Alleles with Age-Specific Effects In our setting, many deaths come from external threats regardless of age, a background level of “extrinsic mortality” with constant hazard \\(\\lambda\\). To keep the story as simple as possible, picture a mutant allele that has a small bad effect on survival only at an “age of onset” \\(a\\). It raises the hazard of the individual who carries it by an amount \\(\\delta\\) in the age interval \\(a\\) to \\(a + 1\\). Picture a constant level of fertility from age 20 onward, set to make the NRR equal to 1 for women who carry no mutant alleles. Take, for example, \\(\\lambda = 0.080\\), \\(\\delta= 0.002\\), and \\(\\nu(a) = 0.020/50\\) for any \\(a \\geq 20\\). For each separate choice of age of onset \\(a\\), find and plot the equilibrium size \\(\\rho(a)\\) as a function of \\(a\\). Here, we explore a genetic process which can generate a plateau in individual hazard functions. In particular, this is the case where a harmful mutant allele increases the hazard function of those that carry such allele with onset only in a single age interval. # Parameters lambda &lt;- 0.080 # background extrinsic hazard delta &lt;- 0.002 # increment to hazard from mutant allele epsilon &lt;- 0.0005 # fixed cost nu &lt;- 0.200/50 # mutation rate per site per generation # Range of ages xxx &lt;- c(0:50) # set of values of x, years past 20, up to 70 age &lt;- 20 + xxx # age # Fertility level that makes baseline NRR equal to 1. lx &lt;- exp(-lambda*xxx) # survivorship under background hazard fert &lt;- 1/sum(lx) #total fertility or constant level of fertility # Loop over choices of an age interval a at which the mutant allele affects the hazard. bigrho &lt;- NULL # vector for holding values of rho for ( a in seq(xxx)) { hxa &lt;- lambda + 0*xxx + 0*epsilon # baseline hazard (no fixed cost) hxa[a] &lt;- hxa[a] + delta # add hazard increment in age interval a Hxa &lt;- c(0, cumsum(hxa))[seq(hxa)] lxa &lt;- exp(-Hxa) Sa &lt;- 1 - sum( fert*lxa) # S(a): Selective cost rho &lt;- nu/Sa # Rho(a) bigrho &lt;- c(bigrho, rho) } \\(\\rho(a)\\) increases exponentially, this comes from the exponential survival. This graph tells us, the number of people that survive when the mutation is triggered at a given age. So at age 70, about 1400 people survive but if the mutation hit at age 20, nobody would survive. par(mfrow=c(1,2)) plot( age, bigrho, ylab=expression(~rho(a))) plot( age, log(bigrho), ylab =expression(&quot;log&quot; ~rho(a)) ) Figure 6.7: \\(\\rho(a)\\) as a function of age 6.4.5.3 Allele Counts and Individual Hazards Suppose that the alleles carried by an individual are a random sample of the alleles present in the population, so that \\(\\rho(a)\\) can be reinterpreted as the mean number of alleles of type \\(a\\). Then the hazard for an individual at age \\(a\\) will look on average like the curve \\(\\lambda + \\rho(a) \\times \\delta\\). Does this curve resemble a Gompertz hazard? What about a Makeham hazard, that is, a Gompertz hazard plus a constant? This hazard looks like a Makeham hazard (Gompertz plus a constant). hxx &lt;- lambda + bigrho*delta plot ( age, hxx, ylim = c(0,0.500) , ylab= &quot;hazard&quot;) Figure 6.8: Hazard after exposure to allele The background intrinsic mortality \\(\\lambda\\) comes from the environment, not from the DNA. What might happen to \\(\\lambda\\) as we move from the time of the cave painters to the time of the moon landings? 6.4.5.4 Plateaus in Allele Counts Suppose, now, that each mutant allele raises the hazard by another small amount \\(\\epsilon= 0.0005\\) at all ages beyond 20, along with its special effect on raising the hazard by \\(\\delta\\) at age \\(a\\). Find and plot the size \\(\\rho(a)\\) of the carriers of a at equilibrium under this new form of action. Is there an appearance of a plateau at high ages? Is it plausible to expect some fixed cost along with an age-specific effect from mildly deleterious mutant alleles? Here is the case were a deleterious mutant allele imposes a fixed cost of size \\(\\epsilon\\) as well as adding an increment of size \\(\\delta\\) to the hazard in age interval \\(a\\). There appears to be a plateau on the survivors after the onset of the mutation at age \\(a\\) when we add a fixed cost to the mutation, even if it is happening late in the reproductive cycle. #Loop over choices of an age interval a at which the mutant allele affects the hazard with fixed cost bigrho2 &lt;- NULL # vector for holding values of rho for ( a in seq(xxx)) { hxa &lt;- lambda + 0*xxx + epsilon # baseline hazard plus fixed cost epsilon hxa[a] &lt;- hxa[a] + delta # add hazard increment in age interval a Hxa &lt;- c(0, cumsum(hxa))[seq(hxa)] lxa &lt;- exp(-Hxa) Sa &lt;- 1 - sum( fert*lxa) # Selective cost including allele at age a rho &lt;- nu/Sa # Equilibrium count of mutation a bigrho2 &lt;- c(bigrho2, rho) } par(mfrow=c(1,2)) plot( age, bigrho2, ylab=expression(~rho(a))) plot( age, log(bigrho2), ylab =expression(&quot;log&quot;~rho(a)) ) Figure 6.9: \\(\\rho(a)\\) as a function of age 6.4.5.5 Questions for Further Study What about the effect of each allele on the selective cost of all the other alleles? Looking across species, under this account would we expect some relationship between the level of extrinsic background mortality and the steepness of the slope of a Gompertz increase in mortality with age? In our calculation we let mortality over the age of 50 continue to reduce the “NRR”. Why might survival beyond ages of childbearing have an effect on generational replacement? We carry in our DNA a load of mutant alleles shaped by natural selection over hundreds and thousands of generations. Why might it be that effects of those alleles that were once lethal in mid-adult life could now be influencing rates of mortality late in life for us? 6.5 Key points Plateaus are significant information for demographers who try to predict future progress against old-age mortality. Gompertz discouragement – Plateau encouragement Gamma-Gompertz models offer one explanation for plateaus, but no explanation for Gompertz acceleration, which is simply assumed. -In frailty models, plateaus come out of the specialness of survivors. The mathematics treats mixtures of survivorship. Evolutionary genetic models aim to explain both Gompertz acceleration and old-age plateaus. In the mutation-accumulation story, plateaus are present in the hazard functions of individuals, shaped by inherited genetic load. In demography, survivorship is ALWAYS an exponential function of cumulative hazards. In genetic stories, this exponential is the source of the exponential in the Gompertz formula. The study of hazards at extreme age may inform our understanding of hazards at younger ages. References "],
["fertility-heterogeneity-tempo-distortions-and-distorted-tempo.html", "Chapter 7 Fertility Heterogeneity: Tempo Distortions and Distorted Tempo 7.1 Outline 7.2 Introduction 7.3 Period Shifts: Bongaarts and Feeney’s model 7.4 An Application to the United States 7.5 Two Americas 7.6 Conclusions 7.7 Questions 7.8 Solutions 7.9 Simulations of parents having children 7.10 The Probability Generating Function: Our mathematical tool 7.11 Extinction 7.12 Good and bad set-ups for branching process 7.13 The distribution of offspring of all generations 7.14 Geometric offspring distribution 7.15 Branching Processes and Covid-19 7.16 Problems 7.17 Solutions", " Chapter 7 Fertility Heterogeneity: Tempo Distortions and Distorted Tempo 7.1 Outline Introduction and a tempo simulation Bongaarts and Feeney’s formula An application to the United States Two Americas? EM algorithm for unmixing mixtures An application to two Americas. Additional resources: Sullivan (2005): An early paper (by a Berkeley Demog student!) focusing on ﬁrst birth hazards. Burkimsher (2017): A descriptive paper, which you can mostly skip. But see especially section 7, where she argues that her ﬁndings contradict Sullivan for the United States. Hastie, Tibshirani, and Friedman (2009): A textbook example of expectation-maximization algorithm applied to mixture of two normals in Section 8.5. Victor Lavrenko. Youtube video : “EM algorithm: how it works” https://www.youtube.com/watch?v=REypj2sy_5U. Bongaarts and Feeney (1998) 7.2 Introduction What we see is superficial. Heterogeneous models reveal what’s “really” going on. (Or do they?). Until the past sections, population hazards mislead. However in this section, homogeneous fertility misleads. We now reverse perspectives: We see differences we see in genotypes, in lineages, in names. These could be due to “real” differences (heterogeneity). But they could also be due to luck: everyone is the same but stochastic outcomes differ. Our models of individual-level randomness will have predicted dynamics, which are themselves interesting but can also be used as a “null” to compare to observations. 7.2.1 Fertility postponement, a very simple example Baseline A population has a history of 1 birth per day When women turn age 25, they have a daughter. This gives us a constant stream of births, 365 per year. Postponement Starting on Jan. 1, 2020, everyone postpones childbearing an additional month, until they are aged 25 1/12. How many births will there be in 2020? How many births in 2021? As everybody postpones childbearing for a month, then the first birth of 2020 occurs on February 1st so that 31 babies have not been born by then. This means that during 2020 there are \\(365-31=334\\) births. For this year, births and total fertility rate decrease. However, the postponement doesn’t affect the birth stream in 2021 as there will still be one birth per day, even if in the absence of postponing these some of the births should’ve occured in 2020. 7.2.2 Continuous postponement, a shiny simulation To answer these questions, we can use the following shiny app. knitr::include_url(&#39;https://shiny.demog.berkeley.edu/josh/tempo/&#39;, height = &#39;600px&#39;) \\(R(t)\\) Cumulative postponment \\(r(t)\\) Incremental postponement \\(r(t) = R&#39;(t)\\) What is a formula for recovering original birth stream? \\[\\begin{align} \\hat{B}_{orig} &amp;= B_{obs} \\times (1 + R&#39;(t)) \\\\ \\text{or}\\\\ \\hat{B}_{orig} &amp;= B_{obs} \\times 1/ \\left[1 - R&#39;(t)\\right]? \\end{align}\\] Note: this idea of ``recovering original’’ is one way to think about tempo adjustment. We can think of the original version as that which should have ocurred in the absence of postponement. Intuitively, it should be higher than the observed birth stream, but how much larger? The table below shows an example of how to recover the original births where each formula refers to the equations above. library(tidyverse) rt &lt;- seq(0.1,0.4,0.1) b_obs &lt;- c(91,84, 77, 72 ) b_orig1 &lt;- b_obs*(1+rt) b_orig2 &lt;- b_obs/(1-rt) b_orig &lt;- tibble(rt,b_obs, b_orig1, b_orig2) names(b_orig) &lt;- c(&quot;r(t)&quot;,&quot;B(obs)&quot;, &quot;B(orig) formula 1&quot;, &quot;B(orig) formula 2&quot;) knitr::kable(b_orig) %&gt;% kableExtra::kable_styling(full_width = F) r(t) B(obs) B(orig) formula 1 B(orig) formula 2 0.1 91 100.1 101.1111 0.2 84 100.8 105.0000 0.3 77 100.1 110.0000 0.4 72 100.8 120.0000 The correct formula is equation 2. NOTE: is this correct? If so, why? 7.3 Period Shifts: Bongaarts and Feeney’s model In a bigger microsimulation Each period will have births across a range of ages We’ll randomly generate the original planned birthdays Then we’ll shift by a continuous function \\(R(t)\\). The birth rate of women, \\(f(a,t)\\), aged \\(a\\) in period \\(t\\) is: \\[ f(a,t) = f_0(a - R(t)) (1- R&#39;(t)) q(t) \\] Where \\(f_0\\): constant baseline schedule (can be normalized to sum to 1). \\(q(t)\\): period intensity parameter: “quantum” \\(R(t)\\): cumulative shift. An example \\[ f(a,t) = f_0(a - R(t)) (1- R&#39;(t)) q(t) \\] \\(R_{2019} = 3\\) \\(R&#39;_{2019} = 0.1\\) \\(q(2019) = 1\\) Give an expression for \\(f(28,2019)\\) \\[ \\begin{aligned} f(28,2019) &amp;= f_{0}(28-3)\\times(1-0.1)\\times(1) \\\\ &amp; = (0.9)f_{0}(25) \\end{aligned}\\] Therefore, the fertility rate for a 28 year-old in 2019 would be 0.9 of the baseline fertility rate at age 25. Another way of thinking about it is that had there been no postponement, the fertility rate that we are observing in 2019 for this 28 year-old would actually be similar to that of a 25 year old. Small changes in the stock can have huge effect in the flows. 7.3.1 A derivation: due to Rodriguez NOTE: not sure what the reference is here Assume no quantum effects (i.e, no \\(q(t)\\)). Take a cohort with cumulative fertility \\[ F_0(a) = \\int_0^a f(x) \\,dx \\] Now put in shifts so that observed fertility is from an age \\(R(t)\\) years earlier. (“28” is the new “25”!) \\[ F(a,t) = F_0(a - R(t)) = F_0(a - R(c + a)) \\] Differentiate with respect to age (which for a cohort is also time \\(t\\)), using chain rule \\[ \\begin{aligned} \\frac{d }{dt}F(a,t)= f(a,t) &amp;= F&#39;_{0}(a-R(c+a))\\times(1-R&#39;(c+a)) \\\\ &amp;= f_0(a - R(t)) \\left[1 - R&#39;(t)\\right] \\end{aligned}\\] Let’s re-notate our constant quantum result \\[ f_0(a,t | R(t) ) = f_0(a - R(t)) \\left[1 - R&#39;(t)\\right] \\] Then we can incorporate period quantum on the shifted surface: \\[ f(a,t) = f_0(a,t | R(t) ) q(t) = f_0(a - R(t)) \\left[1 - R&#39;(t)\\right]q(t) \\] Note: If we vary quantum before shifts, then \\(q(t)\\) will bleed into neighboring years. (a small effect, but makes model messier). NOTE: I don’t understand this, could you explain Josh? 7.3.2 Tempo-adjusted TFR: counter-factual TFR in absence of timing changes \\[ TFR(t) = \\int_0^\\infty f(a,t) \\, da \\] Substituting our shifted birth rates with quantum \\[ \\begin{aligned} TFR(t) &amp;= \\int_0^\\infty f_0(a - R(t)) \\left[1 - R&#39;(t)\\right]q(t) da \\\\ &amp;=\\left[1 - R&#39;(t)\\right]q(t) \\int_0^\\infty f_0(a - R(t)) da \\\\ &amp;= TFR_0 \\left[1 - R&#39;(t)\\right] q(t)\\\\ \\end{aligned} \\] Without loss of generality, define \\(TFR_0 = 1\\), then \\[ q(t) = \\frac{TFR(t)} {1 - R&#39;(t)} \\equiv TFR^*(t) \\] The observed \\(TFR(t)\\) deflated by the rate of change (\\(1 - R&#39;(t)\\)) is the BF formula. How do period schedules change? \\[ f(a,t) = f_0(a - R(t)) \\left[1 - R&#39;(t)\\right]q(t) \\] What is \\({\\partial \\over \\partial t} \\log f(a,t)\\)? Solving \\[ \\begin{aligned} {\\partial \\over \\partial t} \\log f(a,t) &amp; = \\frac{d}{dt}log(f_{0}(a-R(t))) + \\frac{d}{dt}log(1-R&#39;(t)) + \\frac{d}{dt}log(q(t)) \\\\ &amp; = \\frac{-f&#39;_{0}(a-R(t)) R&#39;(t)}{f_{0}(a-R(t))} - \\frac{R&#39;&#39;(t)}{1-R&#39;(t)}+ \\frac{q&#39;(t)}{q(t)} \\end{aligned} \\] If we sketch this, where the age is on the x-axis, then the last two components affect the intercept of the curve. If births are postponed, \\(R&#39;(t)&gt;0\\) but if they are actually advanced then \\(R&#39;(t)&lt;0\\), which affects the slope, \\(\\frac{\\partial}{\\partial t}\\log f(a,t)\\). Uniform shifts BF model assumes all ages shift by \\(R(t)\\). BF model assumes all ages rise or fall by same quantum \\(q(t)\\) Violating these assumptions means change in mean age will not just reflect “tempo”. Example: What happens if people have fewer higher order births? BF recommendation for achieving uniformity Separate estimates for each birth order, and then combine: \\[ TFR^*(t) = \\sum_i TFR_i^*(t) = \\sum_i {TFR_i(t) \\over 1 - r_i(t)} \\] This will protect against order-specific quantum effects. 7.4 An Application to the United States Tempo adjustment of US fertility using HFD data using Bongaarts-Feeney formula: 1. Read in data and format into an array. Below we show the period fertility rates for all parities at each age for 1933 and 1934 of US women. library(data.table) library(dplyr) library(knitr) source(&quot;https://raw.githubusercontent.com/josh-goldstein-git/random_demography/master/bookdown-master/codes/tempo_functions.R&quot;) source(&quot;https://raw.githubusercontent.com/josh-goldstein-git/random_demography/master/bookdown-master/codes/utility_functions.R&quot;) ## age specific fertility rates by birth order for all countries and times ## RR means &quot;rectangles&quot; on Lexis surface dt &lt;- fread(&quot;https://raw.githubusercontent.com/josh-goldstein-git/random_demography/master/bookdown-master/data/zip_w/asfrRRbo.txt&quot;, showProgress = FALSE) dt &lt;- dt[Code == &quot;USA&quot;] ## keep only US dt &lt;- dt[Age %in% 15:49] ## keep only ages 15 to 49 ## put all order fertility into a matrix fat &lt;- dt[, xtabs(ASFR ~ Age + Year)] # age (rows) by cohort year (column) matrix of ASFR fat &lt;- as.matrix(unclass(fat)) fat1 &lt;- dt[, xtabs(ASFR1 ~ Age + Year)] #age specific fertility rates for parity = 1 fat2 &lt;- dt[, xtabs(ASFR2 ~ Age + Year)] fat3 &lt;- dt[, xtabs(ASFR3 ~ Age + Year)] fat4 &lt;- dt[, xtabs(ASFR4 ~ Age + Year)] fat5p &lt;- dt[, xtabs(ASFR5p ~ Age + Year)] year.vec &lt;- colnames(fat) age.vec &lt;- rownames(fat) parity.vec &lt;- c(&quot;all&quot;, 1:5) fat.array &lt;- array(NA, dim = c(nrow(fat), ncol(fat), length(parity.vec))) dimnames(fat.array) &lt;- list(age.vec, year.vec, parity.vec) fat.array[,,&quot;all&quot;] &lt;- fat fat.array[,,&quot;1&quot;] &lt;- fat1 fat.array[,,&quot;2&quot;] &lt;- fat2 fat.array[,,&quot;3&quot;] &lt;- fat3 fat.array[,,&quot;4&quot;] &lt;- fat4 fat.array[,,&quot;5&quot;] &lt;- fat5p kable(fat.array[,1:2,&quot;all&quot;], caption=&quot;An extract of period age-specific fertility rates&quot;)%&gt;% kableExtra::kable_styling(full_width = F) Table 7.1: An extract of period age-specific fertility rates 1933 1934 15 0.00672 0.00715 16 0.01875 0.01991 17 0.03846 0.04062 18 0.06586 0.06957 19 0.08719 0.09155 20 0.10136 0.10749 21 0.10639 0.11296 22 0.11349 0.11807 23 0.11785 0.12034 24 0.11476 0.12208 25 0.11388 0.11536 26 0.10873 0.11399 27 0.10118 0.10487 28 0.10283 0.10554 29 0.09094 0.09483 30 0.09009 0.09330 31 0.06941 0.07239 32 0.07813 0.07541 33 0.07614 0.06993 34 0.06013 0.07248 35 0.06009 0.05676 36 0.05416 0.05401 37 0.04748 0.04670 38 0.04755 0.04769 39 0.03724 0.03752 40 0.03078 0.03024 41 0.01967 0.01963 42 0.01877 0.01874 43 0.01283 0.01235 44 0.00808 0.00789 45 0.00526 0.00491 46 0.00245 0.00242 47 0.00127 0.00122 48 0.00081 0.00087 49 0.00037 0.00037 2. Fit bongaarts feeney without birth order tfr.vec &lt;- colSums(fat) # total fertility rate for each cohort mu.vec &lt;- apply(fat, 2, get.mean) # mean age at childbearing rt.vec &lt;- center.diff(mu.vec) # increments of postponement adj.tfr.vec &lt;- tfr.vec / (1 - rt.vec) # Assuming no quantum effect, tempo-adjusted TFR par(mfrow = c(3,1)) plot(names(mu.vec), mu.vec, xlab = &quot;Year&quot;, ylab=&quot;Mean age of childbearing&quot;) plot(names(mu.vec), rt.vec, xlab = &quot;Year&quot;, ylab= &quot;Shifts&quot;) abline(h =0) plot(year.vec, tfr.vec, type = &quot;l&quot;, xlab = &quot;Year&quot;, ylab= &quot;TFR&quot;) lines(year.vec, adj.tfr.vec, lty = 2) abline(v = c(1945, 2008)) legend(&quot;topright&quot;, c(&quot;Observed TFR&quot;, &quot;Tempo-adjusted TFR&quot;), lty= c(1,2)) Figure 7.1: Adjusted TFR We see fertility since 1980 has been depressed by postponment We see weird dynamics around end of WW2 and great recession. What’s going on? Here is a closeup Figure 7.2: Observed and tempo-adjusted TFRs Now let’s look at turbulence around WWII par(mfrow = c(2,2)) plot(age.vec, fat[,&quot;1944&quot;], type = &quot;l&quot;, ylim = c(0, .23), ylab = &quot;f(a)&quot;, xlab = &quot;age a&quot;) lines(age.vec, fat[,&quot;1945&quot;], type = &quot;l&quot;, col = &quot;red&quot;) lines(age.vec, fat[,&quot;1946&quot;], type = &quot;l&quot;, col = &#39;orange&#39;) lines(age.vec, fat[,&quot;1947&quot;], type = &quot;l&quot;, col = &quot;blue&quot;) legend(&quot;topright&quot;, legend = 1944:1947, col = c(&quot;black&quot;, &quot;red&quot;, &quot;orange&quot;, &quot;blue&quot;), lty = 1) title(&quot;Age specific fertility&quot;) plot(1943:1947, mu.vec[paste(1943:1947)], ylab = &quot;mu(t)&quot;, xlab = &quot;t&quot;, col = c(&quot;black&quot;, &quot;black&quot;, &quot;red&quot;, &quot;orange&quot;, &quot;blue&quot;), pch = 19) title(&quot;Mean ages&quot;) plot(1943:1947, rt.vec[paste(1943:1947)], ylab = &quot;r(t)&quot;, xlab = &quot;t&quot;, col = c(&quot;black&quot;, &quot;black&quot;, &quot;red&quot;, &quot;orange&quot;, &quot;blue&quot;), pch = 19) title(&quot;Changes in mean, centered&quot;) plot(1943:1947, tfr.vec[paste(1943:1947)], ylab = &quot;tfr&quot;, xlab = &quot;t&quot;, ylim = c(1, 4), type = &quot;l&quot;) lines(1943:1947, adj.tfr.vec[paste(1943:1947)], lty = 2) title(&quot;TFR and adjTFR&quot;) legend(&quot;topright&quot;, c(&quot;Observed TFR&quot;, &quot;Tempo-adjusted TFR&quot;), lty=c(1,2)) Figure 7.3: Change in fertility rates around WWII From 1945 to 1946, fertility goes up a lot, but more at younger ages. So mean goes down. BF adjustment over-compensates, and has quantum declining. What’s happening from 1944-45? 3. Fit bongaarts feeney with birth order out &lt;- bf.fit(fat.array) #function to obtain BF tempo-adjusted TFR adj.tfr.bo.vec &lt;- out$tfr.star.out[, &quot;bf.tfr.star&quot;] # sum of parity specific tempo-adjusted TFRs par(mfrow = c(1,1)) plot(year.vec, tfr.vec, type = &quot;l&quot;, lwd = 2, xlab=&quot;Year&quot;, ylab= &quot;TFR&quot;) lines(year.vec, adj.tfr.vec, lty = 2) lines(year.vec, adj.tfr.bo.vec, lty = 1, lwd = 2, col = &quot;red&quot;) legend(&quot;topright&quot;, c(&quot;tfr&quot;, &quot;tfr* (all parities)&quot;, &quot;tfr* (sum of parities)&quot;), col = c(&quot;black&quot;, &quot;black&quot;, &quot;red&quot;), lty = c(1, 2, 1), lwd = c(2,1,2)) Figure 7.4: TFR by parities 4. Use HFD data to verify adjusted TFR. HFD uses a tempo-adjusted TFR that is the sum of the parity specific adjusted BF TFR. ## let&#39;s check against hfd hfd.adj.dt &lt;- fread(&quot;https://raw.githubusercontent.com/josh-goldstein-git/random_demography/master/bookdown-master/data/zip_w/adjtfrRR.txt&quot;, showProgress = FALSE, skip = 2) hfd.adj.dt &lt;- hfd.adj.dt[Code == &quot;USA&quot;] We find that: Taking birth order into account smooths out WW2 turbulence (large fluctuations) but increases the variation during the Great Recession. The baby boom appears to initially be even greater than observed when we take into account birth order, but then it fall more than observed. Finally, the baby bust was not as bad as it seemed. plot(year.vec, tfr.vec, type = &quot;l&quot;, lwd = 2, xlab=&quot;Year&quot;, ylab= &quot;TFR&quot;) lines(year.vec, adj.tfr.vec, lty = 2) lines(year.vec, adj.tfr.bo.vec, lty = 1, lwd = 2, col = &quot;red&quot;) lines(hfd.adj.dt$Year, hfd.adj.dt$adjTFR, col = &quot;blue&quot;) legend(&quot;topright&quot;, c(&quot;tfr&quot;, &quot;tfr* (all parities)&quot;, &quot;tfr* (sum of parities)&quot;, &quot;HFD adj TFR&quot;), col = c(&quot;black&quot;, &quot;black&quot;, &quot;red&quot;, &quot;blue&quot;), lty = c(1, 2, 1, 1), lwd = c(2,1,2,2)) Figure 7.5: TFR by parities using HFD data 7.4.1 Conclusions Baby boom smaller if we account for “pre-ponement”. Fertility lull in 1970s and 80s disappears if we account for “postponement”. Birth order disaggregation improves estimates of shifts from changes in mean age What happened with the recession? 7.5 Two Americas Let’s look at births (all orders). Here we have some animations of the ASFR over time. my.year.vec &lt;- 1975:2017 # library(devtools) # install_github(&quot;dgrtwo/gganimate&quot;) # install.packages(&quot;transformr&quot;) # install.packages(&quot;animation&quot;) library(gganimate) library(data.table) library(mixtools) library(ggplot2) source(&quot;https://raw.githubusercontent.com/josh-goldstein-git/random_demography/master/bookdown-master/codes/tempo_mixed_functions.R&quot;) source(&quot;https://raw.githubusercontent.com/josh-goldstein-git/random_demography/master/bookdown-master/codes/tempo_functions.R&quot;) # plot1 &lt;- ggplot(data=dt[Year %in% my.year.vec,2:4], aes(x=Age, y= ASFR)) + # geom_line(aes(group=Year))+ # transition_time(Year)+ # labs(title = &quot;Year: {frame_time}&quot;) # anim_save(&quot;plot1.gif&quot;, plot1) During the earlier years, the mean childbearing age seems to be in the early 20s. However with time, the AFR seems to become bimodal. So what is happening here? Are there two underlying groups of women that experience different fertility rates. Now fit mixing model and redo the animation. NOTE: Not sure of all the lines in this mixture code. Josh, could you add some notes please? ## takes few minutes to run my.fat &lt;- fat[, paste(my.year.vec)] out &lt;- get.mixed.tfr.star(my.fat) ## out.all &lt;- out #Mixture simulation if (0) { mu.mat &lt;- get.coefs.mixed(out.all$fert.fit.list.variable.sigma)$mu.mat lambda.mat &lt;- get.coefs.mixed(out.all$fert.fit.list.variable.sigma)$lambda.mat sigma.mat &lt;- get.coefs.mixed(out.all$fert.fit.list.variable.sigma)$sigma.mat } mu.mat &lt;- get.coefs.mixed(out.all$fert.fit.list)$mu.mat lambda.mat &lt;- get.coefs.mixed(out.all$fert.fit.list)$lambda.mat sigma.mat &lt;- get.coefs.mixed(out.all$fert.fit.list)$sigma.ma #Temporary comment out until we figure out what these graphs actually are # matplot(my.year.vec, t(mu.mat)) # abline(v = 2015)## problem here # points(c(2015, 2015), c(21.5, 30.3)) # # matplot(my.year.vec, t(lambda.mat)) # abline(v = 2015)## problem here # points(c(2015, 2015), c(21.5, 30.3)) ## interpolate 1915 colnames(lambda.mat) &lt;- my.year.vec colnames(mu.mat) &lt;- my.year.vec lambda.mat[,&quot;2015&quot;] &lt;- (lambda.mat[,&quot;2014&quot;] + lambda.mat[,&quot;2016&quot;])/2 mu.mat[,&quot;2015&quot;] &lt;- (mu.mat[,&quot;2014&quot;] + mu.mat[,&quot;2016&quot;])/2 Now we create the animation with the normal distributions inside as well as the observed ASFR. # Obtaining different ASFRs per group (1 and 2) my.dt &lt;- dt[Year %in% my.year.vec,] for (i in 1:length(my.year.vec)){ my.year &lt;- my.year.vec[i] year.vec &lt;- colnames(my.fat) fx &lt;- my.fat[,paste(my.year)] # fx &lt;- fx/sum(fx) x &lt;- as.numeric(names(fx)) ## par(mfrow = c(1,1)) # plot(x, fx, # ylim = c(0, .3), # ylab = &quot;normalized fx&quot;) s &lt;- year.vec == my.year this.tfr &lt;- sum(fx) fx1.hat &lt;- dnorm(x, mean = mu.mat[1,s], sd = sigma.mat[1,s]) * lambda.mat[1,s]* this.tfr # lines(x, fx1.hat, col = &quot;red&quot;) fx2.hat &lt;- dnorm(x, mean = mu.mat[2,s], sd = sigma.mat[2,s]) * lambda.mat[2,s] * this.tfr # lines(x, fx2.hat, col = &quot;blue&quot;) # lines(x, fx1.hat + fx2.hat) # title(last.year) my.dt &lt;- my.dt[Year==my.year, fx := fx] my.dt &lt;- my.dt[Year==my.year, fx1 := fx1.hat] my.dt &lt;- my.dt[Year==my.year, fx2 := fx2.hat] my.dt &lt;- my.dt[Year==my.year, fx1fx2 := fx1.hat + fx2.hat] } labels &lt;- c(&quot;Observed&quot; = &quot;black&quot;, &quot;Mixture 1&quot; = &quot;blue&quot;, &quot;Mixture 2&quot; = &quot;red&quot;, &quot;Sum of mixtures&quot;=&quot;orange&quot;) # plot2 &lt;- # ggplot(data=my.dt, aes(x=Age)) + # geom_line(aes( y= ASFR, group=Year, color = &quot;Observed&quot;))+ # geom_line(aes( y= fx1, group=Year, color = &quot;Mixture 1&quot;))+ # geom_line(aes( y= fx2, group=Year, color = &quot;Mixture 2&quot;))+ # geom_line(aes( y= fx1fx2, group=Year, color = &quot;Sum of mixtures&quot;))+ # labs(color = &quot;Legend&quot;) + # scale_color_manual(values = labels)+ # theme_bw()#+ # transition_time(Year)+ # labs(title = &quot;Year: {frame_time}&quot;) # anim_save(&quot;plot2.gif&quot;, plot2) The animation shows how the distributions operate under the ASFR curve. There could be two separate normal distributions with distinct mean ages of childbearing. Let’s do tempo adjustment: NOTE: Help! I don’t know how to interpret these graphs rt.mat &lt;- t(apply(mu.mat, 1, center.diff)) tfr.vec &lt;- apply(my.fat, 2, sum) tfr.mat &lt;- lambda.mat * tfr.vec par(mfrow = c(1,2)) matplot(my.year.vec, t(tfr.mat), ylim = c(0, 3)) tfr.star.mat &lt;- tfr.mat / (1 - rt.mat) matplot(my.year.vec, t(tfr.star.mat), ylim = c(0,3)) Figure 7.6: Tempo Adjustment tfr.star.vec &lt;- colSums(tfr.star.mat) par(mfrow = c(1,1)) plot(my.year.vec, tfr.vec, type = &quot;l&quot;, ylim = c(1, 3)) lines(my.year.vec, tfr.star.vec, lty = 2) Figure 7.7: Tempo Adjustment 7.5.1 Mixture Let’s look at 1st births, again as if their are two latent groups: \\(A\\) and \\(B\\). (These could be “early moms” / “late moms”, non-college / college, pre-marital / marital, lower-class / upper class, \\(\\ldots\\)) library(mixtools) ## simulate 2 normals N &lt;- 1000 x1 &lt;- rnorm(N, mean = 22, sd = 3) ## x2 &lt;- rnorm(2*N, mean = 30, sd = 4) ## combine them x &lt;- c(x1,x2) ## use EM to infer mixture out &lt;- normalmixEM(x, lambda = c(.5, .5), mu = c(15, 35), sigma = c(5,5)) ## number of iterations= 284 print(out$mu) ## [1] 21.82989 29.86819 print(out$sigma) ## [1] 2.809958 4.145025 print(out$lambda) ## [1] 0.3024403 0.6975597 Seems to work great. ages &lt;- 10:49 dens1 &lt;- dnorm(x = ages, mean = out$mu[1], sd = out$sigma[1]) * out$lambda[1] dens2 &lt;- dnorm(x = ages, mean = out$mu[2], sd = out$sigma[2]) * out$lambda[2] par(mfrow = c(1,1)) hist(x, probability = T, col = &quot;grey&quot;, main = &quot;&quot;, xlab=&quot;Ages&quot;) lines(ages, dens1, col = &quot;red&quot;, lwd = 2) lines(ages, dens2, col = &quot;blue&quot;, lwd = 2) lines(ages, dens1 + dens2, col = &quot;black&quot;, lwd = 2) Figure 7.8: Histogram of ages (x) 7.5.2 An algorithm for tempo adjustment of mixtures Fit normal mixture to each year. Refit using constant variance (average). This assures shape invariance of each component, fulfilling BF assumption. Estimate BF separately for \\(A\\) and \\(B\\), and combine. tempo_mixed_results_figure.pdf NOTE: not sure about this… 7.6 Conclusions Postponement dilutes period births, lowers TFR Tempo-adjustment tries to ``put births back in’’ Changes in mean work fine if ``shape’’ doesn’t change Shape can change through heterogeneity With strong assumptions, we can identify heterogeneity Declining quantum for young and postponement for old appears to be the story 7.6.1 Caveats Who are these latent groups? Do you start out in one and end up in the other? Do you stay in one your whole life? How do we project forward? Can we use other indicators (e.g., social class, education, marriage) to get same results? 7.7 Questions Using the tempo_simu.R file, Try with N of 4 million – does it still work? What happens? Try with a shift function that goes up and down. Are the adjusted counts ever LESS than the observed counts? If so, when? If the cumulative shift was Rt = a + 0.1*t, what would be a formula for tempo-adjusted counts of births? Sketch the 4 panels without the computer and then check to see if you’re right. Calculate the age profile of fertility change predicted by the BongaartsFeeney model by taking time derivatives of the log schedules. You will end up with three terms. Describe each of these in words. Use simulation based on tempo simu.R to check your answer. Is there a diagnostic plot that you could do to compare observed agespecific changes to those predicted by the BF model? Hint: use normalized schedules that sum to 1.0 Use this diagnostic plot to all-order fertility change during the Great Recession. Use this diagnostic plot to 1st, 2nd, and 3rd births. Fit the two-part normal mixture model to fertility from another country based on what looks interesting in the Burkimsher paper. (E.g., Canada, Portugal, or the Netherlands). I recommend doing this for 1 year, but once you get your code running, you could iterate over years. Use graphs to discuss the goodness of fit. And if you do more than 1 year, discuss whether the time trends in the parameters make substantive sense) 7.8 Solutions Using the tempo_simu.R file, Try with N of 4 million – does it still work? What happens? This simulation will first sample from a normal distribution draws of ages that represent the ages of women when giving birth for the first time. It also creates as shift function \\(R(t)\\) which affects all women of a given year. library(data.table) source(&quot;functions/utility_functions.R&quot;) source(&quot;functions/tempo_functions.R&quot;) million = 10^6 thousand = 10^3 N &lt;- 4 * million year.vec &lt;- 1990:2020 ####################################### ## simulate originally timed births ## ####################################### ## we&#39;ll assume normal with age and uniform with time x &lt;- rnorm(N, mean = 30, sd = 4) t &lt;- runif(N, min = min(year.vec), max(year.vec)+1) dt &lt;- data.table(x, t) ######################### ## shifting the births ## ######################### ## we&#39;ll assume a continuous S-shaped cumulative shift shift.t &lt;- 2*plogis(seq(-5, 5, length.out = length(year.vec))) plot(year.vec, shift.t, type = &quot;o&quot;, main = &quot;Cumulative shifts&quot;) ## include shifts as a column Rt &lt;- approx(x = year.vec, y = shift.t, xout = t)$y dt[, Rt := approx(x = year.vec, y = shift.t, xout = t)$y] ## calculate shifted times and ages of births dt[, t.obs := t + Rt] dt[, x.obs := x + Rt] ## retain only the original time window (for convenience) dt &lt;- dt[floor(t.obs) %in% year.vec] ########################################## ## observed births counts and mean ages ## ########################################## out &lt;- dt[, .(Bt = .N, ## count the events mut = mean(x.obs)), ## get mean age by = .(year = floor(t.obs))] ## by whole years out &lt;- out[order(year)] ############################################ ## change in mean age and adjusted counts ## ############################################ out[, rt.hat := center.diff(mut, end.fill = T)] out[, Rt.hat := cumsum(rt.hat)] out[, Bt.adj := Bt / (1 - rt.hat)] ## function version of tabulating and plotting tempo_simu_plot_fun &lt;- function(dt) { ## requires x.obs and t.obs and ## (optionally) t, the original unshifted birth times ########################################## ## observed births counts and mean ages ## ########################################## out &lt;- dt[, .(Bt = .N, ## count the events mut = mean(x.obs)), ## get mean age by = .(year = floor(t.obs))] ## by whole years out &lt;- out[order(year)] ############################################ ## change in mean age and adjusted counts ## ############################################ out[, rt.hat := center.diff(mut, end.fill = T)] out[, Rt.hat := cumsum(rt.hat)] out[, Bt.adj := Bt / (1 - rt.hat)] ###################### ## plot the results ## ###################### par(mfrow = c(2,2)) out[, plot(year, Bt, ylim = c(.8, 1.2) * range(Bt), main = &quot;Observed Births&quot;)] out[, plot(year, mut, main = &quot;Mean age of birth&quot;)] out[, plot(year, center.diff(mut), main = &quot;Change in mean age of birth&quot;)] ## observed, adjusted, and original births Bt.orig.vec &lt;- dt[, table(floor(t))] out[, plot(year, Bt, ylim = c(.8, 1.5) * range(Bt), main = &quot;Observed and Adjusted Births&quot;)] out[, lines(year, Bt.adj, col = &quot;red&quot;)] points(names(Bt.orig.vec), Bt.orig.vec, col = &quot;grey&quot;) legend(&quot;top&quot;, c(&quot;observed&quot;, &quot;adjusted&quot;, &quot;original&quot;), pch = c(1,-1,1), lty = c(-1, 1,-1), col = c(&quot;black&quot;, &quot;red&quot;, &quot;grey&quot;), bty = &quot;n&quot;) } tempo_simu_plot_fun(dt) Yes, it still works. In fact, we see that the adjusted births are very close to the observed births when using this number of simulations. (I continue to use an N of 4 million for the rest of this problem). b. Try with a shift function that goes up and down. Are the adjusted counts ever LESS than the observed counts? If so, when? The adjusted counts are not always less than the observed. Naturally, this only happens when we have spikes on the observed counts that become smoother after the adjusting of the birth counts. c. If the cumulative shift was \\(R_t = a + 0.1\\times t\\), what would be a formula for tempo-adjusted counts of births? Sketch the 4 panels without the computer and then check to see if you’re right. Let \\(a = -199\\), so we get a shift of 0 to about 3 years depending on the time period: x &lt;- rnorm(N, mean = 30, sd = 4) t &lt;- runif(N, min = min(year.vec), max(year.vec)+1) dt &lt;- data.table(x, t) ######################### ## shifting the births ## ######################### #linear shift alpha = -199 shift.t &lt;- alpha + 0.1*year.vec plot(year.vec, shift.t, type = &quot;o&quot;, main = &quot;Cumulative shifts&quot;) ## include shifts as a column Rt &lt;- approx(x = year.vec, y = shift.t, xout = t)$y dt[, Rt := approx(x = year.vec, y = shift.t, xout = t)$y] ## calculate shifted times and ages of births dt[, t.obs := t + Rt] dt[, x.obs := x + Rt] ## retain only the original time window (for convenience) dt &lt;- dt[floor(t.obs) %in% year.vec] ########################################## ## observed births counts and mean ages ## ########################################## out &lt;- dt[, .(Bt = .N, ## count the events mut = mean(x.obs)), ## get mean age by = .(year = floor(t.obs))] ## by whole years out &lt;- out[order(year)] ############################################ ## change in mean age and adjusted counts ## ############################################ out[, rt.hat := center.diff(mut, end.fill = T)] out[, Rt.hat := cumsum(rt.hat)] out[, Bt.adj := Bt / (1 - rt.hat)] ## function version of tabulating and plotting tempo_simu_plot_fun &lt;- function(dt) { ## requires x.obs and t.obs and ## (optionally) t, the original unshifted birth times ########################################## ## observed births counts and mean ages ## ########################################## out &lt;- dt[, .(Bt = .N, ## count the events mut = mean(x.obs)), ## get mean age by = .(year = floor(t.obs))] ## by whole years out &lt;- out[order(year)] ############################################ ## change in mean age and adjusted counts ## ############################################ out[, rt.hat := center.diff(mut, end.fill = T)] out[, Rt.hat := cumsum(rt.hat)] out[, Bt.adj := Bt / (1 - rt.hat)] ###################### ## plot the results ## ###################### par(mfrow = c(2,2)) out[, plot(year, Bt, ylim = c(.8, 1.2) * range(Bt), main = &quot;Observed Births&quot;)] out[, plot(year, mut, main = &quot;Mean age of birth&quot;)] out[, plot(year, center.diff(mut), main = &quot;Change in mean age of birth&quot;)] ## observed, adjusted, and original births Bt.orig.vec &lt;- dt[, table(floor(t))] out[, plot(year, Bt, ylim = c(.8, 1.5) * range(Bt), main = &quot;Observed and Adjusted Births&quot;)] out[, lines(year, Bt.adj, col = &quot;red&quot;)] points(names(Bt.orig.vec), Bt.orig.vec, col = &quot;grey&quot;) legend(&quot;top&quot;, c(&quot;observed&quot;, &quot;adjusted&quot;, &quot;original&quot;), pch = c(1,-1,1), lty = c(-1, 1,-1), col = c(&quot;black&quot;, &quot;red&quot;, &quot;grey&quot;), bty = &quot;n&quot;) } tempo_simu_plot_fun(dt) 2. Calculate the age profile of fertility change predicted by the BongaartsFeeney model by taking time derivatives of the log schedules. You will end up with three terms. Describe each of these in words. \\[\\begin{aligned} f(a,t)&amp;=f_0(a-R(t))[1-R&#39;(t)]q(t)\\\\ log(f(a,t))&amp;=log(f_0(a-R(t))) + log(1-R&#39;(t)) + log(q(t))\\\\ \\frac{\\partial log(f(a,t))}{\\partial t}&amp;=\\frac{\\partial log(f_0(a-R(t)))}{\\partial t} + \\frac{\\partial log(1-R&#39;(t))}{\\partial t} + \\frac{\\partial log(q(t))}{\\partial t}\\\\ \\frac{\\partial log(f(a,t))}{\\partial t}&amp;=-R&#39;(t)\\frac{f_0&#39;(a-R(t))}{f_0(a-R(t))} -\\frac{R&#39;&#39;(t)}{1-R&#39;(t)} + \\frac{q&#39;(t)}{q(t)} \\end{aligned}\\] The first term represents the proportional change in the fertility of the equivalent pre-postponement cohort. In particular, it is divided into (how far someone shifts ‘over’ relative to ages on the baseline fertility schedule) and an \\(R&#39;(t)\\) term (how much one shifts ‘up’). The second term represents the proportional change in the rate of change in years of postponement; it is a tempo-effect. The third term represents the proportional change in quantum. 3. Use simulation based on tempo simu.R to check your answer. The tempo_simu.R function computes \\(R(t)\\) but we need to obtain the remaining components of the answer from the previous excercise. For simplicity, let’s assume that there are no tempo effects (\\(q(t)=0\\)) and that \\(a=25\\), that is, our baseline schedule is that of women aged 25. a. \\(R(t)\\) components: Let’s briefly look at \\(R(t)\\), \\(R&#39;(t)\\), and \\(R&#39;&#39;(t)\\). In tempo_simu.R \\(R(t)\\) refers to the cumulative shift object (shift.t ). We can obtain the derivatives by taking the centered difference of this object. shift.t.prime &lt;- center.diff(shift.t) shift.t.prime.2 &lt;- center.diff(shift.t.prime) par(mfrow = c(2,2)) plot(1991:2020, shift.t, main = &#39;R(t)&#39;, xlab = &#39;&#39;, ylab = &#39;&#39;) plot(1991:2020, shift.t.prime, main = &#39;R\\&#39;(t)&#39;, xlab = &#39;&#39;, ylab = &#39;&#39;) plot(1991:2020, shift.t.prime.2, main = &#39;R\\&#39;\\&#39;(t)&#39;, xlab = &#39;&#39;, ylab = &#39;&#39;) plot(1991:2020,-shift.t.prime.2/ (1-shift.t.prime), main = &#39;-R\\&#39;\\&#39;(t) / (1- R\\&#39;(t))&#39;, xlab = &#39;year&#39;, ylab = &#39;&#39;) ``` &lt;img src=&quot;bookdown-demo_files/figure-html/unnamed-chunk-98-1.png&quot; width=&quot;768&quot; /&gt; b. $f_0(a-R(t))$ function: In the Bongaarts and Feeney model, the baseline schedule of women of age $a$ at time $t$ is $f_0(a-R(t))$. That is, it is the fertility schedule that is observed because of the shift. From the simulation, we obtain a table of births at each age and the age-specific fertility rates. Then, we can look at the original and the observed ASFRs. The original ASFR is that from the simulation, which we would not observe. Rather we would only the see the ASFR from births that were postponed by year-specific shifts. ```r # floor everything dt_floored &lt;- dt %&gt;% transmute(&#39;x&#39; = floor(x), &#39;t&#39; = floor(t), &#39;t.obs&#39; = floor(t.obs), &#39;x.obs&#39; = floor(x.obs)) # the .obs values are the ones that go into the baseline function. # Births to women born at each age. original_sched &lt;- table(dt_floored$x, dt_floored$t) observed_sched &lt;- table(dt_floored$x.obs, dt_floored$t.obs) # ASFR (The denominator is 100 person years lived, or 100 women at each age) asfr_original&lt;- original_sched/(100*thousand) #f(a,t) asfr_observed &lt;- observed_sched/(100*thousand) #f_0(a,t) #Graph of ASFRs for observed and original births. The lines get lighter with each year. par(mfrow=c(2,1)) matplot(rownames(asfr_observed), asfr_observed, type = &quot;l&quot;, lty = 1, col=grey(seq(0, 1, length = 40)), xlab = &#39;Age&#39;, ylab = &#39;ASFR&#39;, main = &#39;Observed ASFR&#39;) abline(v= 25, lty = 2, col = &#39;black&#39;) matplot(rownames(asfr_original), asfr_original, type = &quot;l&quot;, lty = 1, col=grey(seq(0, 1, length = 40)), xlab = &#39;Age&#39;, ylab = &#39;ASFR&#39;, main = &#39;Original ASFR&#39;) abline(v= 25, lty = 2, col = &#39;black&#39;) ``` &lt;img src=&quot;bookdown-demo_files/figure-html/unnamed-chunk-99-1.png&quot; width=&quot;672&quot; /&gt; The component that we are interersted in is the first derivative of the baseline schedule ($f_0(a-R(t))$). ```r asfr_observed_prime &lt;- apply(asfr_observed, 1, center.diff) par(mfrow = c(1,3)) matplot(rownames(asfr_observed_prime), asfr_observed_prime, type = &quot;l&quot;, lty = 1, col=grey(seq(0, 1, length = 40)), xlab = &#39;Year&#39;, ylab = &#39;ASFR&#39;, main = &quot;f&#39;0(a-R(t))&quot; ) abline(v= 25, lty = 2, col = &#39;black&#39;) matplot(rownames(asfr_observed_prime), asfr_observed_prime/t(asfr_observed), type = &quot;l&quot;, lty = 1, col=grey(seq(0, 1, length = 40)), xlab = &#39;Year&#39;, ylab = &#39;ASFR&#39;, main = &quot;f&#39;0(a-R(t))/f0(a-R(t))&quot; ) abline(v= 25, lty = 2, col = &#39;black&#39;) f &lt;- -shift.t.prime*asfr_observed_prime/t(asfr_observed) matplot(rownames(asfr_observed_prime),-shift.t.prime*asfr_observed_prime/t(asfr_observed), type = &quot;l&quot;, lty = 1, col=grey(seq(0, 1, length = 40)), xlab = &#39;Year&#39;, ylab = &#39;ASFR&#39;, main = &quot;-R&#39;(t)*f&#39;0(a-R(t))/f0(a-R(t))&quot; ) abline(v= 25, lty = 2, col = &#39;black&#39;) ``` &lt;img src=&quot;bookdown-demo_files/figure-html/unnamed-chunk-100-1.png&quot; width=&quot;672&quot; /&gt; c. Comparison of terms from original and observed data: We can merge all the terms of the formula from the previous question and compare it to the derivative of the log version of the observed fertility schedules. ```r #Observed data (right-hand side) observed_change &lt;- -shift.t.prime*asfr_observed_prime/t(asfr_observed) - shift.t.prime.2/ (1-shift.t.prime) #Original data (left-hand side) original_change &lt;- apply(log(t(asfr_original)),2,center.diff) #Graphs par(mfrow = c(1,2)) matplot(rownames(observed_change), observed_change, type = &quot;l&quot;, lty = 1, col=grey(seq(0, 1, length = 40)), xlab = &#39;Year&#39;, ylab = &#39;ASFR&#39;, main = &#39;Observed change (RHS)&#39;) abline(v= 25, lty = 2, col = &#39;black&#39;) matplot(rownames(original_change), original_change, type = &quot;l&quot;, lty = 1, col=grey(seq(0, 1, length = 40)), xlab = &#39;Year&#39;, ylab = &#39;ASFR&#39;, main = &#39;Original change (LHS)&#39;) abline(v= 25, lty = 2, col = &#39;black&#39;) ``` &lt;img src=&quot;bookdown-demo_files/figure-html/unnamed-chunk-101-1.png&quot; width=&quot;672&quot; /&gt; ```r #There seems to be a lot of noise here, so let&#39;s look at the mean at each year for the RHS and the LHS observed_change_mean &lt;- apply(observed_change, 2, mean, na.rm=TRUE) original_change_mean &lt;- apply(original_change, 2, mean, na.rm=TRUE) par(mfrow = c(1,2)) plot(observed_change_mean[12:39], col=&quot;blue&quot;) plot(original_change_mean[12:39], col=&quot;red&quot;) ``` &lt;img src=&quot;bookdown-demo_files/figure-html/unnamed-chunk-101-2.png&quot; width=&quot;672&quot; /&gt; ```r observed_change_mean ``` ``` ## 5 6 7 8 9 10 ## Inf NaN NaN NaN NaN NaN ## 11 12 13 14 15 16 ## 0.0346455819 0.0297976453 0.0248332401 0.0239915297 0.0221809649 0.0199164460 ## 17 18 19 20 21 22 ## 0.0180659826 0.0160980077 0.0144997811 0.0126420118 0.0107639359 0.0089432668 ## 23 24 25 26 27 28 ## 0.0069456544 0.0051884417 0.0032663876 0.0014198640 -0.0004753358 -0.0022687715 ## 29 30 31 32 33 34 ## -0.0041667145 -0.0060392014 -0.0079432768 -0.0096843256 -0.0115976736 -0.0133616444 ## 35 36 37 38 39 40 ## -0.0153737506 -0.0170545337 -0.0189727392 -0.0208894124 -0.0233746760 -0.0249600394 ## 41 42 43 44 45 46 ## -0.0265662882 -Inf NaN NaN NaN -Inf ## 47 48 ## NaN NaN ``` ```r original_change_mean ``` ``` ## 5 6 7 8 9 10 11 ## NaN NaN NaN -0.04702751 -Inf -Inf -0.04966368 ## 12 13 14 15 16 17 18 ## -0.06108219 -0.05255181 -0.05463626 -0.05422444 -0.04876114 -0.05049269 -0.05189116 ## 19 20 21 22 23 24 25 ## -0.05168229 -0.05310568 -0.05152007 -0.05163416 -0.05222859 -0.05216303 -0.05147769 ## 26 27 28 29 30 31 32 ## -0.05243268 -0.05242616 -0.05138857 -0.05216956 -0.05232595 -0.05271028 -0.05269802 ## 33 34 35 36 37 38 39 ## -0.05278829 -0.05342713 -0.05158280 -0.05298234 -0.04710160 -0.06555547 -0.06775549 ## 40 41 42 43 44 45 ## -0.03566782 -0.02772589 NaN NaN NaN NaN ``` ```r observed_change_25 &lt;- -shift.t.prime*asfr_observed_prime[,25]/t(asfr_observed)[,25] - shift.t.prime.2/ (1-shift.t.prime) original_change_25 &lt;- center.diff(log(t(asfr_original)[,25])) plot(observed_change_25, col=&quot;blue&quot;) lines(original_change_25, col=&quot;red&quot;) plot(observed_change[,25], col=&quot;blue&quot;) lines(original_change[,25], col=&quot;red&quot;) ``` &lt;img src=&quot;bookdown-demo_files/figure-html/unnamed-chunk-101-3.png&quot; width=&quot;672&quot; /&gt; &lt;!--chapter:end:06-tempo.Rmd--&gt; # Branching Processes ## Outline - The Galton-Watson-Bienaym\\&#39;e Process: Motivation - Simulating a branching process - Moment generating functions - Extinction probabilities - The distribution of offspring of all generations - A tractable offspring distribution Additional resources: - @grinstead2006: An intermediate/advanced undergraduate textbook with good section on Branching Processes, with references to Harris and Keyﬁtz below. - @harris1964theory: Classic reference, but readable if you take your time. We will only read chapter 1 and will only consider the very easiest material. - Surname Extinction: When will we all be &quot;Smiths&quot;?_ &lt;https://www.youtube.com/watch?v=5p-Jdjo7sSQ&gt;: Popular science video providing good motivation, but without authority. - _Is Your Surname about to Go Extinct?_ &lt;https://blogs.ancestry.com/cm/is-your-rare-surname-about-to-go-extinct/&gt;:A brief blog entry, mentionng of &quot;endangered names&quot;. - @keyfitz1968: Another introduction to branching process with the details of the empirical example cited by Grinstead and Snell. - @hellewell2020feasibility: An interesting application to COVID-19 ## Motivation - Until now, we&#39;ve focused on the hidden structures of heterogeneity. - Now, we&#39;re switching gears: - Stochastic not deterministic - In small populations, randomness matters. (Even when risks are homogeneous.) - We will look at branching processes (&quot;parents producing children&quot;), next Fisher-Wright (&quot;children choosing parents&quot;), and then historical reconstruction from contemporary diversity (&quot;coalescent&quot;). ### Very brief history of Branching Processes - Bienaymé&#39;s lost notes - Old motivation: Galton and Watson&#39;s: to see if elites were dying out because of &quot;degeneration&quot; - Contemporary motivation: evolution and neutral genetic change. What is the chance that a mutant will survive? - War-time motivation: to see how to build the bomb (chain reactions) - Sociological: Anywhere &quot;incipient dynamics&quot; matter (will all of S. Korea be &quot;Kim&quot;?) - Can we get variance of reproductive success from name disambiguation? - It will give us a headstart on other (less realistic but easier) &quot;drift&quot; models. ### Applicability to the Coronavirus? Yes and no. - Perhaps the beginning, with first few cases. - But once scale gets large, we&#39;ll see that deterministic dynamics take over. - One lesson: beyond $R_0$. ### Simulated examples and the questions they raise Here are the chances, $p_k$, that the first carrier passes on the virus to $k$ people ```r library(kableExtra) table &lt;- cbind(c(0,1,2),c(.3,.4,.3)) knitr::kable( table, col.names = c(&#39;$k$&#39;, &#39;$p_k$&#39;))%&gt;% kableExtra::kable_styling(full_width = F) \\(k\\) \\(p_k\\) 0 0.3 1 0.4 2 0.3 What is \\(R_0\\), (aka \\(m\\))? This is the expected number of infected cases: \\[\\begin{aligned} R_{0} &amp; = 0\\times 0.3 + 1\\times 0.4 + 2\\times 0.3 \\\\ &amp; = 1 \\end{aligned}\\] NOTE: is this correct? Now assume that people will infect \\(k\\) other people based on a random number, for instance the last 4 digits of their phone number. knitr::kable( cbind(c(0,1,2),c(.3,.4,.3),c(&quot;0-2&quot;, &quot;3-5&quot;, &quot;6-9&quot;)), col.names = c(&#39;$k$&#39;, &#39;$p_k$&#39;, &#39;digits&#39;) ) %&gt;% kableExtra::kable_styling(full_width = F) \\(k\\) \\(p_k\\) digits 0 0.3 0-2 1 0.4 3-5 2 0.3 6-9 Let’s diagram one chance outcome, using my number “(xxx) xxx-9056”. As each of the four digits is associated with a probability of infecting more people, they can be seen as different the carrier generations. For instance, the first carrier has a probability \\(p_k=0.3\\) of infecting \\(k=2\\) other people. So that first carrier may infect 2.7 people, (3 for simplicity). Each of these three people will have a \\(p_k=0.2\\) of each infecting \\(k=0\\) people. Since they don’t infect anybody then there are no further carrier generations. In the table, we include their rows but the expected number of infected people is still 0 because the spreading stopped in generation 2. knitr::kable( cbind(c(1,2,3,4),c(9,0,5,6),c(0.3,0.2,0.4,0.4), c(&quot;$2 \\\\times 0.3 = 2.7$&quot;, &quot;$0 \\\\times 0.3 = 0$&quot;, &quot;$0$&quot;,&quot;$0$&quot;)), col.names = c(&#39;carrier generation #&#39;, &#39;random digit&#39;, &#39;$p_k$&#39;, &#39;expected # infected&#39;), align=&quot;cccl&quot; ) %&gt;% kableExtra::kable_styling(full_width = F) carrier generation # random digit \\(p_k\\) expected # infected 1 9 0.3 \\(2 \\times 0.3 = 2.7\\) 2 0 0.2 \\(0 \\times 0.3 = 0\\) 3 5 0.4 \\(0\\) 4 6 0.4 \\(0\\) NOTE: does this sound reasonable? 7.8.1 What is a (Bienayme)-Galton-Watson branching process? \\(p_k\\): Each individual in each generation reproduces independently, following same offspring distribution, with \\(p_k\\) as the probability of having \\(k\\) offspring. \\(Z_n\\): The si\\(Z\\)e of the \\(n\\)’th generation \\(Z_n\\). (\\(Z_1 \\equiv 1\\)) \\(p_0 &gt; 0\\): Some non-zero probability of no children. Variance: None of the \\(p_k\\) are 1 Galton’s original question Some questions What is the chance \\(d\\) of eventual extinction (no “outbreak”)? Or, what is the distribution of surviving family sizes? What are the aggregate properties of many branching processes? (Mean growth, variance, time-paths, eventual size)? 7.9 Simulations of parents having children k = 0:2 #number of possible children p0 = .3; p1 = .3; p2 = .4; p_k = c(p0, p1, p2) #probabilities of having k children Z1 = 1 #initial cohort size set.seed(9) kids.of.Z1 = sample(x = k, size = Z1, replace = T, prob = p_k) Z2 = sum(kids.of.Z1) kids.of.Z2 = sample(x = k, size = Z2, replace = T, prob = p_k) Z3 = sum(kids.of.Z2) kids.of.Z3 = sample(x = k, size = Z3, replace = T, prob = p_k) Z4 = sum(kids.of.Z3) gen_size &lt;- c(rep(Z1, 1), rep(Z2, Z2), rep(Z3, Z3), rep(Z4, Z4)) gen &lt;- c(rep(1, 1), rep(2, Z2), rep(3, Z3), rep(4, Z4)) person &lt;- c(1, seq(2.1,by=0.1, to=2 + Z2*0.1), seq(3.1,by=0.1, to=3 +Z3*0.1), seq(4.1,by=0.1, to=4 +Z4*0.1)) total_children &lt;- c(kids.of.Z1, kids.of.Z2, kids.of.Z3, rep(0, Z4)) library(tidyverse) growth &lt;- tibble(gen, person, total_children, gen_size) names(growth) &lt;- c(&quot;Generation #&quot;, &quot;Person ID&quot;, &quot;Total children&quot;, &quot;Generation size&quot;) knitr::kable(growth)%&gt;% kableExtra::kable_styling(full_width = F) Generation # Person ID Total children Generation size 1 1.0 2 1 2 2.1 2 2 2 2.2 2 2 3 3.1 2 4 3 3.2 1 4 3 3.3 2 4 3 3.4 2 4 4 4.1 0 7 4 4.2 0 7 4 4.3 0 7 4 4.4 0 7 4 4.5 0 7 4 4.6 0 7 4 4.7 0 7 Here’s a more visual representation. # install.packages(&#39;DiagrammeR&#39;) DiagrammeR::grViz(&quot; digraph rmarkdown{ 1 -&gt;{2.1 2.2} 2.1-&gt;{3.1 3.2} 2.2-&gt;{3.3 3.4} 3.1-&gt;{4.1 4.2} 3.2-&gt;{4.3} 3.3-&gt;{4.4 4.5} 3.4-&gt;{4.6 4.7} }&quot;) Figure 7.9: Parents having childrens However, we can extend the number of generations in a function: #A function branch &lt;- function(n_max = 30, pk = c(p0, p1, p2), Z1 = 1) { Z.vec &lt;- rep(NA, n_max) # n_max handles the total number of generations Z.vec[1] &lt;- Z1 for (i in 1:(n_max-1)) { Z.vec[i+1] &lt;- sum(sample(x = k, size = Z.vec[i], replace = T, prob = p_k)) } return(Z.vec) # returns a vector of the number of children at every generation } Sometimes generations die out: set.seed(19) ; branch() ## [1] 1 2 2 4 5 2 2 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 set.seed(99) ; branch() ## [1] 1 1 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Let’s see what happens with 20 trials (up to 30 generations). Not all generations go extinct here. n_trials = 20 n_gen = 30 k = 0:2 #number of possible children p0 = .3; p1 = .3; p2 = .4; p_k = c(p0, p1, p2) #probabilities of having k children Z1 = 1 #initial cohort size Z.mat &lt;- matrix(NA, n_trials, n_gen) set.seed(131) for (i in 1:n_trials) Z.mat[i,] &lt;- branch(n_max = n_gen) Figure 7.10: Generation size How many survive (out of 20)? log-scale suppressWarnings(matplot(t(Z.mat), log = &quot;y&quot;, type = &quot;l&quot;, lty = 1, ylab = &quot;Zn&quot;, xlab = &quot;n&quot;)) Figure 7.11: Generation sizes (log-scale) surviving = ifelse(Z.mat[,n_gen] == 0, &quot;extinct&quot;, &quot;survive&quot;) foo &lt;- prop.table(table(surviving)) print(prop.table(table(surviving)) ) ## surviving ## extinct survive ## 0.5 0.5 How would you describe the time path of the surviving lines? Let’s extend the number of generations to observe any long-term trends. n_trials = 20; n_gen = 100 Z.mat &lt;- matrix(NA, n_trials, n_gen) set.seed(131) for (i in 1:n_trials) Z.mat[i,] &lt;- branch(n_max = n_gen) suppressWarnings(matplot(t(Z.mat), log = &quot;y&quot;, type = &quot;l&quot;, lty = 1, ylab = &quot;Zn&quot;, xlab = &quot;n&quot;)) Figure 7.12: Generation sizes (log-scale) over many generations What does this remind you of? (Hint: “Leslie”). (See Harris (1964), Figure 2, Chapter 1) 7.10 The Probability Generating Function: Our mathematical tool “Extinction” vs “breakout” We see that in a super-critical (\\(m &gt; 1\\)) branching process, if a line can survive a few generations and reach a large enough size, it will grow exponentially. What happens if \\(m &lt; 1\\), if \\(m = 1\\)? Discuss. \\[ h(z) = p_0 + p_1 z + p_2 z^2 + \\ldots \\] The PGF “keeps book” on the probabilities. The chance of \\(k\\) is the coefficient on \\(z^k\\). \\(h(0)= p_{0}\\) \\(h(1)= p_{0} + p_{1}\\) \\(h&#39;(1)= p_{1} + 2p_{2}\\) The story of two brothers. A father has two sons. The probability generating function of their children combined is: \\[ h(z)^2 = (p_0 + p_1 z + p_2 z^2) \\times (p_0 + p_1 z + p_2 z^2) \\] If we multiply it out we get: \\[ \\begin{aligned} \\left[h(z)\\right]^2 = &amp; p_0^2 + p_0 p_1 z + p_0 p_2 z^2 +\\\\ &amp; p_1 z p_0 + p_1^2 z^2 + p_1 p_2 z^3 + \\\\ &amp; p_2 z^2 p_0 + p_2 z^3 p_1 + p_2^2 z^4 \\\\ &amp; = p_0^2 + (2p_0 p_1 )z + (2p_0 p_2 + p_1^2)z^2 + (2p_1 p_2)z^3 + p_2^2 z^4 \\end{aligned} \\] The coefficients on \\(z^0, z^1, \\ldots\\) tell us the probability that the sons will have \\(k=0,1,2,3,4\\) sons. What is the probability generating function for the distribution of grandsons? A man has two sons, with probability \\(p_2\\), so PGF in that case is \\(p_2 [h(z)]^2\\). But let’s sum over all possible numbers of sons. \\[ p_0 + p_1 h(z) + p_2 [h(z)]^2 + p_3 [h(z)]^3 + \\ldots \\] This is the cumulative probability of drawing \\(k\\) children within a generation of size \\(Z\\) Which is? \\[ h(h(z)) \\] Can show PGF for the n’th generation is \\[ h(h(h ... \\mbox{$n$ \\times} h(z))) = h_n(z) \\] For instance, let’s get \\(h_2(z) = h(h(z))\\) for \\(h(z) = p_0 + p_1 z + p_2 z^2\\) \\[\\begin{aligned} h(h(z)) = &amp; p_0 + p_1 \\left[p_0 + p_1 z + p_2 z^2\\right] + p_2 \\left[p_0 + p_1 z + p_2 z^2\\right]^2\\\\ = &amp; p_0 + p_1 p_0 + p_1^2 z + p_1 p_2 z^2 + p_2p_0^2 + (2p_0 p_1 p_2)z +\\\\ (2p_0 p_2^2 + p_2p_1^2)z^2 + (2p_1 p_2^2)z^3 + p_2^3 z^4 \\end{aligned}\\] 7.11 Extinction Extinction “Extinction is forever.”: So, the probability \\(d_n\\) of extinction by generation \\(n\\) can never decline over time. (Must it always rise?) Recursive extinction Is non-extinction “forever”?: If \\(\\lim_{n \\rightarrow \\infty} = d(\\infty) &lt; 1\\), then this says there’s a chance \\(1 - d(\\infty)\\) of eternal persistence. We’ll try to figure out more about what this means. If the probability of a female line going extinct in \\(n\\) generations is \\(d_n\\), then this is equivalent to her daughter(s) line(s) going extinct in \\(n-1\\) generations. With \\(p_k\\) chance of having \\(k\\) daughters, we have \\[ d_n = p_0 + p_1 d_{n-1} + \\mbox{What is next term in series?} \\] What can we do with \\[ d_n = h(d_{n-1})? \\] Well, remember that \\(d_n\\) is non-decreasing, and that it’s maximum can be no greater than \\(1.0\\). When \\(d_n\\) reaches it’s limit, say \\(d\\), we won’t need generational subscripts, \\(d\\) will be constant, and will obey \\[ d = h(d) \\] Thus, an amazing result: the probability of ultimate extinction is when the argument equals the PGF of the argument. Can \\(d = 1\\), can \\(d &lt; 1\\) Try \\(d = 1\\). What happens? If we were to find a solution less than 1.0, how would we interpret that? Three cases z = seq(0, 1.6, .01) pk = c(.3, .0, .7); names(pk) &lt;- 0:2 d &lt;- pk[&quot;0&quot;] for (i in 1:10) { d &lt;- pk[&quot;0&quot;] + pk[&quot;1&quot;]*d + pk[&quot;2&quot;]*d^2 } ## super-critical hz = pk[&quot;0&quot;] + pk[&quot;1&quot;]*z + pk[&quot;2&quot;]*z^2 plot.fun &lt;- function(z, hz) { plot(z, hz, type = &quot;l&quot;, ylim = c(0,1.6), ylab = &quot;h(z)&quot;, yaxs = &quot;i&quot;, xaxs = &quot;i&quot;, axes = F) axis(1, at = seq(0, 1.5, .5)) axis(2, at = seq(0, 1.5, .5)) abline(0,1, col = &quot;grey&quot;) lines(z, hz) axis(2, at = pk[&quot;0&quot;], labels = &quot;p0&quot;, col.axis = &quot;red&quot;, col = &quot;red&quot;, lwd = 1, las = 2) } par(mfrow = c(1,3), pty = &quot;s&quot;) plot.fun(z,hz) points(c(d, 1),c(d, 1)) title(&quot;Super-critical (m &gt; 1) \\n 2 roots&quot;) ## sub-critical pk = c(.3, .55, .15); names(pk) &lt;- 0:2 hz = pk[&quot;0&quot;] + pk[&quot;1&quot;]*z + pk[&quot;2&quot;]*z^2 plot.fun(z,hz) title(&quot;Sub-critical (m &lt; 1) \\n 1 root&quot;) points(1,1) ## critical pk = c(.3, .4, .3); names(pk) &lt;- 0:2 hz = pk[&quot;0&quot;] + pk[&quot;1&quot;]*z + pk[&quot;2&quot;]*z^2 plot.fun(z, hz) title(&quot;Critical (m = 1), \\n 1 root&quot;) points(1,1) Figure 7.13: PGF for a variety of z We can prove by answering: What is \\(h&#39;(1)\\)? What is \\(h(0)\\)? Is \\(h&#39;&#39;(z) &gt; 0\\)? In the following cobwed diagram (like a staircase), we can see the values of \\(h(p_0)\\), \\(h(h(p_0))\\), \\(h(h(h(p_0)))\\), \\(\\ldots\\)? The orange dot is \\(h(p_0)\\). The purple dot is \\(h(h(p_0))\\). The blue dot is \\(h(h(h(p_0)))\\). The points would converge until we reach the intersection between \\(h(z)\\) and the diagonal. pk = c(.3, .0, .7); names(pk) &lt;- 0:2 z = seq(0, 1.6, .01) hz = pk[&quot;0&quot;] + pk[&quot;1&quot;]*z + pk[&quot;2&quot;]*z^2 plot.fun(z,hz) hzp0 &lt;- pk[&quot;0&quot;] + pk[&quot;1&quot;]*pk[&quot;0&quot;] + pk[&quot;2&quot;]*pk[&quot;0&quot;]^2 hhzp0 &lt;- pk[&quot;0&quot;] + pk[&quot;1&quot;]*hzp0 + pk[&quot;2&quot;]*hzp0^2 hhhzp0 &lt;- pk[&quot;0&quot;] + pk[&quot;1&quot;]*hhzp0 + pk[&quot;2&quot;]*hhzp0^2 segments(x0=0, y0=pk[&quot;0&quot;],x1=pk[&quot;0&quot;], y1= pk[&quot;0&quot;], col = &quot;orange&quot;, lwd=2)#h(p_0) segments(x0=pk[&quot;0&quot;], y0=pk[&quot;0&quot;], y1= hzp0, col = &quot;orange&quot;, lwd=2) segments(x0=pk[&quot;0&quot;], y0=hzp0,x1=hzp0, y1= hzp0, col = &quot;purple&quot;, lwd=2) #h(h(p_0)) segments(x0=hzp0, y0=hzp0, y1= hhzp0, col = &quot;purple&quot;, lwd=2) segments(x0=hzp0, y0=hhzp0,x1=hhzp0, y1= hhzp0, col = &quot;blue&quot;, lwd=2) segments(x0=hhzp0, y0=hhzp0, y1= hhhzp0, col = &quot;blue&quot;, lwd=2) points(x= pk[&quot;0&quot;], y =hzp0, pch=19, col=&quot;orange&quot;) #h(p_0) points(x= hzp0, y =hhzp0, pch=19, col=&quot;purple&quot;) #h(h(p_0)) points(x= hhzp0, y =hhhzp0, pch=19, col=&quot;blue&quot;) #h(h(h(p_0))) Figure 7.14: Cobwed diagram (staircase) So how do we actually get \\(d\\)? Take the case where \\(p_0 = .3\\), \\(p_1 = 0\\), and \\(p_3 = .7\\) (the one I just plotted). Can do some algebra Or we can recursively iterate on the computer. Numerical recursion: below we start at the first value of the probability vector and sequentially try exploring values of \\(h(z)\\) until we find one that doesn’t change as much. We illustrate the case for up to 20 iterations. pk = c(.3, .0, .7); names(pk) &lt;- 0:2 ## our example d &lt;- pk[&quot;0&quot;] # initial value for (i in 1:20) { d &lt;- pk[&quot;0&quot;] + pk[&quot;1&quot;]*d + pk[&quot;2&quot;]*d^2 if (i %in% c(1,2,19,20)) print(paste(i, d)) } ## [1] &quot;1 0.363&quot; ## [1] &quot;2 0.3922383&quot; ## [1] &quot;19 0.428565882081349&quot; ## [1] &quot;20 0.428568100698915&quot; Did we get the right value? Apparently, yes! The green lines take as vertical and horizontal values our \\(d=0.428568100698915\\) pk = c(.3, .0, .7); names(pk) &lt;- 0:2 z = seq(0, 1.6, .01) hz = pk[&quot;0&quot;] + pk[&quot;1&quot;]*z + pk[&quot;2&quot;]*z^2 plot.fun(z,hz) abline(h = d, col = &quot;green&quot;) abline(v = d, col = &quot;green&quot;) Figure 7.15: ?? Extinction and non-extinction revisited If \\(m &gt; 1\\), there exists \\(d\\) bigger than 0 and less than unity. This means there’s some positive chance of extinction. But also some chance of never-extinction. (What form does never-extinction take?) suppressWarnings(matplot(t(Z.mat), log = &quot;y&quot;, type = &quot;l&quot;, lty = 1, ylab = &quot;Zn&quot;, xlab = &quot;n&quot;)) Figure 7.16: Generation sizes (log-scale) over many generations Relevance to Corona virus? 7.12 Good and bad set-ups for branching process .column-left{ float: left; width: 50%; text-align: left; } .column-right{ float: right; width: 50%; text-align: left; } Good Unrestricted growth (frontier, new disease, start of a reaction) A “null” model for understanding how apparent structure is just random outcomes. Families that die out didn’t have to have low \\(NRR\\). Just because most new viruses don’t break out, doesn’t mean they aren’t potentially dangerous (\\(R_0 &gt;&gt; 1.0\\)). A model that corresponds our mental model of running a generative process forward. (cf. Fisher-Wright) Bad When offspring of 1 depends on offspring of other (e.g., brothers inheriting a farm) When resource constraints slow growth rates (e.g., Malthus: fertility of next gen depends on fertility of last; SIR model in disease spread) Analysis. PGF is powerful but still we often have to deal with listing all possibilities. Big populations – law of large numbers means randomness doesn’t matter. 7.13 The distribution of offspring of all generations Means of offspring in generation \\(n\\) Is it “meaningful”? It tells you about the average number of offspring but it might be a skewed distributions because of the large number of zeros. We’ll show that unconditional mean is the expectation of random sum, which in this case is the expectation of a product. \\[ \\mathbb{E} Z_n = m^n \\] What if \\(m = 1\\)? Mean size of surviving lines? Total probability is sum of conditional probabilities, times the chance of each condition: \\[ \\mathbb{E} Z_n = \\mathbb{E}( Z_n | Z_n &gt; 0) P(Z_n &gt; 0) + \\mathbb{E}( Z_n | Z_n = 0) P(Z_n = 0) \\] where \\(\\mathbb{E}( Z_n | Z_n &gt; 0) P(Z_n &gt; 0)\\) is the expected size given no extinction and \\(\\mathbb{E}( Z_n | Z_n = 0) P(Z_n = 0)\\) is the expected size given extinction. What is mean size of surviving lines? That is, we want to find \\(\\mathbb{E}( Z_n | Z_n &gt; 0)\\) Hint 1: \\(P(Z_n = 0) = d_n\\), So \\(P(Z_n &gt; 0) = 1- d_n\\) Hint 2: \\(\\mathbb{E} Z_n = m^n\\) Also note that by definition, \\(\\mathbb{E}( Z_n | Z_n = 0)=0\\) \\[ \\begin{aligned} \\mathbb{E} Z_n = m^n = &amp; \\mathbb{E}( Z_n | Z_n &gt; 0) (1- d_n) + (0)d_n\\\\ m^n = &amp; \\mathbb{E}( Z_n | Z_n &gt; 0) (1- d_n)\\\\ \\mathbb{E}( Z_n | Z_n &gt; 0) =&amp;\\frac{m^n}{(1- d_n)} \\end{aligned} \\] Let’s check our result using simulation for 1000 trials. Note that for this case \\(m= 0\\times p_0 + 1\\times p_1 + 2\\times p_2= 1\\), so \\(m^n= 1\\) n_trials = 1000; n_gen = 100 p0 = .3; p1 = .4; p2 = .3 ## what is m? p_k &lt;- c(p0, p1, p2) k &lt;- 0:(length(p_k)-1) Z.mat &lt;- matrix(NA, n_trials, n_gen) set.seed(131) for (i in 1:n_trials) Z.mat[i,] &lt;- branch(n_max = n_gen) Zn_bar = apply(Z.mat, 2, mean) matplot(t(Z.mat), type = &quot;l&quot;, lty = 1, ylab = &quot;Zn&quot;, xlab = &quot;n&quot;) Figure 7.17: Extinction simulation Zn_bar = apply(Z.mat, 2, mean) #expected value Z_n (E(Z_n)) n &lt;- 1:ncol(Z.mat) proportion.zero &lt;- function(x){prop.table(table(x == 0))[&quot;TRUE&quot;]} d_n = apply(Z.mat, 2, proportion.zero) # fraction extinct Z.mat.na &lt;- Z.mat; Z.mat.na[Z.mat == 0] &lt;- NA Zn_surv_bar = apply(Z.mat.na, 2, mean, na.rm = T) #expected value of survivors (E(Z_n|Z_n&gt;0)) Using the means for all 1000 simulations, we calculate \\(\\mathbb{E} Z_n\\) (left plot), \\(d_n\\) (center plot) and \\(\\mathbb{E}( Z_n | Z_n &gt; 0)\\). par(mfrow = c(1,3)) plot(n, Zn_bar, main = &quot;Mean Zn&quot;) plot(n, d_n, main = &quot;Fraction extinct&quot;) plot(n, Zn_surv_bar, main= &quot;Mean Zn given Zn&gt;0&quot;) Figure 7.18: Extinction simulations ## insert code here for Zn_surv_bar.hat and add a line 7.13.1 Proving \\(\\mathbb{E} Z_n = m^n\\) Ingredients \\(h(z)=p_{0}+p_{1}z+ p_{2} z^2+ \\ldots\\) \\(h&#39;(z)=p_{1}+ 2zp_{2} + \\ldots\\) Specifically, when \\(z=1\\): \\(h(1)= 1\\) \\(h&#39;(1) =(1)p_1+ (2)p_2+(3)p_3+\\ldots= \\sum_1^k k p_k = m = \\bar{Z}\\) \\(h_n&#39;(1) = m_n = \\bar{Z}_n\\) \\(h_{n+1}(z) = h(h_n(z))\\) Derivation: Take derivative of \\(h_{n+1}(z)\\) \\[ \\begin{aligned} h&#39;_{n+1}(z)&amp;= h&#39;_n(h(z)) h&#39;(z) \\\\ h&#39;_{n+1}(1)&amp;= h&#39;_n(h(1)) h&#39;(1) \\\\ &amp;= h&#39;_n(1) m \\\\ &amp;= \\bar{Z}_n m \\end{aligned} \\] NOTE: Can’t find the complete derivation. Help! 7.13.2 Variance result. We proved that \\(\\mathbb{E} Z_n = m^n\\) using recursion. For the variance, one can also do recursion but this time we start by taking the second derivative of \\(h(z)\\) For \\(m = 1\\), \\[ \\sigma_n^2 = n \\sigma^2 \\] Also a result for \\(m\\neq 1\\) What does increasing variance mean for critical case? (Does this make sense?) What happens to variance of lines that survive? Is it bigger or smaller than unconditional variance? Variance in our simulation increases with generation number: var_Zn = apply(Z.mat, 2, var) n &lt;- 1:ncol(Z.mat) plot(n, var_Zn, xlab = &#39;variance of Zn&#39;) Figure 7.19: Distribution of \\(Z_n\\) Z20 &lt;- table(table(Z.mat[,20])) Z5 &lt;- table(table(Z.mat[,5])) par(mfrow = c(2,2)) plot(Z20[Z20 &lt; 100]) plot(log(Z20[Z20 &lt; 100])) plot(Z5[Z5 &lt; 100]) plot(log(Z5[Z5 &lt; 100])) Figure 7.20: Histogram of selected \\(Z_n\\) 7.14 Geometric offspring distribution For \\(k = 1, 2, \\ldots\\), \\[ p_k = b c^{k-1} \\] For \\(k = 0\\), \\[ p_0 = 1 - p_1 - p_2 - \\ldots . \\] Let’s solve for \\(p_0\\), using the geometric series sum, for \\(a &lt; 1\\), \\[ 1 + a + a^2 + \\ldots = 1 / (1-a) \\] \\[ \\begin{aligned} p_0 &amp;= 1 - (p_1 + p_2 + p_3 +\\ldots) \\\\ &amp;= 1 - (bc^{0}+ bc^{1} +b c^{2} + \\ldots) \\\\ &amp;= 1 - (b+ bc^{1} +b c^{2} + \\ldots) \\\\ &amp;= 1 - b(1+ c^{1} + c^{2} + \\ldots) \\\\ &amp;= 1- \\frac{b}{1-c} \\\\ \\end{aligned} \\] So, now we have all \\(p_k\\) used as inputs for \\(h(z)\\) given value for \\(b\\) and \\(c\\). A picture, Lotka’s parameters for 1920. The graph shows the probability of having exactly \\(k\\) number of girls. When \\(k=0\\) then all children were boys. b = 0.2126 ; c = 0.5893 kk = 1:10 ; p_kk = b * c^(kk-1) p0 = b/(1-c) k = c(0, kk) ; p_k = c(p0, p_kk) Figure 7.21: probability of having exactly \\(k\\) number of girls Realism? See Table 10.3, p 386, (“Introduction to Probability” 2006) 7.14.1 The Geometric Distribution’s simple PGF \\[ h(z) = p_0 + p_1 z + p_2 z^2 + \\ldots \\] With geometric \\(p_k\\) \\[ h(z) = p_0 + \\sum_{k= 1}^\\infty b c^{k-1} z^k. \\] Substituting for \\(p_0\\) and rewriting \\[ h(z) = \\left( 1 - \\frac{b}{(1-c)}\\right) + bz \\sum_{k= 1}^\\infty (cz)^{k-1}. \\] Substituting \\(j = k-1\\), \\[ h(z) = \\left( 1 - \\frac{b}{(1-c)}\\right) + bz \\sum_{j= 0}^\\infty (cz)^{j} = \\left( 1 - \\frac{b}{(1-c)}\\right) + {bz \\over (1 - cz)} \\] The PGF is now “tractable” \\(m\\) and extinction \\[ h(z) = \\left( 1 - {b / 1-c}\\right) + {bz \\over 1 - cz} \\] Please solve for \\(m\\). (Hint: \\(h&#39;(1)\\)). We kmow that \\(h&#39;(1)=m\\), so we start off taking the first derivative of \\(h(z)\\) given the tractable form. \\[ \\begin{aligned} h&#39;(z) &amp;= \\frac{bz(-c)-(1-cz)b}{(1-cz)^2}\\\\ &amp;= \\frac{-1}{(1-cz)^2}\\\\ h&#39;(1) &amp;= \\frac{-1}{(1-c)^2} = m\\\\ \\end{aligned} \\] What is \\(m\\) with Lotka’s \\(b\\) and \\(c\\)? \\[ m= \\frac{-1}{(1-0.5893)^2}= 5.928579 \\] NOTE: does this look reasonable? We solve \\(z = h(z)\\) with a bunch of algebra to get \\[ d = {1 - b - c \\over c(1-c)} \\] How does \\(d\\) depend on \\(b\\) and \\(c\\)? \\(d\\) decreases with \\(b\\) at a rate of \\(\\frac{-1}{c(1-c)}\\) and changes at rate \\(\\frac{-(1-b)(1-2c)-c^2}{c^2(1-c)^2}\\). Big payoff: the full distribution of \\(Z_n\\) (See (“Introduction to Probability” 2006) p. 385) 7.14.2 A plot of Keyfitz’s numbers for generations 1, 2, and 3. Is it exponential for \\(k &gt; 0\\)? ## b = 0.2126 ; c = 0.5893 ## lotka b = 0.3666; c = .5533 ## Keyfitz (from GS) m = b / (1-c)^2 ## [1] 1.260416 d = (1 - b - c) / (c * (1-c)) #[1] 0.8185088 par(mfrow = c(1,2)) for (i in 1:3) { n = i p0_n = d * (m^n - 1)/ (m^n -d) j = kk pj_n = m^n * ((1-d) / (m^n - d))^2 * ((m^n - 1)/(m^n - d))^(j-1) pk_n &lt;- c(p0_n, pj_n) if (i == 1) plot(k, pk_n, type = &quot;l&quot;, log = &quot;&quot;, main=&quot;Absolute&quot;) if (i &gt; 1) lines(k, pk_n, col = i) } for (i in 1:3) { n = i p0_n = d * (m^n - 1)/ (m^n -d) j = kk pj_n = m^n * ((1-d) / (m^n - d))^2 * ((m^n - 1)/(m^n - d))^(j-1) pk_n &lt;- c(p0_n, pj_n) if (i == 1) plot(k, pk_n, type = &quot;l&quot;, log = &quot;y&quot;, main=&quot;Log scaled&quot;) if (i &gt; 1) lines(k, pk_n, col = i) } Figure 7.22: Keyfitz’s plot for generations 1, 2, and 3 Applications We have exponential distribution with a few very large lines, and a lot of small lines. Distribution of neutral alleles Distribution of family lines (Y-chromosome, mtDNA, last names) Our result With geometric \\(p_k\\), we get geometric \\(Z_n\\), for all \\(n\\). Conjecture: geometric is to BP as gamma is to frailty? 7.15 Branching Processes and Covid-19 What is the BP that they are studying? Is it contagion, social contacts, or ? What do they assume about the BP? Do they use any analytical results or just simulation? Why? Best feature of paper? Worst feature of paper? Inspire any other approaches? 7.16 Problems For the following problems, let \\(p_0 = 0.3\\), \\(p_1=0.3\\), \\(p_2=0.4\\). Use the function \\(h(z) = p_0 + p_1 z + p_2 z^2\\). This gives \\(m= 0.3(0) + 0.3(1) + 0.4(2) = 1.1\\), which is supercritical. Multiply out \\(h(z)^3\\) algebraically and explain how the coefficient on \\(z^4\\) consists of all of the possible ways for 3 fathers to produce a total of 4 sons Multiply out \\(h_2(z) = h(h(z))\\) algebraically and explain how the coefficient on \\(z^2\\) consists of all of the possible ways for a woman to have 2 grand-daughters. Write an R-program to reproduce 20 entries of the table (This is for our values of \\(p_0 = 0.3\\), \\(p_1=0.3\\), \\(p_2=0.4\\), not the \\(p_k\\) values on wikipedia) Use the quadratic formula to solve for \\(d\\), the probability of ultimate extinction: \\(d = p_0 + p_1d + p_2d^2\\). What do you get for \\(d\\) given our \\(p_k\\) values above? Does it correspond to the same value one gets by using iteration, as in the Wikipedia table? Simulate a critical branching process such that m = 1 by reversing the \\(p_1\\) and \\(p_2\\) values we’re using. Check that \\(m = 1\\). You can use the “branch()” code in the slides. See if you can do a big number of trials, 1000? For many generations, 30, 50, 100? What fraction of lines become extinct? What is the distribution of surviving lines? (Hint: Choose a time that is is not so distant that few lines survive) What is the mean and variance of of \\(Z_{10}\\), \\(Z_{20}\\) and \\(Z_{30}\\)? What will happen as \\(n \\to \\infty\\)? 7.17 Solutions For the following problems, let \\(p_0 = 0.3\\), \\(p_1=0.3\\), \\(p_2=0.4\\). Use the function \\(h(z) = p_0 + p_1 z + p_2 z^2\\). This gives \\(m= 0.3(0) + 0.3(1) + 0.4(2) = 1.1\\), which is supercritical. 1. Multiply out \\(h(z)^3\\) algebraically and explain how the coefficient on \\(z^4\\) consists of all of the possible ways for 3 fathers to produce a total of 4 sons Finding \\(h(z)^2\\): \\[\\begin{aligned} h(z)^2 &amp;= (p_0 + p_1 z + p_2 z^2)\\times(p_0 + p_1 z + p_2 z^2) \\\\ &amp;= p_0^2+2p_0p_1z+(2p_0p_2+p_1^2)z^2 + 2p_1p_2z^3 + p_2^2z^4 \\end{aligned}\\] Multiplying out again: \\[\\begin{aligned} h(z)^3 &amp;= h(z)^2 h(z) \\\\ &amp;= [p_0^2+2p_0p_1z+(2p_0p_2+p_1^2)z^2 + 2p_1p_2z^3 + p_2^2z^4]\\times(p_0 + p_1 z + p_2 z^2) \\\\ &amp;= p_0^3 + (3p_0^2p_1)z + (3p_0^2p_2 + 3p_0p_1^2)z^2 +(6p_0p_1p_2+p_1^3)z^3 + \\\\ &amp; (3p_0p_2^2+3p_1^2p_2)z^4+ (3p_1p_2^2)z^5 + (p_2^3)z^6\\\\ \\end{aligned}\\] To get a total of 4 children, either two of the fathers have 2 sons each and the third has no sons (\\(p_0p_2^2\\)), or one of the fathers has 2 sons and the others each have 1 son (\\(p_1^2p_2\\)). With three fathers, there are 3 ways for each of these combinations to appear; corresponding to the \\(3p_0p_2^2+3p_1^2p_2\\) coefficient on \\(z^4\\). 2. Multiply out \\(h_2(z) = h(h(z))\\) algebraically and explain how the coefficient on \\(z^2\\) consists of all of the possible ways for a woman to have 2 grand-daughters. \\[\\begin{aligned} h(h(z)) &amp; = p_0+p_1h(z)+p_2h(z)^2 \\\\ &amp; = p_0 +p_1[p_0 + p_1 z + p_2 z^2] + p_2[p_0^2+2p_0p_1z+(2p_0p_2+p_1^2)z^2 + 2p_1p_2z^3 + p_2^2z^4] \\\\ &amp;= [p_0+p_0p_1+p_0^2p_2] + [2p_0p_1p_2+p_1^2]z +\\\\ &amp; [2p_0p_2^2+p_1p_2+p_1^2p_2]z^2 + [2p_1p_2^2]z^3+[p_2^3]z^4 \\end{aligned}\\] Here are the ways a woman can end up with 2 granddaughters: first, she can have a single daughter who herself has 2 daughters (\\(p_1p_2\\)). Or, she can have 2 daughters who then each have 1 daughter (\\(p_1^2 p_2\\)). Lastly, she can have 2 daughters, one of which has 2 daughters and one who has no daughters (\\(2p_0 p_2^2\\); note there are two ways for this to happen because there are two daughters in the second generation). These possibilities correspond to the \\(2p_0p_2^2+p_1p_2+p_1^2p_2\\) coefficient on \\(z^2\\) 3. Write an R-program to reproduce 20 entries of the table (This is for our values of \\(p_0 = 0.3\\), \\(p_1=0.3\\), \\(p_2=0.4\\), not the \\(p_k\\) values on wikipedia) Generation Number Extinction probability Generation Number Extinction probability 1 0.30000 11 0.68599 2 0.42600 12 0.69403 3 0.50039 13 0.70088 4 0.55027 14 0.70676 5 0.58620 15 0.71183 6 0.61331 16 0.71623 7 0.63446 17 0.72006 8 0.65135 18 0.72342 9 0.66511 19 0.72636 10 0.67648 20 0.72895 — — — — The extinction probability is converging to 0.75 (going out to 50 or 60 generations is helpful for observing this). Sample code: d_zero &lt;- 0 p_zero &lt;- 0.3 p_one &lt;- 0.3 p_two &lt;- 0.4 n_gen &lt;- 20 value_table &lt;- matrix(0, nrow = n_gen, ncol = 2) d_prev &lt;- d_zero for (i in 1:n_gen) { prob_extinction &lt;- p_zero + d_prev*p_one + (d_prev^2)*p_two value_table[i,1] = i value_table[i, 2] = prob_extinction d_prev &lt;- prob_extinction } Use the quadratic formula to solve for \\(d\\), the probability of ultimate extinction: \\(d = p_0 + p_1d + p_2d^2\\). What do you get for \\(d\\) given our \\(p_k\\) values above? Does it correspond to the same value one gets by using iteration, as in the Wikipedia table? Do some rearranging of \\(d = p_0 + p_1d + p_2d^2\\) to get: \\[0 = p_2d^2 +(p_1-1)d + p_0 \\] Solving with the quadratic formula: \\[ d^* = {(1-p_1) \\pm \\sqrt{(p_1-1)^2 - 4p_2p_0} \\over 2p_2 } \\] Filling in our given \\(p_k\\) values: \\[\\begin{aligned} d^* &amp;= \\frac{(1-0.3) \\pm \\sqrt{(0.3-1)^2 -4(0.4)(0.3)}}{2(0.4)} \\\\ &amp;= \\{0.75, 1\\} \\end{aligned}\\] Since \\(m&gt;1\\), there are two roots: 1 and 0.75. \\(d=0.75\\) is the solution we are interested in, and it indeed agrees with the probability of the extinction that our iterative solution converges to. Simulate a critical branching process such that m = 1 by reversing the \\(p_1\\) and \\(p_2\\) values we’re using. Check that \\(m = 1\\). You can use the “branch()” code in the slides. Let \\(p_0=0.3\\), \\(p_1 =0.4\\), \\(p_2=0.3:\\)m = 0(0.3) + 1(0.4)+2(0.3) = 1$. See if you can do a big number of trials, 1000? For many generations, 30, 50, 100? Sample simulation with 1000 trials for 100 generations (seed set to 91): Figure 7.23: Branch simulation What fraction of lines become extinct? 96.6% of lines become extinct by generation 100 with the above simulation. The following plot shows extinction at each generation: Figure 7.24: Rate of extinction What is the distribution of surviving lines? (Hint: Choose a time that is is not so distant that few lines survive) The following histograms show surviving lines’ sizes at select generations. At each generation, we can see something resembling a geometric distribution. Figure 7.25: Surviving generations What is the mean and variance of of \\(Z_{10}\\), \\(Z_{20}\\) and \\(Z_{30}\\)? What will happen as \\(n \\to \\infty\\)? Generation \\(n\\) Mean \\(Z_n\\) Var \\(Z_n\\) 10 1.009 5.20001 20 1.012 10.7426 30 0.991 17.53045 &lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;/hdir/0/andreamg/Year2_2019_2020/Random_demography/random_demography/bookdown-master/figures/meanvar.png&quot; alt=&quot;Survival mean and variance&quot; width=&quot;100%&quot; /&gt; &lt;p class=&quot;caption&quot;&gt;(\\#fig:unnamed-chunk-135)Survival mean and variance&lt;/p&gt; &lt;/div&gt; The mean and variance calculated above account for all lines, not just surviving ones. In this simulation, the mean tends to hover around 1 and the variance tends to increase with generation number, at least up to a certain point. As \\(n\\to \\infty\\), the mean and variance theoretically will go to zero (since \\(m=1\\) is critical, all lines must eventually die out). References "],
["fisher-wright.html", "Chapter 8 Fisher-Wright 8.1 Outline 8.2 Parallel 8.3 Mutation 8.4 Fixation 8.5 Baby Names 8.6 Now we can simulate babynames 8.7 Conclusions", " Chapter 8 Fisher-Wright 8.1 Outline COVID Fisher Wright vs Galton Branching Process FW with mutation Extinction Application: Baby Names Additional resources: Blog “Introduction to the Wright-Fisher Model” https://stephens999.github.io/fiveMinuteStats/wright_fisher_model.html#pre-requisites Hahn and Bentley (2003): Evolutionary anthropologists arguing that the neutral explanation of the Fisher-Wright model is consistent with the distribution of 1st names. What other quantitative or qualitative features of 1st name fashion could be used to try to reject the neutral model? Felsenstein (2005): Very complete “lecture notes” for graduate genetics course. Lots of good commentary, does not assume a lot of math background, but lots of content and can be diffcult to read a piece by itself. 8.2 Parallel .column-left{ float: left; width: 50%; text-align: left; } .column-right{ float: right; width: 50%; text-align: left; } Fisher-Wright Children picking their parents (not “generative”) Total population size is constant: process goes backwards Qualitatively similar to BP. Extinction and fixation. Flexible: mutation, selection, even changes in pop size. With apologies, biologists take FW “seriously” even if they don’t take it “literally”. Galton-Watson-Bienaymè Branching Processe Branching process models independent parents randomly producing offspring. “Generative” Total population size can vary, and has a random component and deterministic one \\(m\\) Qualitative result when \\(m = 1\\) is that there is one longest surviving line. This is “fixation”, when one type becomes universal. 8.2.1 Another cell phone example As in the Branching Processes chapter, let’s simulate the creation of generations using the numbers of cell-phone numbers (which are random). For this case, we need as many cell phone numbers as the generations to create, but each next cell phone number is a combination of digits from the first cell phone number. Let these ficticious cell phone numbers be: 731 660 5362 and 530 666 7723. Note how the second number does not contain any 4s, 8s or 9s. Generation 1 starts off with a sequence of numbers from 0 to 9. Then for generation 2, we assign each digit of the cell phone to one of cells. We repeat this for generation 3 but with the second cell phone number. knitr::kable( cbind(c(1:3), rbind(c(0:9),c(7, 3, 1, 6, 6, 0, 5, 3, 6, 2), c(5, 3, 0, 6, 6, 6, 7, 7, 2, 3))), col.names = c(&#39;generation #&#39;, &#39;allele type&#39;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;))%&gt;% kableExtra::kable_styling(full_width = F) generation # allele type 1 0 1 2 3 4 5 6 7 8 9 2 7 3 1 6 6 0 5 3 6 2 3 5 3 0 6 6 6 7 7 2 3 If we translate this graph into a tally of the alleles by generation we see that some alleles are passed/‘’survive’’ more than others. knitr::kable( cbind(c(1:9), c(rep(1,9)), c(1, 1, 2, 0, 1, 3, 1, 0, 0), c(1, 1, 2, 0, 1, 3, 2, 0, 0)), col.names = c(&#39;Allele type&#39;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;)) %&gt;% add_header_above(c(&quot; &quot; = 1, &quot;Count per generation&quot; = 3))%&gt;% kableExtra::kable_styling(full_width = F) Count per generation Allele type 1 2 3 1 1 1 1 2 1 1 1 3 1 2 2 4 1 0 0 5 1 1 1 6 1 3 3 7 1 1 2 8 1 0 0 9 1 0 0 Here, allele type 6 will most likely dominate. This means that everybody will likely become similar and that individual types disappear. NOTE FOR JOSH: does this explanation make sense? I had a hard time following the cell-phone number example in class so my notes are incomplete. Also, it’s not so straightforward to me how the “Children are choosing their parents here”. Could you explain this more? 8.3 Mutation Let’s simulate the process from the example below. We first present some useful functions. fwm &lt;- function(N, n_gen, mu = 0) ## mu != 4/N { ## simulate fisher-wright (with mutations) x &lt;- paste(1:N) ## starting types A &lt;- matrix(NA, nrow = n_gen, ncol = N) for (i in 1:n_gen) { A[i,] &lt;- x x &lt;- sample(x, size = N, replace = T) # Sample from previous generation and draw with replacement x &lt;- mut(x, mu) x } return(A) ## matrix of types, each line a generation. } # Function to detect number of mutations. This occurs with probability mu. mut &lt;- function(x, mu) { ## m, the individuals that mutate m &lt;- which(rbinom(length(x), size= 1, prob = mu) == 1) if (length(m) == 0) ## if no-one mutates return(x) ## add a suffix to their ID, so it will be unique (infinite alleles) suffix &lt;- 10000*round(runif(length(m)),4) x[m] &lt;- paste0(x[m], &quot;.&quot;, suffix) x } Here we try it out. - Each row is a generation and each column is a type of allele. - Notice that already by the third generation, there are several numbers that are not drawn anymore: 3,4,6,8,9. set.seed(1) fwm(N = 10, n_gen = 6, mu = 0) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; &quot;8&quot; &quot;9&quot; &quot;10&quot; ## [2,] &quot;9&quot; &quot;4&quot; &quot;7&quot; &quot;1&quot; &quot;2&quot; &quot;7&quot; &quot;2&quot; &quot;3&quot; &quot;1&quot; &quot;5&quot; ## [3,] &quot;2&quot; &quot;5&quot; &quot;7&quot; &quot;5&quot; &quot;2&quot; &quot;1&quot; &quot;2&quot; &quot;2&quot; &quot;1&quot; &quot;1&quot; ## [4,] &quot;2&quot; &quot;2&quot; &quot;5&quot; &quot;1&quot; &quot;1&quot; &quot;2&quot; &quot;5&quot; &quot;7&quot; &quot;1&quot; &quot;1&quot; ## [5,] &quot;1&quot; &quot;2&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;5&quot; &quot;2&quot; &quot;1&quot; &quot;7&quot; ## [6,] &quot;1&quot; &quot;5&quot; &quot;2&quot; &quot;1&quot; &quot;7&quot; &quot;5&quot; &quot;1&quot; &quot;7&quot; &quot;1&quot; &quot;2&quot; The graph below shows a simulation of 20 generations each of size 10. The colors represent different types drawn in each generation. set.seed(1) A &lt;- fwm(N = 10, n_gen = 20, mu = 0) tt &lt;- table(A, row(A)) ## count types by row ptt &lt;- prop.table(tt, 2) ## proportions Figure 8.1: Generation composition Let’s analyze it more. By generation 5, many of the lines are flat (ocurrence = 0%) which means that they go extinct and the following generations can only select types from a reduced sample. For instance line “5” (pink) is selected until generation 10. Around generation 7, it becomes the most prevalent type but then falls as other types are drawn relatively more. As we are looking at the ocurrence in samples were types disappear, the rises and falls in lines are indicate the substitution of numbers as some go extinct. By generation 15, all draws are 2s and the other numbers do not ‘’survive’’ \\(E(p_i(t) | p_i(t-1))\\) is the likelihood that the same number (type) will be drawn given that it was drawn before. NOTE TO JOSH: is this really what the expectation means? Not on slides This time, let’s increase the number of generations (200) and the number of types drawn at every step. In the long run, many of the colored lines disappear and the generations are composed of a handful of types. set.seed(1) A &lt;- fwm(N = 100, n_gen = 200, mu = 0) tt &lt;- table(A, row(A)) ## count types by row ptt &lt;- prop.table(tt, 2) ## proportions Figure 8.2: Generation composition long term 8.4 Fixation Given that we saw before that some of the lines will disappear, we can look about keeping some of the lines fixed (that it will always be selected). For instance, What is probability that line \\(i\\) will “fix”? What is expected time until some line fixes? How can we describe the path to fixation? 8.4.1 Probability that a particular line will “fix” NOTE TO JOSH: the slide said that finding this was easy but I don’t necessarily see how the result from the graph goes with the formula below. set.seed(1) A &lt;- fwm(N = 10, n_gen = 20, mu = 0) tt &lt;- table(A, row(A)) ## count types by row ptt &lt;- prop.table(tt, 2) ## proportions matplot(t(ptt), type = &#39;l&#39;, lty = 1, main = &quot;FW simu&quot;) text(x = 4, y = jitter(ptt[,4]), rownames(ptt), col = 1:6) Figure 8.3: Time to fix 8.4.2 Expected time until fixation? Answer for us is \\[ \\bar{T}_{fixed} = 2 \\cdot N \\] Note: Biologists say \\(4 N_e\\). See Wikipedia “Genetic drift” Now we carry out simulations of complete processes. In total, we draw 100 times each generation in order to get the time to fixation. For this example, the mean number of generations taken to get only one remaining line is 202 generations \\(\\approx 2 \\times\\) the starting generation size. T.vec &lt;- NULL all.the.same &lt;- function(x){length(unique(x)) == 1} set.seed(10) for (i in 1:100) # 100 simulations { A &lt;- fwm(N = 100, n_gen = 1000,mu = 0) # generation process: rows are generations and columns are types extinction_time = min(row(A)[apply(A, 1, all.the.same)]) # obtain the first generation when all but one line went extinct T.vec[i] &lt;- extinction_time } mean(T.vec) ## [1] 202.89 8.4.3 Path to fixation: a measure of homogeneity/heterogeneity How does the type change over time? We would like a measure of equality of the types of populations. A low measure would mean that the population is homogeneous while a high measure implies population heterogeneity. Let the chance that two randomly drawn individuals are of same type be: \\[ G = \\sum_i p_i^2 \\] If we have two types, \\(p_1 = \\pi\\) , \\(p_2 = 1-\\pi\\). What is G if \\(\\pi = 0, .5, 1\\)? type_fun &lt;- function(pi_vector){ oneminus_pi &lt;- 1-pi_vector G &lt;- pi_vector^2 + oneminus_pi^2 return(plot(pi_vector, G, type=&quot;l&quot;, xlab = &quot;Probability type&quot;, col=&quot;red&quot;)) } pi_vector &lt;- seq(0,1,0.1) type_fun(pi_vector) Figure 8.4: Probability of being the same type Let’s derive time path of G. Assume just two types, \\(\\pi(t)\\) The chance that two individuals are of same type \\[G_{t+1} = P(\\mbox{same parent})\\cdot 1 + P(\\mbox{different parent})\\cdot G_{t}\\] Notation: I’m going use K for pop size. Bio uses 2N. The probability of having the same parent is \\(P(\\mbox{same parent}) = \\frac{1}{K}\\), where \\(K\\) is the population size. This also implies that anybody in the population can be a parent with equal probability. Additionally, \\(P(\\mbox{different parent}) = 1- P(\\mbox{same parent}) = 1- \\frac{1}{K}\\) Then, \\[G_{t+1} = \\left(\\frac{1}{K}\\right) \\cdot 1 + \\left(1 - \\frac{1}{K}\\right) \\cdot G_{t}\\] For simplicity, let \\(H = 1 - G\\): \\[ \\begin{aligned} 1 - H_{t+1} &amp; = {1 \\over K} + \\left(1 - {1 \\over K} \\right) \\cdot (1-H_{t})\\\\ &amp; = {1 \\over K} + 1 - H_{t} - {1\\over K}+ {1\\over K} H_{t} \\\\ H_{t+1} &amp; = H_{t} - {1\\over K} H_{t} \\\\ H_{t+1} &amp; = H_{t} (1 - 1/K) \\end{aligned} \\] For many periods, we start at the initial probabilities. \\[ H_{t} = H_0 (1 - 1/K)^t \\rightarrow H_0 e^{-t/K} \\] So, H goes to 0 exponentially, just as G goes to 1. 8.5 Baby Names For this section we will look at an application of changes in baby names from this paper: “Drift as a mechanism for cultural change: an example from baby names” by Matthew W. Hahn and R. Alexander Bentley Proc. R. Soc. Lond. B 2003 270, S120-S123 8.5.1 Basic idea The process seems to be like Fisher-Wright because: people choose from existing set names are “neutral” draw proportionally Authors test to see if they can reject FW by comparin observed histograms to FW simulation They include mutation to get a stationary distribution. Note: failing to reject FW doesn’t mean it’s correct Source: Hahn and Bentley (2003) 8.5.2 Fisher-Wright simulation of Baby Names (Hahn and Bentley) We download and prepare the data: download.file(url= &quot;https://www.ssa.gov/oact/babynames/names.zip&quot;, &quot;./names.zip&quot;) unzip(&quot;names.zip&quot;, exdir = &quot;./names&quot;) library(data.table) filenames &lt;- system(&quot;ls ./names/*.txt&quot;, intern = T) mylist &lt;- vector(&quot;list&quot;, length(filenames)) names(mylist) &lt;- gsub(pattern = &quot;[^0-9]&quot;, replace = &quot;&quot;, filenames) for (i in 1:length(filenames)) { myfile &lt;- filenames[i] mylist[[i]] &lt;- fread(myfile) } # Final dataframe dt &lt;- rbindlist(mylist, idcol = &quot;year&quot;) names(dt) &lt;- c(&quot;year&quot;, &quot;name&quot;, &quot;sex&quot;, &quot;N&quot;) ## Focus on male names from 1900-1909 my.dt &lt;- dt[sex == &quot;M&quot; &amp; year %in% 1900:1909] foo &lt;- my.dt[, .(N = sum(N)), by = name] foo &lt;- foo[order(N, decreasing = T)] bar &lt;- foo[1:1000,] ## 1000 top names # Observed histogram of name occurence my.breaks &lt;- c(0, 2^(0:11)/10000) bar[, p := round(prop.table(N),5)] # N column contains the share of times that a name is used bar[, pcat := cut(p, breaks = my.breaks, right = F, include.lowest = T)] out &lt;- unclass(prop.table(table(bar$pcat))) my.x &lt;- my.breaks[-length(my.breaks)] + diff(my.breaks)/2 Then we look at observed frequencies and they seem to behave as a power law (in log-log) plot(my.x, out, log = &quot;xy&quot;, xlab=&quot;Frequency of name&quot;, ylab= &quot;log(share)&quot;) Figure 8.5: Power 8.5.3 Drawing their picture with simulation Let’s look at evolution over time of G: chance that two individuals are of same type. get.G &lt;- function(x) { tt &lt;- table(x) p &lt;- prop.table(tt) sum(p^2) } First we look at the case were there is no mutation A &lt;- fwm(1000, n_gen = 4000, mu = 0) G.vec &lt;- apply(A, 1, get.G) plot(G.vec, ylab = &quot;G&quot;, xlab= &quot;# Generation&quot;, type =&quot;l&quot;) Figure 8.6: G path (without mutation) With mutation a single trial shows that the G value oscillates a lot around 0.1. N = 1000 A &lt;- fwm(N, n_gen = 3000, mu = 4/N) G.vec &lt;- apply(A, 1, get.G) plot(G.vec, ylab = &quot;G&quot;, xlab= &quot;# Generation&quot;, type =&quot;l&quot;) Figure 8.7: G path (with mutation, 1 trial) We can increase the number of trials (up to 100 here) and look at the average (yellow horizontal line). n_gen = 2000 n_trials = 100 G.mat &lt;- matrix(NA, n_trials, n_gen) for (i in 1:n_trials) { N = 1000 A &lt;- fwm(N, n_gen, mu = 4/N) G.vec &lt;- apply(A, 1, get.G) G.mat[i,] &lt;- G.vec } G.bar &lt;- apply(G.mat, 2, mean) matplot(t(G.mat), type = &quot;l&quot;, ylab = &quot;G&quot;, xlab= &quot;# Generation&quot;) lines(G.bar, lwd = 4) abline(h = 1/9, lty = 3, col = &quot;yellow&quot;, lwd = 5) Figure 8.8: G path (with mutation, 100 trials) Why is the mean about .11? 1/(1 + 8) Gillespie tells us that \\(\\bar{G}\\) is supposed to be \\(\\frac{1}{(1 + 4*Ne*\\mu)}\\) How does \\(4*Ne*\\mu = 8\\)? Well, we have \\(K*\\mu = 4\\) and since \\(K = 2*Ne\\), \\(Ne = K/2\\) (maybe) 8.5.4 FW babyname simulation of equilibrium frequencies NOTE TO JOSH: I don’t really know what is going on here and I noticed that the code mentions that it might not be (w)right. N = 1000 ## Not sure if this is (w)right :) mu = 4/N ## [1] 0.004 theta = N*mu ## [1] 4 ## H&amp;B&#39;s &quot;best fit&quot; 8.6 Now we can simulate babynames n_gen = 1001 N = 1000 ## set.seed(1) ## A &lt;- fwm2(N, n_gen, mu = 4/N) #A &lt;- fwm2(N, n_gen, mu = 8/N) ############### #What about the fwm2 function? ####################### A &lt;- fwm(N, n_gen, mu = 8/N) ## ok, lets do power law plot of this x &lt;- A[1001,] tt &lt;- table(x) ptt &lt;- prop.table(tt) my.breaks &lt;- c(0, 2^(0:11)/10000) p &lt;- ptt ## bar[, p := round(prop.table(N),5)] ##bar[, pcat := cut(p, breaks = my.breaks, right = F, include.lowest = T)] pcat = cut(p, breaks = my.breaks, right = F, include.lowest = T) out &lt;- unclass(prop.table(table(bar$pcat))) out.hat &lt;- unclass(prop.table(table(pcat))) my.x &lt;- my.breaks[-length(my.breaks)] + diff(my.breaks)/2 plot(my.x, out, log = &quot;xy&quot;) lines(my.x, out.hat) Figure 8.9: Baby Names Simulation 8.7 Conclusions Fisher-Wright an alternative to branching processes It reverses logic of reproduction, but gives similar quantitative and qualitative results A neutral model for other processes? Starting point for coalescent 8.7.1 Some potential criticism While we can’t reject that there’s some parameterization of FW that gives us similar disn, this doesn’t mean that we’ve found the right mechanism. (Just that we can’t reject it). What are some other tests of this mechanism? Markov assumption. We could see if each frequency really followed random walk. Perhaps we could see if variances were scaled to frequencies correctly. References "],
["coalescent.html", "Chapter 9 Coalescent 9.1 Outline 9.2 The Coalescent: Expectations of the Past 9.3 Our first question: When was MRCA? 9.4 Mutation and inference of TMRCA and \\(N\\) 9.5 Coalescence of a sample of \\(n\\) individuals 9.6 An application of coalescent theory 9.7 Reconstruction Ancient European Population Sizes using Batini’s sample of Mitochondrial DNA\"", " Chapter 9 Coalescent 9.1 Outline Big picture: What is “coalescent theory”? Time to (T)MRCA Simulation: Inferring population size An application of Coalescent Theory 9.2 The Coalescent: Expectations of the Past Coalescent theory is not a theory. It’s a model for the probability of different histories. Think about it as a model about how sampling can lead to a history of a common ancestor. “The” coalescent is a bit confusing. We’re not inferring the actual history of common ancestry, just the probabilities An actual “picture” Top panel is a Fisher-Wright instance, ordered so that lines don’t cross. Haplotype is a sequence (we are diploids, each contributing 2 haplotypes). Let’s just think of each line as an individual, for now. Such that each column is a different generation and the lines are the links across generations between dots. Each dot in the columns represents a “child” (or a parent to the next generation). The dark purple dots are 8 sampled individuals. We can find The Most Recent Common Ancestor (TMRCA) of sample. This is the red dot in the middle of the graph. We can make inferences on the entire population based on the sample of individuals. Our sample \\(\\neq\\) even all extant descendants of the MRCA. In other words, the sample is not an exhaustive set of the survivors Since some of the descendants of the pink lines don’t survive, then our sample \\(\\neq\\) all of the descendants of the MRCA. If we chose two descendants at random, would we always get same MRCA? When we model coalescence we are thinking backwards in time. 9.3 Our first question: When was MRCA? If we sample two individuals (today), how long ago was their MRCA? Note that we are not looking for “who” the MRCA is but rather the number of generations ago that they occurred. Our answer will be in terms of the probability of MRCA being 1 generation ago, 2 generations ago, etc. We’ll assume Fisher-Wright: constant N, each gen randomly picks parents. The answer is surprisingly simple. Let’s assume we have \\(N\\) lines in Fisher-Wright (Note: for now we are not using \\(2N\\).) As a reference, think about the population being the dots from the last column of the diagram from the last section. Then this sample is trying to look backwards \\(n\\) generations until they find their MRCA. The chance that two sampled people have same parent is \\(1/N\\). Thus, the probability of coalescence in the first generation is: \\(P(T_{MRCA} = 1) = 1/N\\). Explicitly, \\(T_{MRCA} = 1\\) means that the coalescence of lines occurs in the first generation. What’s the probability that coalescence occurs in the second generation? \\[P(T_{MRCA} = 2) = \\left(1-\\frac{1}{N}\\right)\\frac{1}{N} \\] Here, \\(\\left(1- \\frac{1}{N}\\right)\\) is the probability of non coalescence in the first generation and the second term \\(\\frac{1}{N}\\) is the probability of coalescence in the \\(2^{nd}\\) generation. Therefore the probability of coalescence in the second generation is subject to non coalescence in the first generation. What is \\(P(T_{MRCA} = n)\\)? Continuing with the logic from the previous answer we have: \\[\\begin{aligned} P(T_{MRCA} = 3) &amp;= \\left(1-\\frac{1}{N}\\right)^{2}\\frac{1}{N}\\\\ P(T_{MRCA} = 4) &amp;= \\left(1-\\frac{1}{N}\\right)^{3}\\frac{1}{N}\\\\ \\vdots \\\\ P(T_{MRCA} = n) &amp;= \\left(1-\\frac{1}{N}\\right)^{n-1}\\frac{1}{N}\\\\ \\end{aligned}\\] With a reasonably big population and with a long time scale, we can think about the problem in continuous time Let the hazard of coalescence be \\(c = 1/N\\). Probability of coalescence at time \\(t\\): \\(\\ell(t) h(t) = e^{-ct} c\\) The expected time of coalescence is analogous to the average age of death which is the life expectancy at birth. \\[\\begin{aligned} e_0 &amp;=\\frac{T_0}{l_0}\\\\ &amp; = \\frac{\\sum_0^{\\infty} \\ell_x}{1} \\\\ &amp; = \\int_0^{\\infty} \\ell_x dx \\\\ &amp; = \\int_0^{\\infty} e^{-cx}dx \\\\ &amp; = (\\frac{-1}{c})e^{-cx}|_0^{\\infty}\\\\ &amp; = (\\frac{-1}{c})(0-1)\\\\ &amp; = \\frac{1}{c} \\end{aligned}\\] Since \\(c = 1/N\\), then the expected waiting time until coalescence is \\(\\frac{1}{c}= N\\) What is expected time of coalescence? Think life expectancy. \\(E(T_{MRCA})\\) if two samples: \\(1/c = 1/(1/N) = N\\) We can look at this through simulations. The functions below create Fisher-Wright processes and get the time to coalescence. ## Our functions ## (1) Fisher-Wright with Mutations &quot;2&quot; ## (builds on function we used last time, but also returns history of draws which we can use to trace TMRCA) fwm2 &lt;- function(N, n_gen, mu = 0, start_types = paste(1:N)) { ## position vector, for sampling pos &lt;- 1:N ## matrices to keep book on each generation ## Types A &lt;- matrix(NA, nrow = n_gen, ncol = N) ## Positions P &lt;- matrix(NA, nrow = n_gen, ncol = N) x &lt;- start_types for (i in 1:n_gen) { ## this code is a bit different from last time ## note: this is a bit confusing, maybe we should assign A[i+1,] &lt;- x at the end of this loop and ## only go up to n_gen -1 A[i,] &lt;- x ## types of last generation positions &lt;- sample(pos, size = N, replace = T) ## we sample the parents 1:N P[i,] &lt;- positions ## keep book on positions x &lt;- A[i,positions] ## get types of next generation x &lt;- mut(x, mu) ## mutation ## x } return(list(A=A, P=P)) ## A= matrix of types, each line a generation; P= matrix of positions } mut &lt;- function(x, mu) { ## m, the individuals that mutate m &lt;- which(rbinom(length(x), 1, mu) == 1) if (length(m) == 0) ## if no-one mutates return(x) ## add a suffix to their ID, so it will be unique (infinite alleles) suffix &lt;- 10000*round(runif(length(m)),4) x[m] &lt;- paste0(x[m], &quot;.&quot;, suffix) x } ## Time to TMRCA get.coalescence.time &lt;- function(P, i,j, verbose = F) { ending_individuals = c(i,j) ## two individuals we&#39;re tracking back in time parents &lt;- ending_individuals k_ago = 0 PP = P ## for verbose, tracks coalescence for (k in nrow(P):1) # row P = generation until 1 (moving backwards in time) { k_ago = k_ago + 1 if (verbose == TRUE) print(parents) parents &lt;- P[k, parents] PP[k, parents] &lt;- P[k, parents]*10 + P[k, parents] # way to tag the parents. PP = P when we are not following (backwards) the individuals i, j if (parents[1] == parents[2]) # Stop looking backwards when both parents are the same { if(verbose) print(parents) ifelse(verbose, return(list(PP, k_ago)), return(k_ago)) } } if (k_ago == nrow(P)) k_ago &lt;- NA ifelse(verbose, return(list(PP, k_ago)), return(k_ago)) } First, consider a FW process with 5 generations and 5 people. The first row of the matrix A is the starting population of people types 1 through 5. The next generations (in each row) are sampled from the previous generation with replacement. If one type is not sampled into the next generation then it is ‘’lost’’ and cannot appear in future generations. ** NOTE FOR JOSH:** I am really confused about the difference between the A and P matrix, so I don’t know if I am writing the correct explanation above and below. Could you please explain more how P and A work in the code below and in the context of the get.time.coalesce fn? set.seed(10) out &lt;- fwm2(5,5,0) # N = 5, #generations = 5, mutation =0 P &lt;- out$P A &lt;- out$A print(A) ## [,1] [,2] [,3] [,4] [,5] ## [1,] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; ## [2,] &quot;3&quot; &quot;1&quot; &quot;2&quot; &quot;4&quot; &quot;3&quot; ## [3,] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;3&quot; &quot;2&quot; ## [4,] &quot;1&quot; &quot;2&quot; &quot;2&quot; &quot;2&quot; &quot;1&quot; ## [5,] &quot;2&quot; &quot;2&quot; &quot;1&quot; &quot;2&quot; &quot;1&quot; print(P) ## [,1] [,2] [,3] [,4] [,5] ## [1,] 3 1 2 4 3 ## [2,] 2 2 2 5 3 ## [3,] 2 5 5 5 1 ## [4,] 4 2 5 2 5 ## [5,] 2 1 2 2 1 Here we look at a function that obtains the time to coalescence given a FW process. The output contains (in order) the parents of the individuals tracked, the position matrix and the time to coalescence. For individuals 1 and 2 \\(T_{MRCA}=3\\) and for individuals 3 and 4, \\(T_{MRCA}=1\\) get.coalescence.time(P,1,2, verbose = T) # individuals tracked are 1 and 2 ## [1] 1 2 ## [1] 2 1 ## [1] 2 4 ## [1] 5 5 ## [[1]] ## [,1] [,2] [,3] [,4] [,5] ## [1,] 3 1 2 4 3 ## [2,] 2 2 2 5 3 ## [3,] 2 5 5 5 11 ## [4,] 4 22 5 22 5 ## [5,] 22 11 2 2 1 ## ## [[2]] ## [1] 3 get.coalescence.time(P,3,4, verbose = T) # individuals tracked are 3 and 4 ## [1] 3 4 ## [1] 2 2 ## [[1]] ## [,1] [,2] [,3] [,4] [,5] ## [1,] 3 1 2 4 3 ## [2,] 2 2 2 5 3 ## [3,] 2 5 5 5 1 ## [4,] 4 2 5 2 5 ## [5,] 2 11 2 2 1 ## ## [[2]] ## [1] 1 #output: 1) parents , 2) PP matrix, 3) Here is an example where there is no coalescence for individuals 3 and 4. In this case, we are looking at 5 types over 2 generations. set.seed(10) out &lt;- fwm2(5,2,0) P &lt;- out$P print(P) ## [,1] [,2] [,3] [,4] [,5] ## [1,] 3 1 2 4 3 ## [2,] 2 2 2 5 3 get.coalescence.time(P,1,2, verbose = T) #Individuals 1 and 2 ## [1] 1 2 ## [1] 2 2 ## [[1]] ## [,1] [,2] [,3] [,4] [,5] ## [1,] 3 1 2 4 3 ## [2,] 2 22 2 5 3 ## ## [[2]] ## [1] 1 get.coalescence.time(P,3,4, verbose = T) #Individuals 3 and 4 ## [1] 3 4 ## [1] 2 5 ## [[1]] ## [,1] [,2] [,3] [,4] [,5] ## [1,] 33 1 22 4 3 ## [2,] 2 22 2 5 33 ## ## [[2]] ## [1] NA get.coalescence.time(P,3,3, verbose = T) #Individuals 3 and 3 ## [1] 3 3 ## [1] 2 2 ## [[1]] ## [,1] [,2] [,3] [,4] [,5] ## [1,] 3 1 2 4 3 ## [2,] 2 22 2 5 3 ## ## [[2]] ## [1] 1 Now let’s do average of coalescent time in different FW processes. We’ll just draw 1 time for each one. We’ll look at 200 generations of 40 types (no mutations). Over 200 simulations, we find that the average time to coalescence is 52.08 which is close to what our formula \\(E(T_{RMCA})=N\\) predicts. Try another size of N, ie 20, and you’ll find similar results! The variance is 2828.174. If the process was an exponential distribution we would get that the mean \\(=\\frac{1}{\\lambda}\\) and that the variance \\(=\\frac{1}{\\lambda^2}\\). Here, if \\(\\lambda=\\frac{1}{52.08}\\), then then variance should be \\(=\\frac{1}{52.08^2}= 2712.326\\). So, the variance below is a bit off from what we would expect from an exponential distribution. set.seed(2) N &lt;- 50 ## pop size n_trials = 200 ## the number of &quot;histories&quot; we simulate n_samples = 1 ## the number of samples we do, of each history T.bar.vec &lt;- rep(NA, n_trials) for (r in 1:n_trials) { ## for each trial #print(r) out&lt;- fwm2(N, n_gen = N*20, mu = 0) ## big enough n_gen so we almost always observe MRCA P &lt;- out$P T.vec &lt;- rep(NA, n_samples) ## vector of Coalescent times from samples for (i in 1:n_samples) { ij &lt;- sample(1:N, 2) ## draw random pair of individuals T.vec[i] = get.coalescence.time(P, ij[1], ij[2]) } T.bar.vec[r] &lt;- mean(T.vec) ## average coalescent times for this trial } mean(T.bar.vec) #Mean time to coalescence ## [1] 52.08 var(T.bar.vec) #Variance time to coalescence ## [1] 2828.174 set.seed(10) out &lt;- fwm2(N=5,n_gen= 5,mu=0) P &lt;- out$P print(P) ## [,1] [,2] [,3] [,4] [,5] ## [1,] 3 1 2 4 3 ## [2,] 2 2 2 5 3 ## [3,] 2 5 5 5 1 ## [4,] 4 2 5 2 5 ## [5,] 2 1 2 2 1 9.4 Mutation and inference of TMRCA and \\(N\\) Using mutations, we can infer the most recent common ancestor. How? Say mutations occur at a constant rate \\(\\mu\\) (\\(10^{-8}\\)?). Then in each generation we would expect \\(\\mu\\) mutations, and over \\(T\\) years we would expect \\(T\\mu\\) mutations. Specifically, since the same mutation cannot happen twice, each year we expect new mutations. Say we observe that two people differ at \\(k\\) sites of the genome. Given this information we can find the TMRCA and even the size of the population. In the tree graph above, we have that the difference between the parent point (1) and the branches is the number of generations: The tree length is \\(2T\\) The expected number of mutations is # branches \\(\\times\\) # generations \\(\\times\\) mutations: \\[ E(k) = E(2T\\mu) = 2\\mu E(T) = 2 \\mu \\bar{T} \\] \\(\\bar{T}\\) is the average number of generations until we reach the most common recent ancestor and from the previous section we know that: \\[ \\bar{T} = E(T_{MRCA}) = N \\] If we observe on average \\(\\bar{k}\\) mutations, then \\[ \\begin{aligned} \\bar{k} &amp; \\approx E(k) = N 2 \\mu \\\\ \\hat{N} &amp; = {\\bar{k} \\over 2 \\mu} \\end{aligned} \\] Therefore, an estimate of the population is given by the number of events (\\(\\bar{k}\\)) as a share of the exposure (\\(2\\mu\\)). This allows us to make inferences on how big a population is just by knowing an estimate of mutations and their probabilities. 9.4.1 Inference of population size (Simulation) For this simulation, we will do FW with mutations. Then we will average pairwise differences and ivide by \\(2\\mu\\) to get our estimate. We can repeat this process multiple times and see if the average estimate converges to the truth. # Function count_pairwise_diff &lt;- function(str1, str2, verbose = F) { ## stategy: split strings at &quot;.&quot; and add ## up number of mutations after divergence if (verbose == TRUE) { print(paste0(&#39;Item 1: &#39;,str1)) print(paste0(&#39;Item 2: &#39;,str2)) } z1 = unlist(strsplit(str1, &quot;\\\\.&quot;)) z2 = unlist(strsplit(str2, &quot;\\\\.&quot;)) n1 = length(z1) n2 = length(z2) n = min(c(n1, n2)) ## make sure population has fixed if(z1[1] != z2[1]) return(NA) ## now get location of prefix (ID of TMRCA) (ie last point before divergence) pre.n = max(which(z1[1:n] == z2[1:n])) ## get suffix ## these are the mutations after prefix ## code is a bit awkward because for 1 of the ## individuals, there may be no additional mutations if (pre.n &lt; length(z1)) post.1 &lt;- z1[(pre.n +1): length(z1)] else post.1 = NULL if (pre.n &lt; length(z2)) post.2 &lt;- z2[(pre.n +1): length(z2)] else post.2 = NULL if (verbose == TRUE) { print(paste0(&#39;Mutations of item 1: &#39;, paste(post.1, collapse = &quot;; &quot;))) print(paste0(&#39;Mutations of item 2: &#39;, paste(post.2, collapse = &quot;; &quot;))) } ## count number of periods, note: length(NULL) is 0 n_mutations = length(post.1) + length(post.2) return(n_mutations) } Let’s see how this function works by starting off with a FW process of 100 types in 2000 generations with a mutation rate \\(\\mu=0.01\\). We save the last generation. Notice that each item in the last generation is a string with ‘.’ which denote a mutation and that the they most of them only differ in the last 4 items between the dots. set.seed(1) mu = .01 N = 100 A &lt;- fwm2(N, 2000, mu = mu)$A x &lt;- A[2000,] # Obtain the last generation x[1:10] ## [1] &quot;74.5520.5563.3239.6558.7128.7639.9055.2605.7108.7876.5694.4778.248.6772.4397.8568.9300.2922.9156.6429.4644.6302.989&quot; ## [2] &quot;74.5520.5563.3239.6558.7128.7639.9055.2605.7108.7876.5694.4778.248.6772.4397.8568.9300.2922.9156.6429.4644.6302.4596.5931.1038.3855&quot; ## [3] &quot;74.5520.5563.3239.6558.7128.7639.9055.2605.7108.7876.5694.4778.248.6772.4397.8568.9300.2922.9156.6429.4644.6302.989&quot; ## [4] &quot;74.5520.5563.3239.6558.7128.7639.9055.2605.7108.7876.5694.4778.248.6772.4397.8568.9300.2922.9156.6429.4644.6302.4596.5931.1038&quot; ## [5] &quot;74.5520.5563.3239.6558.7128.7639.9055.2605.7108.7876.5694.4778.248.6772.4397.8568.9300.2922.9156.6429.4644.6302.989&quot; ## [6] &quot;74.5520.5563.3239.6558.7128.7639.9055.2605.7108.7876.5694.4778.248.6772.4397.8568.9300.2922.9156.6429.4644.6302.4596.5931.1038&quot; ## [7] &quot;74.5520.5563.3239.6558.7128.7639.9055.2605.7108.7876.5694.4778.248.6772.4397.8568.9300.2922.9156.6429.4644.6302.4596.5931.1038&quot; ## [8] &quot;74.5520.5563.3239.6558.7128.7639.9055.2605.7108.7876.5694.4778.248.6772.4397.8568.9300.2922.9156.6429.4644.6302.4596.5931.1038&quot; ## [9] &quot;74.5520.5563.3239.6558.7128.7639.9055.2605.7108.7876.5694.4778.248.6772.4397.8568.9300.2922.9156.6429.4644.6302.989&quot; ## [10] &quot;74.5520.5563.3239.6558.7128.7639.9055.2605.7108.7876.5694.4778.248.6772.4397.8568.9300.2922.9156.6429.4644.6302&quot; Below we look at the differences between the different types. Function prints out the items, the mutations that occur after the types start diverging and the total number of mutations between each of the types. For types 1 and 4, there are 4 mutations while for types 1 and 10 there is only 1 mutations. Finally, for between types 10 and 13 there are only 3 differences. count_pairwise_diff(x[1], x[4], verbose = T)#Difference between types 1 and 4 ## [1] &quot;Item 1: 74.5520.5563.3239.6558.7128.7639.9055.2605.7108.7876.5694.4778.248.6772.4397.8568.9300.2922.9156.6429.4644.6302.989&quot; ## [1] &quot;Item 2: 74.5520.5563.3239.6558.7128.7639.9055.2605.7108.7876.5694.4778.248.6772.4397.8568.9300.2922.9156.6429.4644.6302.4596.5931.1038&quot; ## [1] &quot;Mutations of item 1: 989&quot; ## [1] &quot;Mutations of item 2: 4596; 5931; 1038&quot; ## [1] 4 count_pairwise_diff(x[1], x[10], verbose = T)#Difference between types 1 and 10 ## [1] &quot;Item 1: 74.5520.5563.3239.6558.7128.7639.9055.2605.7108.7876.5694.4778.248.6772.4397.8568.9300.2922.9156.6429.4644.6302.989&quot; ## [1] &quot;Item 2: 74.5520.5563.3239.6558.7128.7639.9055.2605.7108.7876.5694.4778.248.6772.4397.8568.9300.2922.9156.6429.4644.6302&quot; ## [1] &quot;Mutations of item 1: 989&quot; ## [1] &quot;Mutations of item 2: &quot; ## [1] 1 count_pairwise_diff(x[10], x[13], verbose = T)#Difference between types 10 and 13 ## [1] &quot;Item 1: 74.5520.5563.3239.6558.7128.7639.9055.2605.7108.7876.5694.4778.248.6772.4397.8568.9300.2922.9156.6429.4644.6302&quot; ## [1] &quot;Item 2: 74.5520.5563.3239.6558.7128.7639.9055.2605.7108.7876.5694.4778.248.6772.4397.8568.9300.2922.9156.6429.4644.6302.4596.5931.1038&quot; ## [1] &quot;Mutations of item 1: &quot; ## [1] &quot;Mutations of item 2: 4596; 5931; 1038&quot; ## [1] 3 ## now do get average of all pairwise differences x &lt;- A[2000,] Pij &lt;- matrix(NA, length(x), length(x)) for (i in 1:(length(x)-1)) { for (j in (i+1):length(x)) { Pij[i,j] = count_pairwise_diff(x[i], x[j]) # if verbose=F, then only prints out the total number of mutations } } k.bar = mean(Pij, na.rm = T) # ## we can now infer pop size N.hat = k.bar /(2*mu) print(N.hat) ## [1] 112.7778 Now do repeated trials to see if estimator approximates the formula from the previous section: \\(\\hat{N} = \\frac{\\bar{k}}{2 \\mu}\\). With 100 simulations, we get really close to the actual size of the population, which we established at the beginning. mu = .01 n_trials = 100 N = 100 n_gen = N*5 k.bar.vec = NULL n_casesfixation = 0 for (r in 1:n_trials) { #print(r) A &lt;- fwm2(N, n_gen, mu = mu)$A x &lt;- A[n_gen,] ## check on fixation (if we have many of these, increase n_gen) if (length(unique(substr(x,1,2))) &gt; 1) #print(x) n_casesfixation = n_casesfixation + 1 Pij &lt;- matrix(NA, length(x), length(x)) for (i in 1:(length(x)-1)) { for (j in (i+1):length(x)) { Pij[i,j] = count_pairwise_diff(x[i], x[j]) } } k.bar.vec[r] &lt;- mean(Pij, na.rm = T) } print(paste0(&#39;# cases of fixation: &#39;,n_casesfixation)) ## [1] &quot;# cases of fixation: 4&quot; print(paste0(&#39;Average # mutations: &#39;,mean(k.bar.vec))) ## [1] &quot;Average # mutations: 1.85187558619893&quot; N.hat = mean(k.bar.vec) /(2*mu) print(paste0(&#39;Average population size: &#39;,N.hat)) ## [1] &quot;Average population size: 92.5937793099466&quot; Given this simulation framework, we can modify many of the inputs to see how the size of the population reacts. For instance, we can include a large mutation rate or modify the population size. 9.5 Coalescence of a sample of \\(n\\) individuals This is covered on pages 42 and 43 of Gillespie NOTE FOR JOSH: I can’t find this reference. What are you refering to? We’ll just do one quick example, accepting the result Here is a sample of 3 (Note we’re using \\(N\\) instead of \\(2N\\)). The intuition here is that when we have more individuals, there’s more chance that some pair of them will coalesce. This tree might be the beginning or the end, we really don’t know. So, it is important to keep in mind what we are talking about. \\begin{verbatim} * _______ / \\ / \\ / \\ T(2) : E(T(2)) = N / \\ / * _______ / / \\ / / \\ T(3) : E(T(3)) = N * 2/[3*2] = N / 3 / / * _______ / / / \\ / / / \\ T(4) : E(T(4)) = N * 2/[4*3] = N / 6 * * * * ... _______ T(n) : E(T(n)) = N * 2/[n * (n-1)] \\end{verbatim} If we sample 4, how much of time to TMRCA is do we for 4 branches, 3 branches, and 2 branches? NOTE FOR JOSH: Could you check this answer here The total time waiting until MRCA of all 4 individuals is \\(N + {N\\over 3} + {N \\over 6} = {3\\over 2} N\\) Then, the time spent at each branch relative to the total time (out of 4 branches) is given by the third column. We count the total branch length as the number of branches time the expected time to coalesce. Number of branches (n) E(T(n)) Time spent at each branch /total Total branch length 2 \\(N\\) \\(\\frac{N}{N\\frac{3}{2}}=\\frac{2}{3}\\) \\(2N\\) 3 \\(\\frac{N}{3}\\) \\(\\frac{N\\frac{1}{3}}{N\\frac{3}{2}}= \\frac{2}{9}\\) \\(3\\frac{N}{3}=N\\) 4 \\(\\frac{N}{6}\\) \\(\\frac{N\\frac{1}{6}}{N\\frac{3}{2}}= \\frac{1}{9}\\) \\(4\\frac{N}{6} = \\frac{2}{3}N\\) 9.6 An application of coalescent theory In this section, we will look at an application to making inferences about the real history of human populations. Caveat: We’re still using \\(N\\) (not \\(2N\\)) as the number of haploids 9.6.1 Coalesence when population is changing We know that the hazard of coalescence is \\(h = c = 1/N\\). For instance if the populations were \\(N_1 =1000\\), \\(N_2 = 2000\\), then the hazard of coalesence in one generation for each of the populations would be \\(h_1= {1\\over1000}\\) and \\(h_2= {1\\over2000}\\), respectively. What if within the same population in one generation we have \\(N(t) = 1000\\) and in the following generation \\(N(t+1)= 2000\\)? We still follow FW in allowing children to choose their parents. If the population size changes over time \\(N(t)\\), then hazards of coalescence in will change too: \\(h(t) = 1/N(t)\\). Let’s look at a small simulation. We are thinking about a population that has lived over a certain number of years: 5000 people lived during the last 1000 years. Before that, the population was only 500. NOTE FOR JOSH: It’s not so clear to me why T1 is being sampled with N_recent and not with N_ancient. I thought that for the first 1000 years, the time to coalesce should be drawn from rexp(n, rate = 1/N_ancient) and then T2 &lt;- T_thresh + rexp(n2, rate = 1/N_recent). I tried changing in the simulation and I don’t get the nice histogram (nor the intended message), so I assume that my intuition is wrong. Could you clarify the populations involved and when the threshold happens in relation to the population sizes? N_recent = 5000 ## population last T_thresh years T_thresh = 1000 N_ancient = 500 ## earlier population n = 1000 ## sampled individuals set.seed(0.4886) T1 &lt;- rexp(n, rate = 1/N_recent) ## random draws from an exponential fn of times to coalesce. T1[T1 &gt; T_thresh] &lt;- NA ## Remove times that coalesce event happens after first 1000 generations. n2 &lt;- sum(is.na(T1)) # total years removed. T2 &lt;- T_thresh + rexp(n2, rate = 1/N_ancient) ## at ancient rate T.vec &lt;- c(T1, T2) hist(T.vec, breaks = seq(0, 5000, 250), main=&quot;History of times to coalesce&quot;, xlab=&quot;Years&quot;) Figure 9.1: Histogram How could we estimate population sizes from this histogram? We need to go from hazard to population size. First, let’s think about the times to coalesce like the age at death of a specific line of types. Therefore, we sort the times to coalesce (equivalent to time of death) to get a survivorship graph and then obtain \\(d_x\\). T.vec &lt;- sort(T.vec) St = (n:1)/n par(mfrow = c(1,2)) plot(T.vec, St) abline(v = T_thresh) plot(T.vec, log(St)) abline(v = T_thresh) Figure 9.2: Population How can we estimate hazards from this histogram? Say we have \\(i\\) pairs of haploids We then compute how many pairwise differences there are, but instead of computing \\(\\bar{k}\\), we keep the distributional information \\(k_i\\). Each \\(k_i\\) implies a \\(T_i\\) We then have a set of ``death times’’ (coalescence times), can build a life table, estimate the hazards, and infer \\(N(t)\\). Below we proceed with an example of how to obtain the hazards and the population sizes. 9.7 Reconstruction Ancient European Population Sizes using Batini’s sample of Mitochondrial DNA\" We use real sequences of mitochondrial DNA to estimate ancient population sizes. The sequences were made available by Batini et al. (2017), who analyzed sub-populations in their paper using software for Bayesian inference for comparing groups of individuals. Our approach here is to use a simpler, but less powerful approach. We will simply look at pairwise differences of random pairs of individuals. NOTE FOR JOSH: Is the Batini reference this one? https://www.nature.com/articles/s41598-017-11307-9 For this we are not going to do subgroups such as the Greeks or Irish, but are going to use the entire European sample. The population sizes we estimate are for the entire population represented by the 328 individuals. Special thanks to Ken Wachter for this approach and whose R-code forms the basis of this application 9.7.1 Summary of Batini et al. Before we begin our own analysis, let’s look at the inputs to Batini et al. (2017) analysis – the mtDNA haplotype sequences, and then at the resulting population estimates. 9.7.1.1 The mitochondrial DNA Data preparation begins. There are 380 individuals grouped into regional sub-populations. We select out the Greeks, whose labels begin with “gre”. x &lt;- scan(&quot;/hdir/0/fmenares/Book/bookdown-master/data/mtdna.csv&quot;, what = character()) nchar(x) ## [1] 4 3 4 2 5 11 1 15 16577 16577 16577 16577 16577 16577 ## [15] 16577 16577 16577 16577 16577 16577 16577 16577 16577 16577 16577 16577 16574 16575 ## [29] 16575 16575 16575 16575 16575 16575 16575 16575 16575 16574 16575 16574 16574 16574 ## [43] 16574 16574 16574 16574 16575 16575 16575 16575 16575 16575 16575 16575 16575 16575 ## [57] 16575 16575 16575 16575 16575 16575 16575 16575 16575 16574 16576 16576 16576 16576 ## [71] 16576 16576 16576 16576 16576 16576 16576 16576 16576 16576 16575 16575 16575 16578 ## [85] 16578 16575 16575 16575 16576 16577 16577 16577 16577 16577 16577 16577 16577 16577 ## [99] 16577 16577 16577 16577 16577 16577 16577 16577 16577 16577 16577 16575 16574 16575 ## [113] 16575 16575 16575 16575 16574 16574 16574 16574 16575 16575 16575 16575 16575 16576 ## [127] 16576 16576 16575 16575 16576 16576 16574 16574 16575 16575 16575 16575 16575 16574 ## [141] 16575 16575 16575 16575 16575 16575 16575 16575 16575 16575 16574 16574 16575 16575 ## [155] 16575 16575 16575 16575 16574 16575 16575 16575 16575 16575 16575 16575 16575 16575 ## [169] 16574 16574 16574 16574 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 ## [183] 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 ## [197] 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 ## [211] 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 ## [225] 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 ## [239] 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 ## [253] 16575 16576 16576 16576 16576 16577 16577 16577 16576 16576 16576 16576 16576 16576 ## [267] 16576 16576 16576 16576 16576 16576 16576 16576 16576 16576 16576 16576 16576 16576 ## [281] 16576 16577 16577 16577 16577 16577 16577 16577 16577 16577 16577 16577 16577 16577 ## [295] 16577 16576 16577 16577 16576 16575 16577 16575 16575 16577 16574 16575 16575 16575 ## [309] 16575 16574 16575 16575 16575 16575 16575 16575 16575 16574 16575 16574 16574 16574 ## [323] 16574 16574 16575 16575 16574 16575 16575 16575 16576 16575 16575 16575 16575 16575 ## [337] 16575 16575 16575 16576 16575 16576 16575 16575 16574 16575 16575 16575 16575 16575 ## [351] 16575 16575 16575 16575 16575 16574 16575 16574 16574 16574 16574 16574 16574 16574 ## [365] 16574 16575 16575 16575 16575 16575 16575 16575 16575 16575 16575 16574 16575 16574 ## [379] 16574 16574 16574 16574 16574 16574 16576 16576 16576 16576 ## note the strings have different length ## because there is some header information ## and then because the labels are mixed with the sequences ## separate out the sequences xx = x[nchar(x) &gt; 10000] ## elements that contain both label and sequences xx.list = strsplit(xx, split = &quot;,&quot;) ## list of elements, split into label and sequences ## now split up this list into a vector of labels and a vector of sequences get.first.element = function(x) {x[1]} get.second.element = function(x) {x[2]} labels = unlist(lapply(xx.list, get.first.element)) seqs = unlist(lapply(xx.list, get.second.element)) ## Now use labels to select out the 20 Greeks s &lt;- grepl(&quot;^gre&quot;, labels) my.labels = labels[s] my.seqs = seqs[s] nchar(my.seqs) ## note the sequences all have same number of bases. ## [1] 16568 16568 16568 16568 16568 16568 16568 16568 16568 16568 16568 16568 16568 16568 ## [15] 16568 16568 16568 16568 16568 16568 ## now put the bases in a matrix, with each column an indiviual and ## each row a base. my.list &lt;- strsplit(my.seqs, &quot;&quot;) A &lt;- do.call(cbind, my.list) dim(A) ## [1] 16568 20 ## coding region sequences, 576-16023 (according to &quot;Tree construction ## and haplogroup prediction&quot; section, but not clear if this was used for ## Intrapopulation diversity B &lt;- A[576:16023,] haps &lt;- seqs Let’s inspect just a bit of one of these sequences print(nchar(haps[213])) ## [1] 16568 a_segment = substr(haps[213], 1, 100) print(a_segment) ## [1] &quot;GATCACAGGTCTATCACCCTATTAACCACTCACGGGAGCTCTCCATGCATTTGGTATTTTCGTCTGGGGGGTGTGCACGCGATAGCATTGCGAGACGCTG&quot; ## tip: don&#39;t try to print the 16,000 character whole string. it will clog up your computer. Let’s put the haps in a matrix my.list &lt;- strsplit(haps, &quot;&quot;) H &lt;- do.call(cbind, my.list) print(H[1:10, 1:4]) ## all the same ## [,1] [,2] [,3] [,4] ## [1,] &quot;G&quot; &quot;G&quot; &quot;G&quot; &quot;G&quot; ## [2,] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ## [3,] &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; ## [4,] &quot;C&quot; &quot;C&quot; &quot;C&quot; &quot;C&quot; ## [5,] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ## [6,] &quot;C&quot; &quot;C&quot; &quot;C&quot; &quot;C&quot; ## [7,] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ## [8,] &quot;G&quot; &quot;G&quot; &quot;G&quot; &quot;G&quot; ## [9,] &quot;G&quot; &quot;G&quot; &quot;G&quot; &quot;G&quot; ## [10,] &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; Let’s find a site where there’s polymorphism hap1 = H[,1] hap2 = H[,2] s &lt;- min(which(hap1 != hap2)) head(H[s + -2:2, 1:4]) ## the polymorphic site in context ## [,1] [,2] [,3] [,4] ## [1,] &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; ## [2,] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ## [3,] &quot;A&quot; &quot;G&quot; &quot;G&quot; &quot;G&quot; ## [4,] &quot;G&quot; &quot;G&quot; &quot;G&quot; &quot;G&quot; ## [5,] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; Let’s see if that’s hap1 is the only “A” table(H[s,]) ## ## A G ## 19 361 We see that there are 19 individuals with this “A” instead of “G”. Q: How many pairwise differences in total are there between hap1 and hap2? These are the kind of comparisons we will be doing. 9.7.2 Ancient population estimates Let’s look at Figure 2 on page 5 Figure 9.3: Figure 2 page 5 from Batini et al. (2017) If we look at Ireland (IRE), the think lines are effective population estimates over thousands of years (KYA). For instance, according to mtDNA, 1 thousand years ago the effective population size was around \\(12,500\\), while 50 thousand years ago the population was around \\(\\approx 1,250\\). The order of magnitude for each these populations appears to be about 10^4 in last few KYA and 10^3 50 KYA. Together, perhaps the size is 10 fold. So we’re looking at European effective population sizes on the order of 100,000 the last few thousand years and on the order of 10,000 tens of thousands of years ago. 9.7.2.1 Using the Coalescent to estimate changing population size Our procedure will involve a four steps: Pick 100 pairs of people at random and count their pairwise differences Estimate 100 different times of MRCA (\\(T\\)) using assumed mutation rate Estimate \\(h(t)\\), the time-varying hazard of coalescence Estimate the population size $N_e(t) 9.7.2.1.1 Step 1: random sampling and pairwise differences First, we sample 100 people with replacement. set.seed(1) hap_ids = 1:ncol(H) hap_id_sample = sample(hap_ids, size = 200, replace = FALSE) hap_id.mat &lt;- matrix(hap_id_sample, 100, 2) # 100 by 2 pairwise_diff_fun &lt;- function(hap1, hap2) { h1 &lt;- hap1 h2 &lt;- hap2 ## h1 &lt;- unlist(strsplit(hap1, &quot;&quot;)) ## h2 &lt;- unlist(strsplit(hap2, &quot;&quot;)) h1[h1 == &quot;N&quot;] &lt;- NA ## note &quot;N&quot; means missing h2[h2 == &quot;N&quot;] &lt;- NA ## making these NA avoids counting as polymorphism k = sum(h1 != h2, na.rm = T) n_valid = sum(!is.na(h1) &amp; !is.na(h2)) return(list(k = k, n_valid = n_valid)) } pairwise_diff_fun(H[,1], H[,2]) ## $k ## [1] 45 ## ## $n_valid ## [1] 16565 Now we’re ready to do pairwise comparisons of all 100 pairs of haplotypes. We’ll define the fraction of locii that have mutated (the pairwise differences) as NOTE FOR JOSH: Not sure what P or C are here. \\[ \\bar{Y} = P/C \\] P.vec = NULL C.vec = NULL for (i in 1:nrow(hap_id.mat)) { hap_id.1 = hap_id.mat[i,1] hap_id.2 = hap_id.mat[i,2] hap1 = H[,hap_id.1] hap2 = H[,hap_id.2] out = pairwise_diff_fun(hap1, hap2) P.vec[i] = out$k C.vec[i] = out$n_valid } Y.bar = P.vec/C.vec head(P.vec) ## [1] 19 36 13 39 5 84 head(C.vec) ## [1] 16566 16484 16539 16565 16565 16544 head(Y.bar) ## [1] 0.0011469274 0.0021839359 0.0007860209 0.0023543616 0.0003018412 0.0050773694 9.7.2.1.2 Step 2: Use mutation rate to obtain 100 distinct TMRCA Now we’ll use the mutation rate \\(\\theta_m\\) given by Batini et al. (2017) to compute time back to MRCA. First, some background: Let \\(a\\) index sites and write \\(Y_a = 1\\) if the letters are different, and \\(Y_a = 0\\) otherwise. For 1 site, the probability that it there has been a mutation, is 1 minus the chance that there has been no mutation. \\[ P( Y_a = 1 ) = 1 - e^{-T\\theta} \\] The mean \\(\\bar{Y}\\) across the segment is the proportion of \\(Y_a\\) that equal 1. So, in expectation for the fraction of sites that mutate is the same as the probability that 1 site mutates (assuming independence of mutation probabilities by site). This allows us to write: \\[ E{\\bar{Y}} = 1 - e^{-2T\\theta}, \\] where we’ve added a “2” in order to account that either one of the pairwise branched could have had a mutation, so we our “exposure” is twice the time to MRCA. Rearranging we get an estimate \\(\\hat{T}\\) of \\(T\\) to be \\[ \\hat{T} = {-\\log (1 - \\bar{Y} ) \\over \\theta} \\] Now we’re ready to estimate the MRCAs theta_m = 2.21 * 10^(-8) ## Batini page 6 (TMRCA estimation) T.vec &lt;- -(1/2) * (1/theta_m) * log(1 - Y.bar) ## TMRCAs in years ago head(T.vec, n = 10) ## [1] 25963.477 49464.349 17790.271 53328.902 6830.018 115165.228 56610.650 12294.775 ## [9] 21863.319 54701.270 Let’s visualize these hist(T.vec) We see a lot of coalescence about 50 KYA, which is as far back as Batini et al. (2017) estimates go. This means the population was small back then. 9.7.2.1.3 Step 3: Obtaining time-varying hazard of coalescence We’ll do this in two ways: Compute the slope of the logarithm of the survival curve, but we’ll see that it is noisy and needs to be smoothed. Construct a “life table” of coalescence with discrete periods of time. Let’s start with the more continuous version of estimating slopes. ## Plot survival curve by order of T St = (100:1)/100 ## or more generally (length(T.vec):1)/length(T.vec) t = kya = sort(T.vec)/1000 plot(kya, St, type = &quot;l&quot;, xlab = &quot;Kilo Years Ago&quot;, ylab = &quot;Fraction of pairs without common ancestor&quot;, main = &quot;&quot;) Figure 9.4: Estimatated probability of not coalescing plot(kya, log(St), type = &quot;l&quot;, xlab = &quot;Kilo Years Ago&quot;, ylab = &quot;Log fraction of pairs without common ancestor&quot;, main = &quot;&quot;) Figure 9.5: Estimatated probability of not coalescing The slope in the first 50,000 years has increased, which implies that the hazard has also increased. This means that the population has increased over time. 9.7.2.1.3.1 Estimating Hazards method 1. From smoothed survival curve First, we smooth the survival curve (St) out = lowess(x = kya, y = St, f = 1/5) St_smooth = out$y kya_smooth = out$x plot(kya, St, cex = .5, ylab=&quot;Fraction of pairs without common ancestor&quot;,xlab=&quot;Kilo Years Ago&quot;) lines(kya_smooth, St_smooth, type = &#39;l&#39;) Figure 9.6: Smoothing In this case we tried an f parameter of 1/5 but it can be modified to get a better fit. To convert the smoothed survivorship curve into hazards, we use the fact that hazards are equal to minus the slope of log survivorship. haz_hat = -diff(St_smooth)/diff(kya_smooth) plot(kya_smooth[-1], haz_hat, type = &#39;l&#39;, ylab = &quot;Estimated Hazard&quot;, xlab = &quot;Kilo Years Ago (Smooth)&quot;) Figure 9.7: Hazards Unfortunately, this plot does not tell us anything about the uncertainty of our estimates. 9.7.2.1.3.2 Estimating Hazards method 2. Life table appraoch Now let’s estimate the hazards using a “life table”, where again “death” is coalescence and “survival” is still not having a common ancestor. ## we choose these time boundaries arbitrarily x = c(0,2, 5, 10, 20, 30, 40, 65, 180) * 1000 ## time interval boundaries Define a function to count “exposure” by those pairs that have MRCA in time intervals. get_nax &lt;- function(Ti, x) { ## get person years lived in interval by those who die nax &lt;- NULL for (i in 1:(length(x)-1)) { s &lt;- Ti &gt;= x[i] &amp; Ti &lt; x[i+1] if (length(Ti[s]) != 0) { nax[i] = mean(Ti[s] - x[i]) } nax[is.na(nax)] &lt;- 0 } return(nax) } Construct the life table n &lt;- diff(x) T.vec.by.cat &lt;- cut(T.vec, x, include.lowest = T, right = F) ndx = table(T.vec.by.cat) lx = rev(cumsum(rev(ndx))) lxpn = c(lx[-1], 0) nax = get_nax(Ti = T.vec, x = x) nLx = n*lxpn + nax * ndx ## exposure nmx = ndx/nLx ## hazard lt &lt;- cbind(x = x[-length(x)], n, ndx, lx, nax, nLx, nmx) print(lt) ## x n ndx lx nax nLx nmx ## [0,2e+03) 0 2000 0 100 0.000 200000.0 0.000000e+00 ## [2e+03,5e+03) 2000 3000 0 100 0.000 300000.0 0.000000e+00 ## [5e+03,1e+04) 5000 5000 3 100 3651.934 495955.8 6.048926e-06 ## [1e+04,2e+04) 10000 10000 7 97 6416.957 944918.7 7.408045e-06 ## [2e+04,3e+04) 20000 10000 7 90 3662.324 855636.3 8.181046e-06 ## [3e+04,4e+04) 30000 10000 19 83 6798.251 769166.8 2.470206e-05 ## [4e+04,6.5e+04) 40000 25000 54 64 11619.224 877438.1 6.154280e-05 ## [6.5e+04,1.8e+05] 65000 115000 10 10 24611.455 246114.6 4.063149e-05 Let’s compare the two estimates: x.mid = x[-length(x)] + n/2 plot(x.mid, nmx, type = &#39;o&#39;, ylab = &quot;Mortality Rate&quot;, xlab = &quot;Age (Midpoint)&quot;, col=&quot;red&quot;) axis(2) lines(kya_smooth[-1] * 1000, haz_hat/1000, type = &quot;l&quot;, col=&quot;blue&quot;) legend(&quot;topleft&quot; , legend=c(&quot;Lifetable&quot;, &quot;Smooth Survival Curve&quot;), col=c(&quot;red&quot;, &quot;blue&quot;), lty=1:2, cex=0.8) Figure 9.8: Hazards comparison We’re getting basically the same thing, with a little more hint of rising hazards (shrinking pop size) in first 20 kya. Nearly the same thing estimate 40 kya ago, and very little signal before that. 9.7.2.1.4 Step 4: Estimate the population size \\(N_e(t)\\) In order to estimate the population size, we have to think for a minute about units. Our hazards are per year, but our logic for why hazards are related to population size is per generation. Remember, the chance of coalescence per generation was \\(1/N\\). This means we will want to multiply the annual hazard by generation length in order to get hazards per generation unit of time. Second, mtDNA is inherited only through mothers. So the coalescent that we are thinking of is only for women. And the effective population size we’re estimating is for females only. We can get a rough estimate of both sexes by doubling the number of females. Putting these two considerations together, we have: \\[ \\hat{N_e(both sexes)} = 2 \\times {1 \\over 25 \\cdot h(t)}, \\] The 2 inflates to both sexes, and the 25 inflates the annual hazard into generations of 25 years in length. Ne_smooth = 2 / (haz_hat/1000 * 25) Ne_lifetable = 2 / (nmx * 25) ## create step function for plotting Ne_lifetable_step = rep(Ne_lifetable, n/1000) kya_step = 1:(max(x)/1000) Plotting the results plot(kya_smooth[-1], Ne_smooth, type = &#39;l&#39;, ylim = c(1000, 60000), log = &#39;y&#39;, lty = 2, ylab=&quot;Estimated Population Size&quot;, xlab = &quot;Kilo Years Ago (Smooth)&quot;) lines(kya_step, Ne_lifetable_step, type = &#39;l&#39;, lwd = 2) We could evaluate uncertainty using resampling techniques such as bootstrap. The estimate above doesn’t include the fact that maybe the mutation rate is not constant or that the sample of people is not representative. Also, it’s possible that we are not seeing mutations that are not sampled. Migration: maybe the people are not all the same population. Let’s loop through and do the whole estimation 40 times n_trials = 40 Ne.mat &lt;- matrix(NA, nrow = n_trials, ncol = max(x)/1000) set.seed(1) for (r in 1:n_trials) { #r = 1 #print(r) ## sample hap_id_sample = sample(hap_ids, size = 200, replace = FALSE) hap_id.mat &lt;- matrix(hap_id_sample, 100, 2) ## estimate MRCA distribution P.vec = NULL C.vec = NULL for (i in 1:nrow(hap_id.mat)) { hap_id.1 = hap_id.mat[i,1] hap_id.2 = hap_id.mat[i,2] hap1 = H[,hap_id.1] hap2 = H[,hap_id.2] out = pairwise_diff_fun(hap1, hap2) P.vec[i] = out$k C.vec[i] = out$n_valid } Y.bar = P.vec/C.vec T.vec &lt;- -(1/2) * (1/theta_m) * log(1 - Y.bar) ## TMRCAs in years ago ## estimate Ne T.vec.by.cat &lt;- cut(T.vec, x, include.lowest = T, right = F) ndx = table(T.vec.by.cat) lx = rev(cumsum(rev(ndx))) lxpn = c(lx[-1], 0) nax = get_nax(Ti = T.vec, x = x) nLx = n*lxpn + nax * ndx ## exposure nmx = ndx/nLx ## hazard Ne_lifetable = 2 / (nmx * 25) ## create step function for plotting Ne_lifetable_step = rep(Ne_lifetable, n/1000) kya_step = 1:(max(x)/1000) ## save result Ne.mat[r,] &lt;- Ne_lifetable_step } Ne.interval &lt;- apply(Ne.mat, 2, quantile, c(.1,.5, .9)) matplot(t(Ne.interval), type = &#39;l&#39;, log = &#39;y&#39;, col = &quot;grey&quot;, lty = 1, lwd = 2, ylab=&quot;Estimated Population Size&quot;, xlab=&quot;Kilo Years Ago&quot;) lines(Ne.interval[&quot;50%&quot;,], lwd = 4) So it seems fairly clear that effective population size has been growing the last 50 thousand years, from a low of a few thousand to a few tens of thousand. The general trend in growth is consistent with Batini but Our total population size seems smaller by a factor of about 4 or 5. We don’t have the resolution to see increase between 10 and 20 kya, the end of the Last Glacial Maximum or the more recent Bronze Age steppe expansion 2 to 5 kya. In order to get more resolution and study sub-group differences, we would want to turn to methods that do more than pair-wise comparisons, giving us more detailed information about the effective population sizes of the past. References "],
["student-presentations.html", "Chapter 10 Student Presentations 10.1 Mortality Crossovers 10.2 Plateaus 10.3 Rising Inequality", " Chapter 10 Student Presentations 10.1 Mortality Crossovers 10.1.1 Outline Paper presentations Coale and Kisker (1986) Manton and Stallard (1981) Empirical examples of crossovers with CenSoc data Investigate quality of age of death reporting in CenSoc 10.1.2 Mortality Crossovers: Reality or Bad Data? (Coale and Kisker 1986) They noticed the following patterns in the age-specific death rates for different countries. Figure 10.1: Age specific death rates for different countries and cohorts. Source: Coale and Kisker (1986) Selection / heterogeneity: Elimination of the frailer members of the population at younger ages leaves only the very robust with lower mortality rates. Level playing fields at older ages Social Security, Medicare, etc. Bad data Misreporting age of death can lead to biased estimates of mortality rates at older ages 10.1.2.1 Age heaping: General pattern of age misstatement, most often rounding up to nearest 5 or 10. Begins with a modest upward transfer at age 60 or 70, increases rapidly with age. Figure 10.2: Age heaping example Source: IPUMS International Implications of age heaping: \\(\\text{age heaping on age 70} = \\frac{Pop_{70}}{(Pop_{69}+Pop_{71})/2}\\) Figure 10.3: Age heaping. Source: Coale and Kisker (1986) 10.1.2.2 Takeaways Age overstatement at advanced ages is common and downwardly biases estimates of mortality rates Age heaping is associated with age overstatement Low quality mortality data can artificially create a mortality crossover 10.1.3 Methods for Evaluating the Heterogeneity of Aging Processes in Human Populations Using Vital Statistics Data: Explaining the Black/White Mortality Crossover by a Model of Mortality Selection (Manton and Stallard 1981) 10.1.3.1 Summary A model to compute the ratio of Black and White individual age specific mortality risks (within sex) to determine if the adjustments of heterogeneity and mortality selection is sufficient to remove the crossover. Data from the U.S. Black and White populations for the period 1935 to 1975. Mortality crossover (Blacks having relatively lower mortality rates) at age 75. Could be explained under the proposed model. Data quality? Variety of evidence supporting the existence of a crossover. Consequently, careful consideration should be made of the population mechanisms by which the crossover might occur. 10.1.3.2 A model of selection Life tables are separately calculated for the Black and White populations in the U.S. over the period 1935 to 1975 based upon the assumptions: Each population is heterogeneous. The initial distribution of individuals in each population is identical (within sex) with respect to variables relevant to longevity. -Individual’s environmental conditions are fixed at birth. Operationally, they modified standard life table calculations (Chiang, 1968) to reflect the dependence of mortality rates at advanced ages upon the selection of earlier mortality levels on a heterogeneous population. 10.1.3.3 A little bit of math Assumptions: The following partial differential equation governs the change of the distribution as cohort age: \\[\\begin{aligned} \\frac{\\partial f_{x}(z)}{\\partial x}= f_{x}(z)(\\bar{\\mu}_{x}-\\mu_{x}(z)) \\end{aligned}\\] Each person retains the value of \\(z\\) (longevity characteristics) given at birth. Functional forms: \\[\\begin{aligned} \\mu_{x}(z)=z\\mu_{x}(1)= z\\mu_{x} \\end{aligned}\\] Thus \\(z\\) may be taken to be a measure of relative (to the standard individual) frailty or “susceptibility to death”. Alternatively, \\(1/z\\) may be considered as a measure of vitality or “robustness”. Variance and frailty relation: We also have the following definitions: \\[\\begin{aligned} \\overline{\\mu}_x&amp;= \\overline{z}\\mu_x\\\\ \\overline{z}_x&amp;= \\int_0^\\infty z f_x(z) dz \\end{aligned}\\] Therefore, we can say that \\(\\frac{\\partial\\overline{z}_x}{\\partial x}=- \\mu_x \\sigma_x^2(z)\\) \\[\\begin{aligned} \\frac{\\partial f_x(z)}{\\partial x}&amp;=f_x(z)(\\overline{z}\\mu_x - z\\mu_x)\\\\ \\frac{\\partial\\overline{z}_x}{\\partial x}&amp;= \\frac{\\partial \\int z f_x(z) dz}{\\partial x}\\\\ &amp;= \\int z \\frac{\\partial f_x(z) }{\\partial x}dz\\\\ &amp;= \\int z f_x(z)(\\overline{z}\\mu_x - z\\mu_x)dz \\\\ &amp;= \\mu_x \\left(\\int z f_x(z)\\overline{z} dz- \\int z^2 f_x(z)dz\\right)\\\\ &amp;= -\\mu_x \\left(\\int z^2 f_x(z)dz - \\overline{z} \\int z f_x(z) dz \\right)\\\\ &amp;= -\\mu_x \\left(\\int z^2 f_x(z)dz - \\overline{z}^2 \\right)\\\\ \\frac{\\partial\\overline{z}_x}{\\partial x}&amp;= - \\mu_x \\sigma_x^2(z) \\end{aligned}\\] This means the “frailer” population members (with high z’s) are being selected earlier than their more “robust” contemporaries (with low z’s) Gamma distribution: The proportionality assumption has implications for \\(f_x(z)\\) Mortality cannot be negative, then z must be positive. Average endowment, \\(\\overline{z}_0\\), for longevity, it follows that \\(\\overline{\\mu}_0=\\mu_0\\). Hence, \\(\\overline{z}_0=1\\) It would be desirable that the paramteres of \\(f_x\\) be unchanged for any \\(x\\). \\[\\begin{aligned} f_x(z)=z^{k-1}\\lambda_x^k exp(-z\\lambda_x)/\\Gamma(K) \\end{aligned}\\] With mean \\(\\overline{z}_x=k/\\lambda_x\\) and variance: \\[\\begin{aligned} \\sigma_x^2(z) = \\overline{z}^2_x/k = k/\\lambda^2 \\end{aligned}\\] ASPD and the relative risk: From the variance of the gamma, the average mortality and the definition of \\(\\overline{s}_x\\), we have: \\[\\begin{aligned} \\sigma_x^2(z)&amp;= \\overline{z}^2_x/k\\\\ \\overline{\\mu}_x&amp;= \\overline{z}_x\\mu_x\\\\ \\overline{s}_x&amp;= exp\\left(-\\int_0^x \\overline{\\mu}_t dt\\right)\\\\ nq_x(z) &amp;= 1-exp\\left(\\frac{kz}{\\overline{s}_x^{1/k}}-\\frac{kz}{\\overline{s}_{x+n}^{1/k}}\\right)\\\\ \\overline{r}_x&amp;= \\frac{\\mu_{x1}}{\\mu_{x2}}\\left(\\frac{\\overline{s}_{x1}}{\\overline{s}_{x2}}\\right)^{1/k} \\end{aligned}\\] 10.1.3.4 Parameter k Select values of k focus upon the biological rather than statistical Biological dimensions underlying longevity are normally distributed at birth. Any deviation from an “optimal” biological point will be associated with decreased survival. Conditionally on age, mortality will be a quadratic function Each individual’s endowment for longevity (z) is fixed at birth. The value of к is the result of n, number of dimensions relevant to longevity. The relation of n to the gamma shape parameter is simply n=2k. Lower n, the greater is the heterogeneity (higher variance of gamma) The values of n used are 1 and 2, suggesting that longevity is unidimensional (k=0.5) and bidimensional (k=1), respectively. Figure 10.4: Cohort and Individual Age Specific Mortality Probabilities for the 1875 White Female Birth Cohort. Source: Manton and Stallard (1981) Figure 10.5: Age-specific mortality risk ratios (Black males vs White males) for the years 1935,1955 and 1975. Source: Manton and Stallard (1981) Figure 10.6: Age-specific mortality risk ratios (Black females vs White females) for the years 1935,1955 and 1975. Source: Manton and Stallard (1981) 10.1.3.5 Takeaways It seems that the crossover at advanced ages for males is an artifact of the early differential mortality selection. An explanation for this differentials at older ages is the relatively more rapid reduction in individual white male mortality For black females we can see that they were worse off than males between 25-45 (the childbearing years) at 1935. Different Zs will result in a divergence between the increase with age of the cohort mortality rates and the age increase in the probabilities of death for individuals within the cohort. This because the earlier selection of the less “robust” population members, implies that individuals age “faster” than their cohorts. 10.1.4 CenSoc Mortality Crossovers Figure 10.7: Pooled cohorts of 1890-1900 Figure 10.8: Pooled cohorts of 1890-1900, by education level Figure 10.9: Pooled cohorts of 1890-1900 by location Figure 10.10: Pooled cohorts of 1890-1900 by wages 10.1.4.1 Can the crossover be eliminated? The baseline hazard is given by \\(\\mu_{0}(x)=\\bar{\\mu}(x)e^{\\sigma^{2}\\bar{H}(x)}\\) and we try different values of \\(\\sigma^2\\) for each group of people, in this case Black and White. Figure 10.11: Pooled cohorts of 1890-1900 by wages 10.1.4.2 Is death data in CenSoc file less reliable for Blacks? 57% of black people in pooled 1890-1900 cohort are missing death days (day of the month) 51% of white people missing death days No missing death months Missing day of birth far less common (about 0.005% of records) Are missing dates indicative of poor data? Figure 10.12: Day of death Figure 10.13: Month of death If observations with missing dates are dropped then the mortality rates look slightly different. Figure 10.14: Mortality crossover for pooled cohorts of 1890-1900. 10.1.4.3 Heaping for reported birth year No Heaping on Death Year No Heaping on Age of Death Heaping on Birth Year \\(Heaping(1900)=\\frac{B_{1900}}{(B_{1899}+B_{1901})/2}\\) Figure 10.15: Heaping: birth year 10.2 Plateaus Steinsaltz and Wachter (2006) Barbi et al. (2018): Recent paper claiming to be “the best evidence to date for the existence of extreme-age mortality plateaus in humans” Using total mortality rates for italian cohorts from 1900 to 1926 (from HMD), we can look at mortality rates over ages and cohorts, as an introduction to Barbi et al. (2018). When focusing on mortality rates above age 60, we see a constantly increasing curve with some variation at very old ages (beyond 100). One important limitation of our life tables is that the rates are only observed up until age 109. library(tidyverse) it &lt;- read_table(&quot;data/ITA.bltcoh_1x1.txt&quot;, skip=1) it$Age &lt;- as.numeric(it$Age) it$mx &lt;- as.numeric(it$mx) it$qx &lt;- as.numeric(it$qx) it &lt;- it %&gt;% mutate(mx = if_else(mx == 0, as.numeric(NA), mx)) Figure 10.16: Log mortality rates above age 60 after 1900 To detect plateaus above age 105 like the paper, we estimate a Gompertz on ages 60- 100 (there’s some noise from the war) after 1900. Recall that to estimate mortality using hazard rates for Gompertz: \\begin{aligned} h(x) = a e^{bx} \\ log(h{_x}) = log(a) + bx \\end{aligned*} Since we don’t have \\(h(x)\\) from the lifetable, we use \\({_1}m_x\\) min_gomp_age &lt;- 60 max_gomp_age &lt;- 105 max_plateau_age &lt;- 109 min_year &lt;- 1900 gomp &lt;- lm(log(mx) ~ Age, data = it %&gt;% filter(Age &gt; min_gomp_age &amp; Age &lt; max_gomp_age &amp; Year &gt; min_year)) new &lt;- data.frame(Age = max_gomp_age:max_plateau_age) new$Gomp.pred &lt;- exp(predict(gomp, new)) new &lt;- new %&gt;% left_join(it %&gt;% filter(Age &gt; max_gomp_age-1, Year &gt; min_year) %&gt;% select(Age, Year,mx) %&gt;% spread(Year, mx)) new &lt;- new %&gt;% gather(&quot;Year&quot;, &quot;mx&quot;, -Age) It seems that the Gompertz prediction is in line with the data, at least in its trend. However, note the variation in rates between every cohort. Figure 10.17: Predicted log mortality rates above age 104 after 1900 Now, we look at predicted mortality rates by gender. The graphs below show a similar trend as the previous graph for overall mortality rates. Although the predictions seem to fit the data, that is Gompertz is an adequate method to model mortality between the ages of 100 to 109, a plateau may appear for even later ages. Since HMD data uses ages up to 109, we are unable to observe a plateau as in Barbi et al. (2018). # For men: it_m &lt;- read_table(&quot;data/ITA.mltcoh_1x1.txt&quot;, skip=1) it_m$Age &lt;- as.numeric(it_m$Age) it_m$mx &lt;- as.numeric(it_m$mx) it_m$qx &lt;- as.numeric(it_m$qx) it_m &lt;- it_m %&gt;% mutate(mx = if_else(mx == 0, as.numeric(NA), mx)) gomp &lt;- lm(log(mx) ~ Age, data = it_m %&gt;% filter(Age &gt; 60 &amp; Age &lt; 100 &amp; Year &gt; 1900)) new &lt;- data.frame(Age = 101:109) new$Gomp.pred &lt;- exp(predict(gomp, new)) new &lt;- new %&gt;% left_join(it_m %&gt;% filter(Age &gt; 95, Year &gt; 1900) %&gt;% select(Age, Year,mx) %&gt;% spread(Year, mx)) new &lt;- new %&gt;% gather(&quot;Year&quot;, &quot;mx&quot;, -Age) Figure 10.18: Log mortality rates for men above age 60 after 1900 Figure 10.19: Predicted log mortality rates for men above age 99 after 1900 # Women it_f &lt;- read_table(&quot;data/ITA.fltcoh_1x1.txt&quot;, skip=1) it_f$Age &lt;- as.numeric(it_f$Age) it_f$mx &lt;- as.numeric(it_f$mx) it_f$qx &lt;- as.numeric(it_f$qx) it_f &lt;- it_f %&gt;% mutate(mx = if_else(mx == 0, as.numeric(NA), mx)) gomp &lt;- lm(log(mx) ~ Age, data = it_f %&gt;% filter(Age &gt; 45 &amp; Age &lt; 100 &amp; Year &gt; 1900)) new &lt;- data.frame(Age = 101:109) new$Gomp.pred &lt;- exp(predict(gomp, new)) new &lt;- new %&gt;% left_join(it_f %&gt;% filter(Age &gt; 95, Year &gt; 1900) %&gt;% select(Age, Year,mx) %&gt;% spread(Year, mx)) new &lt;- new %&gt;% gather(&quot;Year&quot;, &quot;mx&quot;, -Age) Figure 10.20: Log mortality rates for women above age 60 after 1900 Figure 10.21: Predicted log mortality rates for women above age 99 after 1900 10.3 Rising Inequality Waldron (2007): Age-cohort model suggesting growing inequality by income, but includes many caveats about heterogeneity. Our challenge is to apply models of heterogeneity to this issue, particularly the result on mortality improvement over time. 10.3.1 Trends in mortality differentials and life expectancy for male social security-covered workers, by socioeconomic status (Waldron 2007) This paper fits in nicely with our discussion of heterogeneity and different rates of improvement across groups Analyzes trends in mortality differentials and life expectancy by average relative earnings for male Social Security-covered workers aged 60 or older Finds differences in level and rate of change in mortality improvement over time by SES “..male Social-Security covered workers born in 1941 who had average relative earnings in the top half of the earnings distribution and who lived to age 60 would be expected to live 5.8 more years than their counterparts in the bottom half. In contrast, among male Social Security-covered workers born in 1912 who survived to age 60, those in the top half of the earnings distribution would be expected to live only 1.2 years more than those in the bottom half.” Warns that these projections are very much only one possible outcome, since the causes of the widening differentials observed are still not understood 10.3.1.1 Context and data Historically, mortality inequalities by class that emerged between 1650-1850 began to narrow by the 1930s and 1940s (eg. Antonovsky 1967) Evidence that the gap has widened due to differential rates of decline in deaths due to heart disease (Feldman 1989) This paper adds to the literature by using a large longitudinal data set in which deaths are observed over 29 years This allows for disaggregation by age and year-of-birth, avoiding linearity assumptions with regard to interaction terms Wage data comes from the SSA Continuous Work History Sample, combined with the Numident (master death) file and the Master Beneficiary Record file Earnings are measured relative to the national average wage in the year, then averaged Earnings are only used post 1957 to account for expansion of Social Security coverage–some issues still exist due to subsequent expansions, but Waldron suggests that these should not have an important Important caveat: this is not a representative sample, as it excludes men not participating in the labor force and does not account for the possibility of low covered earnings combined with high non-covered earnings 10.3.1.2 Methods Estimates are constructed of mortality differentials and cohort and period life expectancies Models: Mortality differentials over time: \\(1(dead)_{isc}= \\alpha +\\beta_{1}age_{isc} + \\beta_{2}1(earnings)_{isc}+\\epsilon_{isc}\\) Cohort life expectancy estimates: Uses a discrete-time logistic regression model of the form \\(1(dead)_{isc}= \\gamma + \\theta_{1}age_{isc}+ \\theta_{2}birthyear_{isc} + \\theta_{3}age_{isc}\\times birthyear_{isc}+ \\theta_{4}1(earnings)_{isc}+ \\theta_{5}age_{isc}\\times 1(earnings)_{isc}+ \\theta_{6}birthyear_{isc}\\times 1(earnings)_{isc}+ \\theta_{7}age_{isc}\\times birthyear_{isc}\\times 1(earnings)_{isc}+\\varepsilon_{isc}\\) Does not control for changes in sample frailty over time: “Theoretically, if more frail members of lower-earnings groups are making it into the sample at older ages than in the past, then they could push up mortality differentials relative to the past. Hypothetically, it is possible that widening mortality differentials can indicate improvement for the lower-earnings groups, if such widening is an indication of their survival in greater numbers to ages at which previously only the strongest among them survived.” 10.3.1.3 Results Widening mortality differentials: Figure 10.22: Selected cohort survival curves for male Social Security-covered workers, by age and earnings group. Source: Chart 1 Waldron (2007) Figure 10.23: Percentage change in the death rate for male Social Security-covered workers, by selected age and earnings group from birth years 1912-1941. Source: Chart 2 Waldron (2007) Figure 10.24: Cohort life expectancy at age 65 (and 95 percent confidence intervals) for male Social Security-covered workers, by selected birth years and earnings group. Source: Chart 3 Waldron (2007) These results also hold for cohort life expectancies, though for later birth cohorts the confidence intervals tend to overlap–projected estimates. Waldron, using period data, also attempts to compare these numbers to other OECD countries, finding that, at 65, high-earning Social Security-covered men rank close to population averages for multiple other countries like Canada, suggesting they do worse than high-earning men in these countries Men in the bottom quarter of the earning distribution “could expect to live roughly as long as the average Irishman” Differences in medical care and health behaviors? Short discussion of the differences in frailty across countries–Mexico is predicted to have a selectively healthier and more robust population at age 80 This paper offers insight into the way in which population heterogeneity may lead to very different outcomes–though questions about sample frailty remain. A simulation of mortality differentials over time shows that: Over time, for a given age, the differential has widened. Within the same cohort, across ages, the differential falls. Figure 10.25: Odds ratio (confidence intervals) for the bottom half of the earnings distribution relative to the top half of the distribution, by year of birth and age. Source: Table 1 Waldron (2007) We can replicate the results of the simulation below. We want to see if heterogeneity alone can explain the pattern in Waldron’s observations of hazard ratios declining by age and increasing from one cohort to the next. The key idea is that moving from one cohort to the next, holding age constant, is like moving to younger ages within a cohort. Just as moving to younger ages makes the observed hazard ratio larger, moving to a lower baseline mortality rate, holding age constant, also makes the hazard ratio larger. ## Waldron Simulation using Gamma-Gompertz t &lt;- 1:5 ## five different cohrots (say each 10 years apart) k &lt;- .25 ## amount of mortality decline per decade (about 2.5% per year) b &lt;- .1 ## gompertz slope a0 &lt;- 10^{-3} ## starting hazard (rather high) a0.vec &lt;- a0 * exp(-k * t) #hazard vector for every cohort, including a mortality decline x &lt;- 0:100 # mu.bar &lt;- a * exp(b * x) / (1 + (a * s2 / b) * (exp(b*x) - 1)) #gamma gompertz formula, where s2 is sigma^2 mu.1.bar.xt &lt;- matrix(NA, length(t), length(x)) # matrix of cohorts (rows) by ages (columns) mu.2.bar.xt &lt;- matrix(NA, length(t), length(x)) dimnames(mu.1.bar.xt) &lt;- list(t, x) dimnames(mu.2.bar.xt) &lt;- list(t, x) s2 &lt;- .2 for (i in 1:length(t)) #i: cohort counter { a1 &lt;- a0.vec[i] a2 &lt;- a1 * 2 mu.1.bar.xt[i,] &lt;- a1 * exp(b * x) / (1 + (a1 * s2 / b) * (exp(b*x) - 1)) # baseline hazard mu.2.bar.xt[i,] &lt;- a2 * exp(b * x) / (1 + (a2 * s2 / b) * (exp(b*x) - 1)) # population hazard } R.mat &lt;- mu.2.bar.xt/mu.1.bar.xt #odds ratio waldron.simu &lt;- R.mat[, x %in% seq(60, 100, 10)] print(waldron.simu) ## 60 70 80 90 100 ## 1 1.443725 1.226597 1.097246 1.038110 1.014365 ## 2 1.505985 1.273363 1.121510 1.048411 1.018370 ## 3 1.568061 1.325716 1.150818 1.061317 1.023465 ## 4 1.628069 1.382813 1.185699 1.077385 1.029930 ## 5 1.684373 1.443338 1.226496 1.097228 1.038107 Interestingly, you can see that after 5 decades, the \\(R(x)\\) curve has shifted over almost exactly 10 years. R(90, decade 1) nearly equals R(100, decade 5) and similarly for age 60, 70, and 80. We now block the lower right cells (so that our table looks like Waldron’s): ## 60 70 80 90 100 ## 1 1.44 1.23 1.10 1.04 1.01 ## 2 1.51 1.27 1.12 1.05 NA ## 3 1.57 1.33 1.15 NA NA ## 4 1.63 1.38 NA NA NA ## 5 1.68 NA NA NA NA We see a more rapid decline by age, and a less rapid increase by cohort. But qualitatively the pattern looks similar. Further investigation could try to choose more accurate \\(a0\\) and \\(b\\) parameters to match better with observed mortality rates. Note: the true risk of being in group 2 instead of 1 is R = 2. So it’s not that by cohort 5 we’re seeing a distortion of the R(60). Rather we’re seeing convergence of the population value to the individual risk. References "],
["demographic-theory-and-covid-19.html", "Chapter 11 Demographic theory and COVID-19 11.1 Outline 11.2 Motivating questions 11.3 Population aging 11.4 Keyfitz’s entropy 11.5 Loss of person years remaining 11.6 Stationary theory", " Chapter 11 Demographic theory and COVID-19 11.1 Outline Formal demography of epidemic mortality Additional resources: For more details and insights refer to Goldstein and Lee (2020) 11.2 Motivating questions How does age-structure of population affect epidemic mortality? How does mortality change affect life expectancy in normal times? How much remaining life is lost from an epidemic? 11.3 Population aging Worldwide distribution of the elderly Source: Tuljapurkar and Zuo Covid19 has affected the elderly the most which accounts for a substantial share of the population of the Global North. 11.3.1 Stable theory Let’s revist the stable population theory to understand a change the importance of population structure on epidemic dynamics. The underlying assumptions to a stable population are that i) age-specific mortality and fertility rates are fixed over a long period, ii) age-structure is constant and iii) population closed to migration. In this context, the population of age \\(x\\) in year \\(t\\) depends on the births (\\(B(t)\\)) and the survivorship: \\[N(x,t)= B(t-x)\\ell(x) =B(t)e^{-rx}\\ell(x)\\]. The total population in year \\(t\\) is then \\(N(t)=\\int_{0}^{x} N(a,t)da = B(t)\\int_{0}^{x} e^{-ra}\\ell(a)da\\) Proportion of stable population at age x: \\[ c(x) = \\frac{N(x,t)}{N(t)}=\\frac{B(t)e^{-rx}\\ell(x)}{N(t)} =b e^{-rx}\\ell(x) \\] where \\(b\\) is the birth rate \\(\\left(b=\\frac{B(t)}{N(t)}\\right)\\). Note that the age-structure and the birth rate are independent of \\(t\\) in the notation. Birth rate of a stable population: As \\(\\int_0^{x} c(a)da =1\\), \\[\\int_{0}^{x} b e^{-ra}\\ell(a)da =1 \\\\ b = \\frac{1}{\\int_{0}^{x} e^{-ra}\\ell(a)da} \\] Using the Lotka-Euler equation we find that: \\[ \\] Now we look at the crude death rate (CDR), which is the share of deaths \\(D(t)\\) in a given population $$ \\[\\begin{aligned} CDR &amp;= \\frac{D(t)}{N(t)}\\\\ &amp; = \\frac{\\int_{0}^{x} D(a,t)da}{\\int_{0}^{x} N(a,t)da} \\\\ &amp; = \\frac{\\int_{0}^{x} h(a) N(a,t)da}{B(t)\\int_{0}^{x} e^{-ra}\\ell(a)da} \\\\ &amp;= \\frac{B(t)\\int_{0}^{x} h(a) e^{-ra}\\ell(a)da}{B(t)\\int_{0}^{x} e^{-ra}\\ell(a)da} \\end{aligned}\\] $$ where \\(h(x)\\) is the hazard of dying at age \\(x\\). Therefore, in a stable population with growth rate \\(r\\) we have a crude death rate that depends on the intrinsic growth rate: \\[CDR(r) = {\\int e^{-ra} \\ell(a) h(a) \\, da \\over \\int e^{-ra} \\ell(a) \\, da} \\] How does the CDR vary with growth rates? We can change \\(r=b-d\\) to make the population younger or older: \\(r&gt;0 \\Rightarrow\\) younger population as \\(b&gt;d\\) but if \\(r&lt;0 \\Rightarrow\\) then the population is older \\[ \\begin{aligned} \\frac{d}{dr} \\log CDR(r) &amp;= \\frac{d }{dr}\\log \\int e^{-ra} \\ell(a) h(a) da - \\frac{d}{dr}\\log \\int e^{-ra} \\ell(a)da\\\\ &amp; = -\\frac{\\int a e^{-ra} \\ell(a) h(a) da}{\\int e^{-ra} \\ell(a) h(a) da} + \\frac{\\int a e^{-ra} \\ell(a) da}{\\int e^{-ra} \\ell(a) da} \\\\ \\end{aligned}\\] If we assume a stationary population, such that \\(r=0\\), \\[ \\begin{aligned} \\frac{d}{dr} \\log CDR(r) &amp; = -\\frac{\\int a \\ell(a) h(a) da}{\\int \\ell(a) h(a) da} + \\frac{\\int a \\ell(a) da}{\\int \\ell(a) da} \\\\ &amp; =-\\frac{\\int a D(a) da}{\\int D(a) da} + \\frac{\\int a \\ell(a) da}{\\int \\ell(a) da} \\\\ &amp; = -\\int a D(a) da + \\frac{\\int a \\ell(a) da}{\\int \\ell(a) da} \\end{aligned} \\] Here, \\(l(x)h(x)\\) is the density of deaths by age \\(x\\) and \\(\\int_0^x D(a)da =1\\). This is a classic result (from Lotka) where the rate at which \\(r\\) changes affects the CDR through the mean age (\\(A\\)) and the life expectancy at birth (\\(e_0\\)): \\[{d \\log CDR(r) \\over dr}|_{r = 0} = A - e(0)\\] An example: Let \\(A=40\\) and \\(e_0=80\\) then \\({d \\log CDR(r) \\over dr}|_{r = 0}\\approx -40\\) If US and India had same age-specific mortality, but India grew 1 percent faster, what would the ratio of their crude death rates be? Both countries experience the same CDR(r) but for India \\(dr=0.01\\): \\(d \\log CDR(r) = (-40)(0.01) = -0.4\\) The death rate will be 40% lower in the US relative to India conditional on age structure NOTE FOR JOSH: Not sure of interpretation of this example. Now, if Covid-19 increases hazards at all ages by the same amount proportion in both countries, what will the ratio of their crude death rates be? 4 deaths in India per 10 deaths in the US. 11.4 Keyfitz’s entropy Assume that there is a proportional difference in mortality rates across all ages such that: \\[\\mu^*(x) = (1 + \\Delta) \\mu_0(x)\\] where \\(\\delta \\in (0,1]\\). The new survivoship is: \\[ \\begin{aligned} \\ell^*(x) &amp;= e^{-\\int_0^{x}\\mu^{*}(a)da}\\\\ &amp; = e^{-(1+\\Delta)\\int_0^{x}\\mu(a)da} \\\\ &amp; =\\ell(x)^{1+ \\Delta} \\end{aligned}\\] So, \\(H^*(x) = (1 + \\Delta) H(x)\\). Life expectancy at birth is: \\[e_0^{*} (x) = \\int_{0}^x \\ell(a)^{1+\\Delta}da\\] How does the new life expectancy change with the increase in mortality at al ages? \\[ \\frac{de_0^{*} (x)}{d\\Delta} = \\int_{0}^x (\\log\\ell(a))\\ell(a)^{1+\\Delta}da\\] This quantity will never be positive, as \\(\\ell(a) \\leq 1\\) such that \\(\\log(\\ell(a))&lt;0\\). As the \\(\\Delta\\) factor increases, life expectancy at birth falls. Entropy is defined as \\[ {\\cal H} = {d \\log e_{0}(0) \\over d \\Delta} = {-\\int \\ell(x) \\log \\ell(x) \\, dx \\over e_{0}(0)} \\] Reverse order of integration to get \\[ {\\cal H} = {\\int d(x) e(x) \\, dx \\over e_{0}(0)} \\] NOTE TO JOSH: don’t really know what the last formula is supposed to convey. 11.5 Loss of person years remaining Before epidemic the person year remaining (PYR): \\[ PYR = \\int N(x) e(x) \\, dx \\] After (‘’instant’’) epidemic \\[ PYR = \\int \\left[ N(x) - D^*(x) \\right] e(x) \\, dx \\] Proportion of person years lost \\[ \\int D^*(x) e(x) \\,dx \\over \\int N(x) e(x)\\, dx \\] 11.6 Stationary theory If \\(\\color{red}{\\mbox {Stationarity}}\\, N(x) \\propto \\ell(x)\\) \\(\\color{red}{\\mbox {Proportional hazards}}\\, M^*(x) = (1 + \\Delta) M(x)\\) Then Proportional loss of person years: \\[ \\color{red}{ {-d \\log PYR \\over d \\Delta} = {H \\over A} = {\\mbox{Life table entropy} \\over \\mbox{Mean age of stationary pop}}} \\approx {0.15 \\over 40} = 0.0038 \\] A doubling of mortality in epidemic year (\\(\\Delta = 1)\\) causes ``only’’ a 0.38% loss of remaining life expectancy. % Average person who dies loses \\(e^\\dagger \\approx 12\\) years. These numbers seem small, but: Even an epidemic doubling mortality has small effect on remaining life expectancy (\\(\\approx \\color{red}{2 \\mbox{ months}}\\) per person) But all-cause mortality also small (\\(\\approx \\color{red}{2 \\mbox{ months}}\\) per person) Covid-19: 1 million deaths \\(= 30\\)% more mortality, but older \\ (\\(\\approx \\color{red}{2 \\mbox{ weeks}}\\) per person) "]
]
