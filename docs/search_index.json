[
["index.html", "Mathematical Demography Chapter 1 Introduction", " Mathematical Demography Josh R. Goldstein 2020-11-04 Chapter 1 Introduction Mathematical demography book ``` "],
["intro.html", "Chapter 2 Introduction to Demographic Heterogeneity 2.1 Outline 2.2 Part I. Conceptual Introduction 2.3 Part II. Formal Analysis 2.4 Conclusions", " Chapter 2 Introduction to Demographic Heterogeneity 2.1 Outline What demographic heterogeneity is (and isn’t) Dynamics of population growth with two sub-groups Keyfitz’s result \\(\\bar{r}&#39;(t) = \\sigma^2_r(t)\\). Ken’s model of Poisson heterogeneity 2.2 Part I. Conceptual Introduction 2.2.1 What is Demographic Heterogeneity? If we see different outcomes (e.g., people dying at different ages), is this Demographic Heterogeneity? NO. Demographic heterogeneity \\(=\\) different rates for different folks. In a demographically heterogeneous population, people are of different types, with different type-specific rates. (These types can be discrete, with individuals being homogeneous within their type, or they can be continuous with possibly no individual having exactly the same risk as another.) 2.2.1.1 An example Let’s draw 10 individuals from a homogeneous population and heterogeneous population. ## Homogeneous hazard of 1/10 set.seed(13) x.homo &lt;- rexp(10, rate = 1/10) ## Heterogeneous hazard (half 1/6 and half 1/13) ## Note: I didn&#39;t pick these particular numbers for any specific reason x.hetero &lt;- c(rexp(5, rate = 1/6), rexp(5, rate = 1/13)) par(mfrow = c(1,2)) dotchart(x.homo, main = &quot;homogenous variation&quot;) dotchart(x.hetero, main = &quot;heterogeneous variation&quot;) Figure 2.1: Homogeneity and Heterogeneity Can you tell which is which? Homogeneous: Chance only Heterogeneous: Chance + group variation in risk Would we expect to see a difference if we increased sample? NOTE: ANSWER THIS 2.2.2 Analogies Social inequality: equal opportunity vs. equal outcomes Analysis of variance: \\(\\mbox{total variance} = \\mbox{within group} + \\mbox{between group}\\) Statistical models \\(y = a + b x + \\epsilon\\) 2.2.3 What’s new? Dynamics. Heterogeneous populations evolve differently. Aggregates \\(\\neq\\) Individuals Rates of growth (or decline) Changes over time or age or duration The trajectory of even the individual differs from population average Relative positions, change of groups, may be misleading. Terminology Heterogeneity Unobserved heterogeneity Selection Selective survival Other terms? Big Caveat: Fundamental Unidentifiability Same data of \\(N\\) observations \\(N\\) draws from 1 distribution \\(1\\) draw from \\(N\\) distributions Something in-between Abel (66) and Beth (76) example. 2.2.3.1 A 2nd example: Exponential growth, two countries Two countries start equal size, but grow at different rates. What happens to aggregate growth rate? rA = .03 ## growth rate of A rB = .01 ## growth rate of A KA = 100 ## starting pop size KB = 100 t = 0:200 KA.t = KA*exp(rA*t) ## exp growth of A KB.t = KB*exp(rB*t) ## exp growth of B K &lt;- KA.t + KB.t ## combined pop r.bar = diff(log(K)) ## growth rate plot(t[-1], r.bar, type = &quot;l&quot;, ylim = c(0, 0.04), ylab = &quot;r.bar&quot;, xlab = &quot;time&quot;) abline(h = c(rA, rB), lty = 2) Figure 2.2: Aggregate growth rate of sub-populations A + B Questions What determines growth rate? How does it change over time? Does the process converge? 2.2.3.2 More examples to work Differential, constant mortality (\\(\\mu_A = .03\\); \\(\\mu_B =.01\\)) Differential, time-varying mortality or growth. ``Movers and Stayers’’ (Migration) ``Movers and Stayers’’ (Marriage) Fecundity: aging or heterogeneity? Divorce: duration or heterogeneity? Duration of unemployment: duration or heterogeneity? Recidivism by time out of prison 2.2.4 Application Can you create a plateau? Can you create a crossover? Can you get aggregate rate to decline? Anything else? 2.3 Part II. Formal Analysis 2.3.1 Outline Keyfitz result Keyfitz USA-Mexico example Ken’s Poisson-Exponential Model 2.3.2 Keyfitz result \\[{d \\over dt}\\bar{r}(t) = \\sigma^2_r(t)\\] When group-specific growth rates are constant the rate of change of the aggregate growth rate equals the variance of the growth rates. Derivation By definition, \\[ \\bar{K}(t) = \\sum_i K_i(t) = \\sum_i K_i e^{r_i t} \\] and \\[\\bar{r}(t) = {{d \\over dt} \\bar{K}(t) \\over \\bar{K}(t)}\\] Let’s take derivatives and simplify, recalling definition of variance. SOLVE? 2.3.3 US-Mexico Example rm = 3.5/100 ru = .75/100 Km = 50 Ku = 100 t &lt;- -50:150 ## go back in time to see rise and fall of variance Kt = Km * exp(t*rm) + Ku * exp(t*ru) bar.rt &lt;- diff(log(Kt)) par(mfrow = c(2,2)) plot(t, Kt, lwd = 2, type = &#39;l&#39;) title(&#39;Total pop size (solid)\\n Group m (dashed)&#39;) lines(t, Km * exp(t*rm), lty = 2, col = &quot;red&quot;) lines(t, Ku * exp(t*ru), lty = 2, col = &quot;blue&quot;) my.v = 26 abline(v = my.v) plot(t, Kt, lwd = 2, type = &#39;l&#39;, log = &#39;y&#39;, ylim = c(.5, max(Kt))) lines(t, Km * exp(t*rm), lty = 2, col = &quot;red&quot;) lines(t, Ku * exp(t*ru), lty = 2, col = &quot;blue&quot;) abline(v = my.v) title(&quot;Total pop size (solid)\\n Group &#39;m&#39; (dashed): Log-scale&quot;) plot(t[-1], bar.rt, type = &#39;l&#39;, main = &#39;Aggregate growth rate&#39;) plot(t[-(1:2)], diff(bar.rt), type = &#39;l&#39;, main = &#39;Change in aggregate growth rate&#39;) Figure 2.3: Keyfitz result for US-Mexico 2.3.3.1 Commentary on Keyfitz result Growth rates in heterogeneous populations start at pop average and then increase. Heterogeneity pop growth We will extend to cover non-constant growth But Doesn’t tell us how much bigger \\(\\bar{K}(t)\\) is projection using constant aggregate rate \\(\\bar{r}(0)\\). Doesn’t give us a formula for time path of aggregate \\(\\bar{K}(t)\\) or \\(\\bar{r}(t)\\) Note: our homework will try to address some of this using Taylor approximation. 2.3.4 The Origin of Professor Wachter’s Poisson-Exponential Model Given a world with many sub-populations, each growing expontentially at their own rate, what can we say about the time-path of world population growth? From an email: Josh asks: Suppose we have a discrete mix of subpopulations growing at different intrinsic rates r whose maximum is r0. Is there a handy approximation for the growth path of the aggregate populations? The assumption of a discrete mix is essential here. Otherwise Tauberian theorems apply and, with a vanishingly small portion of the population close to the maximum growth rate, we do not obtain long-run exponential growth. I recommend modeling the discrete distribution of growth rates as a mixture of Poisson distributions. We are considering \\[\\begin{equation} \\label{mixture} \\bar{K}(t) = \\sum_i e^{r_i t} K_i(0). \\end{equation}\\] Ken suggests \\[\\begin{equation} \\label{ri_def} r_i = r_0 - s(\\lambda) \\cdot a, \\end{equation}\\] \\(r_0\\) growth rate of the fastest growing sub-population \\(s\\) a non-negative Poisson distributed integer \\(\\lambda\\) the parameter of the Poisson distribution (also it’s mean and variance) \\(a\\) gap between adjacent growth rates. Example: sub-populations have growth rates 3, 2, 1, 0, -1, \\(\\ldots\\) percent, then \\(r_0 = 0.03\\) and \\(a = 0.01\\). Sizes of sub-pops determined by Poisson dis’n 2.3.4.1 Closed-form result \\[ K(t) = K(0) e^{r_0 t} e^{-\\lambda (1 - e^{-at})}. \\] To derive: Write out mixture to get \\[ K(t) = K(0) e^{r_0 t} \\sum_i e^{-sat} f(s) \\] Substitute for \\(f(s)\\): \\(Pois ~ {\\lambda^s e^{-\\lambda} \\over s!}\\) Recognize that our mixture contains the series representation of \\(e^{-at}\\) Interpretation \\[ K(t) = K(0) e^{r_0 t} e^{-\\lambda (1 - e^{-at})}. \\] Dominant term contains the maximum population growth rate \\(r_0\\), Second term gives the diminishing effect of the sub-populations with smaller population growth rates over time. Some further analysis, What is the closed-form expression for \\(\\bar{r}(t)\\)? 2.3.5 Some commentary Poisson and Exponential ``fit’’ We’ll this complementarity again (e.g., with Gamma) Tractable models are super powerful for enhancing our understanding. But be careful. Avoid extremes: the model is right/wrong. A BIG caveat, are disaggregated models necessarily better? Some potential problems: Aggregate constraints? Interacting sub-populations? Illusion of precision? 2.4 Conclusions Heterogeneity as variation in risk (not just outcome) Constantly growing parts \\(\\neq\\) constantly growth whole Keyfitz result: Change in growth rate \\(=\\) variance of growth rates Poisson growth gives us a closed-form solution. "],
["frailty.html", "Chapter 3 Multiplicative Fixed Frailty 3.1 Outline 3.2 Part I. Results from Fixed Frailty 3.3 Part II. Introduction to Gamma Frailty 3.4 Conclusions", " Chapter 3 Multiplicative Fixed Frailty 3.1 Outline Review of Mortality Mathematics Multiplicative-fixed-frailty and alternatives to it. Population Survival and Hazards under fixed frailty Gamma frailty 3.1.1 Review of mortality mathematics \\(\\ell(x)\\) or \\(S(x)\\) probability of survival to age \\(x\\) \\(\\mu(x)\\) or \\(h(x)\\) hazard rate at age \\(x\\) (“minus the exponential rate of change in survival”) Let’s treat \\(\\mu\\) as a definition. \\[ \\mu(x) \\equiv -{d \\over dx} \\log \\ell(x) \\] Can anti-differentiate (integrate) to solve for survival: \\[ \\ell(x) = s(x) = e^{-\\int_0^x \\mu(a)\\, da} \\] 3.1.2 Application: what is \\(\\ell&#39;(x)\\)? in words? taking derivative of \\(\\ell(x)\\) interpretation 3.1.2.1 Two special cases Constant hazards \\(\\mu(x) = \\mu\\). What’s \\(\\ell(x)\\)? Gompertz hazards \\(\\mu(x) = a e^{b x}\\). What’s \\(\\ell(x)\\)? 3.1.3 Extending Keyfitz to mortality \\[ {d \\over dx} \\bar{\\mu}(x) = \\mbox{average rate of change} - \\sigma_\\mu^2 \\] What is \\(\\bar{\\mu}\\)? It’s a weighted average: \\[ \\bar{\\mu}(x) = {\\int \\mu(x | z) \\ell(x | z) p(z) \\, dz \\over \\int \\ell(x | z) p(z) \\, dz} \\] To derive Keyfitz extension, differentiate with respect to age \\(x\\). (See eq (13)). A good exercise. Multiplicative Fixed frailty For individual \\(i\\), \\[ \\mu_i(x) = z_i \\mu_0(x). \\] \\(z_i\\) “frailty” of the \\(i\\)th individual. (Usually thought of as a random variable with mean \\(1\\).) \\(\\mu_0(x)\\) “Baseline hazard” schedule. (Also, the schedule of a person with \\(z = 1\\)). 3.1.4 fragile Which look like multiplicative fixed frailty? 3.2 Part I. Results from Fixed Frailty 3.2.1 A simulation Our questions How do we do a micro-simulation, with individuals? How does fixed frailty fit in? How do we compute pop survival, hazards, etc. How does life table of heterogeneous pop differ from baseline? 3.2.2 Let’s derive pop survival (Note: \\(\\bar{s} = \\bar{\\ell}\\)) Pop survival will be a weighted average of group survival curves \\[ \\bar{s}(x) = {p(z_1) s_1(x) + p(z_2) s_2(x) + \\ldots \\over p(z_1) + p(z_2) + \\ldots} \\] With continuous \\(z\\) (what are limits of integration?) \\[ \\bar{s}(x) = \\int s(x|z) p(z) \\, dz \\] Under Multiplicative Fixed Frailty use \\[ \\mu(x|z) = z \\mu_0(x) \\] to derive \\[\\bar{s}(x) = \\int s_0(x)^z p(z) \\,dz.\\] 3.2.3 Now population hazards (stepping stones) Definition of hazards: \\[ \\bar{\\mu}(x) = - {d \\over dx} \\log \\bar{s}(x) \\] \\[ \\bar{\\mu}(x) = \\mu_0(x) {\\int z s_0(x)^z p(z) \\, dz \\over \\int s_0(x)^z p(z) \\, dz} \\] \\[ \\bar{\\mu}(x) = \\mu_0(x) \\bar{z}(x) \\] Let’s fill in steps. 3.2.4 Rodriguez question Why isn’t population hazard a (simple) average of individual hazards? Answer: selected survival means that the distribution of frailty at age \\(x\\) differs from the starting frailty distribution at age \\(0\\). The rate of increase in hazards (AKA “LAR: Lifetable Aging Rate”) \\[ \\beta(x) = {d \\over dx} \\log \\mu(x) \\] Example: What is \\(\\beta(x)\\) for Gompertz: \\(\\mu(x) = a e^{bx}\\)? Vaupel’s result \\[ \\bar{\\beta}(x) = \\beta_0(x) - \\bar{\\mu}(x) CV_z^2(x) \\] Hazards rise less slowly in pop than in baseline If pop hazards plateau, then \\(\\bar{\\beta}(x) = 0\\) Two special cases Homogeneous pop and plateau in baseline Gompertz and constant \\(CV_z\\) (e.g., from Gamma) 3.3 Part II. Introduction to Gamma Frailty 3.3.1 The Gamma distribution What do we want in a frailty distribution? What’s the Gamma? Last math: closed form pop survival positive? a single dimension summarizing multiple factors? (Normal?) flexible? tractable? \\[ p(z | k, \\lambda) = {\\lambda^k \\over \\Gamma(k)} z^{k-1} e^{-\\lambda z} \\]. \\(z\\) the random variable representing frailty \\(k, \\lambda\\) parameters \\(\\Gamma(k)\\) A normalizing constant. 3.3.2 Gamma in R Mean: \\(k / \\lambda\\) Variance: $ k / ^2$ ## with k and lambda k = 3; lambda = 6 x &lt;- rgamma(10000, shape = k, rate= lambda) mean(x) ## [1] 0.498123 sd(x) ## [1] 0.2915809 Alternate parameterization ## with mean 1, sigma.sq sigma.sq &lt;- .25 z &lt;- rgamma(10000, shape = 1/sigma.sq, rate = 1/sigma.sq) mean(z) ## [1] 1.003287 var(z) ## [1] 0.2468513 3.3.3 Population Survival of Gamma Frailty Big picture \\[ \\bar{s}(x) = \\int s_0(x)^z p(z) \\, dz \\] Or, using our definition of survival, \\[ \\bar{s}(x) = \\int e^{-z H_0(x)} p(z) \\, dz \\] Completing the gamma \\[ \\bar{s}(x) = \\int e^{-z H_0(x)} {\\lambda^k \\over \\Gamma(k)} z^{k-1} e^{-\\lambda z} \\, dz \\] Rearranging, \\[ \\bar{s}(x) = \\lambda^k \\int { 1 \\over \\Gamma(k)} z^{k-1} e^{-z (H_0(x)+\\lambda)} \\, dz \\] Integral is like a \\(Gamma(z | k, H_0(x) + \\lambda)\\), but missing something. What? Our Result \\[ \\bar{S}(x) = {\\lambda^k \\over \\left[H_0(x) + \\lambda\\right]^k} \\] If mean = 1.0, then we can let \\(\\lambda = k = 1/\\sigma^2\\), \\[ \\bar S(x) = {1/\\sigma^2 \\over (H_0(x) + 1/\\sigma^2)^{1/ \\sigma^2}} = {1 \\over \\left(1 + \\sigma^2 H_0(x)\\right)^{1/ \\sigma^2}} \\] 3.3.4 Interpreting Gamma-frailty survival \\[ \\bar S(x) = {1 \\over \\left(1 + \\sigma^2 H_0(x)\\right)^{1/ \\sigma^2}} \\] Older ages, smaller survival. Variance not so clear, need a picture. (What if \\(\\sigma^2 = 0\\)?) x &lt;- 0:100 a = 10^-4 b = 1/10 mx.0 &lt;- a * exp(b*x) Hx.0 &lt;- cumsum(mx.0) Sx.0 &lt;- exp(-Hx.0) ## small sigma sigma.sq = .5^2 bar.S.small.sigma &lt;- 1 / (1 + sigma.sq *Hx.0)^(1/sigma.sq) ## big sigma sigma.sq = 1^2 bar.S.big.sigma &lt;- 1 / (1 + sigma.sq *Hx.0)^(1/sigma.sq) plot(x, Sx.0, lty = 2, type = &quot;l&quot;, ylim = c(0,1), ylab = &quot;Survival&quot;) lines(x, bar.S.small.sigma, col = &quot;blue&quot;) lines(x, bar.S.big.sigma, col = &quot;red&quot;) legend(&quot;bottomleft&quot;, c(&quot;Pop big.sigma&quot;, &quot;Pop small.sigma&quot;, &quot;Baseline&quot;), lty = c(1, 1, 2), bty = &quot;n&quot;, col = c(&quot;red&quot;, &quot;blue&quot;, &quot;black&quot;)) title(&quot;Gamma-frailty population survival&quot;) 3.4 Conclusions Multiplicative Fixed Frailty is one option for modeling Gave us analytical expressions for population survival and hazards including \\(\\bar{\\mu}(x) = \\mu_0(x) \\bar{z}(x)\\) Extended Keyfitz result to age-changing hazards Survival curve for Gamma "],
["gamma-frailty-with-applications.html", "Chapter 4 Gamma Frailty with Applications 4.1 From pop survival to pop hazards 4.2 Selection and observed frailty in CenSoc", " Chapter 4 Gamma Frailty with Applications 4.1 From pop survival to pop hazards We have \\[ \\bar S(x) = {1 \\over \\left(1 + \\sigma^2 H_0(x)\\right)^{1/ \\sigma^2}} \\] Let’s compute \\(\\bar\\mu(x)\\). \\[ \\bar\\mu(x) = {\\mu_0 \\over 1 + \\sigma^2 H_0(x)} \\] 4.1.1 What happens to frailty of survivors? Recall that pop hazards = baseline \\(\\times \\bar{z}(x)\\). So, \\[ \\bar\\mu(x) = \\mu_0(x) { 1 \\over 1 + \\sigma^2 H_0(x)} \\] Sketch \\(\\bar{z}(x)\\). Hint: what form does \\(H_0(x)\\) have? 4.1.1.1 Example: Gamma-Gompertz If \\(H_0(x)\\) be Gompertz, we have closed-form expression. What is it? Does \\(\\bar{z}\\) have the form \\[ {1 \\over 1 + v*e^{w x}} \\] This is a backwards S, going down. sigma.sq = .2 x = 0:100 a = 5 * 10^-4 b = 1/8 H0.x = (a/b) * (exp(b*x) - 1) bar.z = 1 / (1 + sigma.sq * H0.x) plot(x, bar.z) Look at the apparent exponential decline in tail Homework: what is proportional rate of change in \\(\\bar{z}\\) as \\(x\\) gets big? Is it close to Gompertz \\(b\\)? Average frailty in terms of survival \\[ \\bar{z}(x) = [\\bar{S}(x)]^{\\sigma^2}! \\] In real life, we observe \\(\\bar{S}(x)\\). So this allows us to say something about implied \\(\\bar{z}\\) from hazards. Reversing the logic: if we see a characteristic changing with age, then we can estimate “\\({\\sigma^2}\\)” (I put in quotes because its the variance of the proportional effect of the observed characteristic.) 4.2 Selection and observed frailty in CenSoc We have a large matched sample from the 1940 census to Social Security death data observed from 1975 to 2004. This means that we can compute the survival curves of extinct cohorts and see how mortality selection changes the composition of the cohort as it ages. In this example, we use observed wage income in 1940 for the cohort born 1895 to 1900. We look at how wages of survivors increase with age as a result of selective mortality and we see if the gamma-frailty model can produce similar results. 4.2.1 Data Read in the data and transform the variables to what we want. We produce a variable \\(y\\) (in this case a standardized version of log wage income) to be transformed into a frailty score. ## read in dat library(data.table) dt &lt;- fread(&quot;/data/josh/CenSoc/censoc_bfdw.csv&quot;) ## Clean wage data dt[, incwage := INCWAGE] dt[incwage == 999998, incwage := NA] dt[incwage == 0, incwage := NA] hist_incwage &lt;- dt[, hist(incwage)] hist_ln_incwage &lt;- dt[, hist(log(incwage))] ## Do age at death for 1895-1900 cohorts dt[, age.at.death := dyear + dmonth/12 - (byear + bmonth/12)] my.dt &lt;- dt[byear %in% 1895:1900 &amp; dyear %in% 1975:2004] ## now limits to deaths younger than 105 my.dt[, max(age.at.death), by = byear] ## byear V1 ## 1: 1900 104.9167 ## 2: 1898 106.8333 ## 3: 1897 107.0833 ## 4: 1895 109.4167 ## 5: 1899 105.6667 ## 6: 1896 107.9167 nrow(my.dt[age.at.death &gt;= 105]) ## [1] 177 nrow(my.dt[floor(age.at.death) == 104]) ## [1] 253 ## now we have same age range for every cohort my.dt &lt;- my.dt[age.at.death &lt; 105] my.dt &lt;- my.dt[!is.na(incwage)] ## keep only non-missing Log-wages look reasonable, unimodal, kind of symmetric. We now center our variable to 0 before estimating the effect on mortality. Our model exponentiates this 0 to become 1, which is where we want our frailty measure to be centered. ## standardized log income ## log_inc_stan = log(y_orig) - mean(log(y_orig)) ## note: control for byear, since different ages in 1940 my.dt[, y_orig := incwage] my.dt[, log_inc := log(incwage)] my.dt[, log_inc_mean := mean(log_inc), by = byear] my.dt[, y := log_inc - log_inc_mean] hist_y &lt;- my.dt[, hist(y)] my.dt[, summary(y)] ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -7.0542 -0.4159 0.1661 0.0000 0.5660 4.2460 Now we’re centered at 0. Show how our (life-long fixed) characteristic of interest changes by age because of mortality selection. par(mfrow = c(1,2)) my.dt[, plot(x, y_orig.bar)] ## NULL title(&quot;Wage income by surviving age&quot;, cex.main = .7) my.dt[, plot(x, y.bar)] ## NULL title(&quot;Standardized log of Wage income by surviving age&quot;, cex.main = .7) So we see annual wage income in 1940 increases by about $100 or so, or about 5% from age 75 to age 95. And more after that. Is this what we would expect from our Gamma frailty model? 4.2.2 Estimation Estimate an observed frailty for each person, call this \\(z_{obs}\\) To do this we first use Cox regression to estimate the proportional effect of \\(y\\) on hazards. The Cox model has the form \\[ \\mu_i(x) = \\mu_0(x) e^{\\beta y} \\] We can then transform \\(y\\) into a frailty score \\(z_{obs}\\), letting \\[ z_{obs} = e^{\\hat\\beta y} \\] ## now get z&#39;s library(survival) my.dt[, event := 1] m &lt;- coxph(Surv(age.at.death, event) ~ y, data = my.dt) (summary(m)) ## Call: ## coxph(formula = Surv(age.at.death, event) ~ y, data = my.dt) ## ## n= 402797, number of events= 402797 ## ## coef exp(coef) se(coef) z Pr(&gt;|z|) ## y -0.03073 0.96974 0.00177 -17.36 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## exp(coef) exp(-coef) lower .95 upper .95 ## y 0.9697 1.031 0.9664 0.9731 ## ## Concordance= 0.512 (se = 0.001 ) ## Likelihood ratio test= 298 on 1 df, p=&lt;2e-16 ## Wald test = 301.5 on 1 df, p=&lt;2e-16 ## Score (logrank) test = 301.5 on 1 df, p=&lt;2e-16 ## coef exp(coef) se(coef) z Pr(&gt;|z|) ## y -0.03073 0.96974 0.00177 -17.36 &lt;2e-16 *** ## so a 10% increase in income reduces mortality by .3% (quite a tiny effect!) beta &lt;- coef(m) The effect is very small. Any ideas why? Now estimate our z’s. my.dt[, z := exp(beta * y)] hist_z &lt;- my.dt[, hist(z, xlim = c(0, 3))] Does this look gamma-like? Calculating the variance of \\(z_{obs}\\) to be used for estimating \\(\\bar{z}_{obs}\\). (Also plotting the histogram to see if it looks gamma-like) sigma.sq &lt;- var(my.dt$z) print(sigma.sq) ## [1] 0.000745355 print(sqrt(sigma.sq)) ## [1] 0.02730119 Check SD against histogram. Does it look right? Extinct cohort method to estimate survivorship \\(\\bar{S}(x)\\) Dx &lt;- my.dt[, table(floor(age.at.death))] par(mfrow = c(1,2)) plot(Dx) lx &lt;- rev(cumsum(rev(Dx))) lxpn &lt;- c(lx[-1],0) Lx &lt;- (lx + lxpn)/2 mx &lt;- Dx/Lx x &lt;- as.numeric(names(Dx)) plot(x, log(mx), type = &quot;p&quot;) ## gomp fit from ages 80 to 95 m &lt;- lm (log(mx) ~ x, subset = x %in% 80:100) lines(80:100, predict(m), lwd = 2) axis(2) ## no slowdown in mortality!! How does Dx look? Plausible? How about hazards? They are Gompertzian for a while, but how do we explain tails? plot(x, lx) Estimation of \\(\\hat{\\bar{z}}(x)\\) using the gamma-frailty result: \\[ \\bar{z}(x) = \\bar{S}(x)^{\\sigma^2} \\] sx.bar &lt;- lx/lx[1] z.bar.hat &lt;- sx.bar^sigma.sq Comparing this to our observed \\(\\bar{z}\\) x &lt;- 74:104 z.bar &lt;- NULL for (i in 1:length(x)) { z.bar[i] &lt;- my.dt[age.at.death &gt; x[i], mean(z)] } Plotting comparison plot(x, z.bar.hat, ylim = c(.995, 1.001), type = &quot;l&quot;, lty = 2) lines(x, z.bar) How did we do? I’m not quite sure why intercept of observed is not exactly 1.0. (Feel free to play around, but I don’t think this is important – I hope.) Showing plots for observed mortality selection and the gamma-frailty based estimate of mortality selection. Do this for several measures including \\(y\\), and raw (unstandardized) income. y.bar.hat &lt;- log(z.bar.hat)/beta plot(x, y.bar, ylab = &quot;log(inc) - mean(log(inc))&quot;) lines(x, y.bar.hat) title(&quot;Mean standardized log-income&quot;) legend(&quot;topleft&quot;, legend = c(&quot;observed&quot;, &quot;fitted&quot;), pch = c(1, -1), lty = c(-1, 1)) ## ( bar.log.y = mean(log(my.dt$y_orig)) ) ## [1] 7.03562 y_orig.bar.hat.wrong &lt;- exp(y.bar.hat) * exp( bar.log.y) ## this is geometric mean y_orig.bar.hat.right &lt;- exp(y.bar.hat)*y_orig.bar[1] plot(x, y_orig.bar, ylab = &quot;$ per year&quot;) title(&quot;Mean income&quot;) legend(&quot;topleft&quot;, legend = c(&quot;observed&quot;, &quot;fitted&quot;), pch = c(1, -1), lty = c(-1, 1)) lines(x, y_orig.bar.hat.wrong, lty = 2) lines(x, y_orig.bar.hat.right, lty = 1) 4.2.3 Discuss our conclusions and possible future directions to follow. How did we do? Does our gamma frailty model give basically the right prediction? How come it appears that wage income matters so little? How could we improve the measurement of wage income? What other variables could we look at? How would we expect the gamma model do with another variable, e.g. educational attainment? What is the relationship between “observed” and “unobserved” frailty? IMPORTANT: Is our work here a validation of the model’s applicability to real life? If so what are we validating? That our transformed covariate is roughly gamma distributed? Are we assuming multiplicative fixed frailty – or are we validating it’s applicability? "],
["convergence-and-cross-overs.html", "Chapter 5 Convergence and cross-overs 5.1 Outline 5.2 What happens to mortality disparities at older ages? 5.3 Student Presentation", " Chapter 5 Convergence and cross-overs 5.1 Outline Concepts Student Presentation 5.2 What happens to mortality disparities at older ages? Cumulative disadvantage Age as a leveler Individual adaptation/plasticity, gov support, separation from unequal structures like labor market Bad data / measurement Unreliable ages, institutionalization changes sample, etc. Nothing It’s all selection (“frailty”), pop hazards but individual hazards would have remained “parallel”. Our goal is to examine this last “null hypothesis”. What can frailty explain, and what can’t it? 5.2.1 A possible null-model 2 groups, each with internal gamma-frailty proportional baseline hazards \\[ \\mu_2(x) = R \\mu_1(x) \\] see V&amp;M (38) \\[ \\mu_1(x |z_1) = \\mu_1 z_1 \\\\ \\mu_2(x |z_2) = \\mu_2 z_2 \\] And, frailty terms are each gamma, with mean 1 and own variances. 5.2.2 A result: (5E) \\[ \\bar{R}(x) \\equiv {\\bar\\mu_2(x) \\over \\bar\\mu_1(x)} = {R + R\\sigma_1^2 H_1(x) \\over 1 + R \\sigma_2^2 H_1(x)} \\] Questions: If variances are equal. What happens at age 0? What happens at very old ages. If the higher mortality group has bigger frailty variance, what happens at older ages? Same if higher mortality group has smaller frailty variance? Homework: prove this, simulate this. see if cross of is when cumulative hazards satisfy the condition at the end of 5E). (* problem. can you solve for x0 in temrs of variances 1 and 2 and R with gamma gompertz? 5.2.3 Inversion Our challenge is to invert a not easy pop hazards formula \\[ \\bar{\\mu}(x) = {\\mu_0(x) \\over 1 + \\sigma^2 H_0(x)} \\] because we have both hazards and cumulative hazards on right. Hazards are slope of log survival Recall for Gamma, \\[ \\bar{S}(x) = { 1 \\over (1 + \\sigma^2 H_0(x))^{1/\\sigma^2}} \\] We write down the hazard as the derivative of log survival \\[ \\bar{\\mu}(x) = {1 \\over \\sigma^2} {d \\over dx} \\log(1 + \\sigma^2 H_0(x)). \\] The anti-derivative of both sides, gives \\[ \\bar{H}(x) = {1 \\over \\sigma^2} \\log(1 + \\sigma^2 H_0(x)). \\] And now we have only 1 expression involving the baseline hazards on the right. Solving \\[ \\bar{H}(x) = {1 \\over \\sigma^2} \\log(1 + \\sigma^2 H_0(x)). \\] gives us the cumulative hazard \\[ H_0(x) = {1 \\over \\sigma^2} \\left(e^{\\sigma^2 \\bar{H}(x)} - 1 \\right). \\] And differencing, gives us a remarkably simple expression for the baseline hazard in terms of the observed popualtion hazard \\[ \\mu_0(x) = \\bar\\mu(x) e^{\\sigma_2 \\bar{H}(x)} \\] We don’t observe underlying baseline hazard \\(\\mu_0\\) on left What is observed (and unobserved) on right? 5.2.4 An example library(data.table) dt &lt;- fread(&quot;/hdir/0/fmenares/Book/bookdown-master/data/ITA.cMx_1x1.txt&quot;, na.string = &quot;.&quot;) my.dt &lt;- dt[Year == 1915] my.dt[, H.f := cumsum(Female)] my.dt[, H.m := cumsum(Male)] my.dt[, h.f := Female] my.dt[, h.m := Male] sigma.sq &lt;- .5^2 my.dt[, h0.f.5 := h.f * exp(sigma.sq *H.f)] my.dt[, h0.m.5 := h.m * exp(sigma.sq *H.m)] sigma.sq &lt;- .2^2 my.dt[, h0.f.2 := h.f * exp(sigma.sq *H.f)] my.dt[, h0.m.2 := h.m * exp(sigma.sq *H.m)] sigma.sq &lt;- 1^2 my.dt[, h0.f1 := h.f * exp(sigma.sq *H.f)] my.dt[, h0.m1 := h.m * exp(sigma.sq *H.m)] Italian Females, born 1915 (\\(\\sigma^2 = .2^2, .5^2, 1^2\\)) par(mfrow = c(1,2)) foo &lt;- my.dt[, plot(Age, H.f, col = &quot;red&quot;)] title(&quot;Cumulative Hazards\\n Italian Females born 1915&quot;) foo &lt;- my.dt[, plot(Age, log(h.f), type = &quot;l&quot;, ylim = c(-7, 2), col = &quot;red&quot;, main = &quot;Observed vs. implied baseline&quot;)] foo &lt;- my.dt[, lines(Age, log(h0.f.2), lty = 2, col = &quot;red&quot;)] foo &lt;- my.dt[, lines(Age, log(h0.f.5), lty = 3, col = &quot;red&quot;)] foo &lt;- my.dt[, lines(Age, log(h0.f1), lty = 4, col = &quot;red&quot;)] legend(&quot;topleft&quot;, legend = c(&quot;baseline&quot;, &quot;obs if s2 = .2^2&quot;, &quot;obs if s2 = .5^2&quot;, &quot;obs if s2 = 1^2&quot;), col = &quot;red&quot;, lty = 1:4) Italian Females vs Males born 1915 (\\(\\sigma^2 = .5^2\\)) par(mfrow = c(1,2)) ## title(&quot;Cumulative Hazards\\n Italian Females born 1915&quot;) foo &lt;- my.dt[, plot(Age, log(h.f), type = &quot;l&quot;, ylim = c(-7, 2), col = &quot;red&quot;, main = &quot;Observed vs. implied baseline&quot;)] foo &lt;- my.dt[, lines(Age, log(h0.f.5), lty = 2, col = &quot;red&quot;)] ugh &lt;- my.dt[, lines(Age, log(h.m), type = &quot;l&quot;, col = &quot;blue&quot;)] ugh &lt;- my.dt[, lines(Age, log(h0.m.5), lty = 2, col = &quot;blue&quot;)] legend(&quot;topleft&quot;, legend = c(&quot;female observed&quot;, &quot;female baseline&quot;, &quot;male observed&quot;, &quot;male baseline&quot;), col = c(&quot;red&quot;,&quot;red&quot;, &quot;blue&quot;, &quot;blue&quot;), lty = c(1,2, 1,2)) ## now do difference foo &lt;- my.dt[, plot(Age, h.m/h.f, type = &quot;l&quot;, col = &quot;black&quot;, ylab = c(&quot;h.m/h.f&quot;), main = &quot;Male-female hazard ratio&quot;)] foo &lt;- my.dt[, lines(Age, h0.m.5/h0.f.5, lty = 2)] legend(&quot;topright&quot;, legend = c(&quot;observed&quot;, &quot;implied baseline&quot;), ## col = c(&quot;red&quot;,&quot;blue&quot;), lty = 1:2) Much bigger convergence in ``observed’’ than in baseline 5.2.5 Application 5.3 Student Presentation "],
["mortality-plateaus.html", "Chapter 6 Mortality plateaus 6.1 Outline 6.2 Heterogeneity slows mortality improvement 6.3 Conclusions 6.4 Ken’s class", " Chapter 6 Mortality plateaus 6.1 Outline Math Ken’s class Presentation 6.2 Heterogeneity slows mortality improvement Define \\(\\rho(x,t)\\) be the rate of mortality \\[ \\rho(x,t) = - {d \\over dt} \\log \\bar\\mu(x,t) \\] Extending our gamma result for 1 cohort to the surface, \\[ \\bar\\mu(x,t) = \\mu_0(x,t) \\bar{S}_c(x,t)^{\\sigma^2} \\] We take the log and the time-derivative of hazards give (39^*) \\[ \\rho(x,t) = \\rho_0(x,t) - \\sigma^2 {d \\over dt} \\log \\bar{S}_c(x,t)^{\\sigma^2} \\] So individual risks from one cohort to the next are going down faster it seems. Intuition? 6.2.1 An example Assume \\(\\sigma^2 = .2\\). library(data.table) sigma.sq = .2 dt &lt;- fread(&quot;/hdir/0/fmenares/Book/bookdown-master/data/ITA.bltcoh_1x1.txt&quot;, na.string = &quot;.&quot;) mx.80.c1880 &lt;- dt[Year == 1880 &amp; Age == &quot;80&quot;]$mx mx.80.c1900 &lt;- dt[Year == 1900 &amp; Age == &quot;80&quot;]$mx (rho.bar.80 &lt;- -log(mx.80.c1900/mx.80.c1880)/20) ## about 0.8% ## [1] 0.008729961 Sx.80.c1880 &lt;- dt[Year == 1880 &amp; Age == &quot;80&quot;]$lx Sx.80.c1900 &lt;- dt[Year == 1900 &amp; Age == &quot;80&quot;]$lx (d.log.Sx &lt;- log(Sx.80.c1900/Sx.80.c1880)/20) ## [1] 0.02177952 (rho.0.80 = rho.bar.80 + sigma.sq * d.log.Sx) ## about 1.3% ## [1] 0.01308586 So mortality progress is more than 50% faster than it appears! Issues? 6.3 Conclusions Gamma frailty gives simple expressions for population survival, hazard, and average frailty. Gamma frailty gives a plateau Gamma frailty gives us a predicted rate of convergence and cross-over with age All of this means it is a useful null model. Takes us away from “it could be selection” to “what if it were selection” 6.4 Ken’s class "],
["tempo.html", "Chapter 7 Tempo 7.1 Outline 7.2 Introduction 7.3 Period Shifts: Bongaarts and Feeney’s model 7.4 An Application to the United States 7.5 Two Americas 7.6 Conclusions", " Chapter 7 Tempo 7.1 Outline Introduction and a tempo simulation Bongaarts and Feeney’s formula An application to the United States Two Americas? EM algorithm for unmixing mixtures An application to two Americas. 7.2 Introduction What we see is superficial. Heterogeneous models reveal what’s “really” going on. (Or do they?) - Until today, population hazards mislead - Today, homogeneous fertility misleads Now we will reverse perspectives We see differences we see in genotypes, in lineages, in names. These could be due to “real” differences (heterogeneity). But they could also be due to luck. Everyone is the same but stochastic outcomes differ. Our models of individual-level randomness will have predicted dynamics, which are themselves interesting but can also be used as a “null” to compare to observations. 7.2.1 Fertility postponement, a very simple example Baseline A population has a history of 1 birth per day When women turn age 25, they have a daughter. This gives us a constant stream of births, 365 per year. Postponement Starting on Jan. 1, 020, everyone postponements childbearing an additional month, until they are aged 25 1/12. How many births will there be in 2020? How many births in 2021? 7.2.2 Continuous postponement, a shiny simulation \\(R(t)\\) Cumulative postponment \\(r(t)\\) Incremental postponement \\(r(t) = R&#39;(t)\\) What is a formula for recovering original birth stream? \\[ \\hat{B}_{orig} = B_{obs} \\times (1 + R&#39;(t)) \\] or \\[ \\hat{B}_{orig} = B_{obs} \\times 1/ \\left[1 - R&#39;(t)\\right]? \\] Note: this idea of ``recovering original’’ is one way to think about tempo adjustment. 7.3 Period Shifts: Bongaarts and Feeney’s model A bigger microsimulation - Each period will have births across a range of ages - We’ll randomly generate the original planned birthdays - Then we’ll shift by a continuous function \\(R(t)\\). \\[ f(a,t) = f_0(a - R(t)) (1- R&#39;(t)) q(t) \\] \\(f(a,t)\\) birth rate of women aged \\(a\\) in period \\(t\\) \\(f_0\\) A constant baseline schedule (can be norm’d to sum to 1). \\(q(t)\\) A period intensity parameter: ``quantum’’ \\(R(t)\\) Cumulative shift. An example \\[ f(a,t) = f_0(a - R(t)) (1- R&#39;(t)) q(t) \\] \\(R_{2019} = 3\\) \\(R&#39;_{2019} = .1\\) \\(q(2019) = 1\\) Give an expression for \\(f(28,2019)\\). 7.3.1 A derivation: due to Rodriguez Assume no quantum effects. Take a cohort with cumulative fertility \\[ F_0(a) = \\int_0^a f(x) \\,dx \\] Now put in shifts so that observed fertility is from an age \\(R(t)\\) years earlier. (“28” is the new “25”!) \\[ F(a,t) = F_0(a - R(t)) = F_0(a - R(c + a)) \\] Differentiate with respect to age (which for a cohort is also time \\(t\\)), using chain rule \\[ f(a,t) = f_0(a - R(t)) \\left[1 - R&#39;(t)\\right] \\] Let’s re-notate our constant quantum result \\[ f_0(a,t | R(t) ) = f_0(a - R(t)) \\left[1 - R&#39;(t)\\right] \\] Then we can incorporate period quantum on the shifted surface: \\[ f(a,t) = f_0(a,t | R(t) ) q(t) = f_0(a - R(t)) \\left[1 - R&#39;(t)\\right]q(t) \\] Note: If we vary quantum before shifts, then \\(q(t)\\) will bleed into neighboring years. (a small effect, but makes model messier). Tempo-adjusted TFR: counter-factual, TFR in absence of timing changes \\[ TFR(t) = \\int_0^\\infty f(a,t) \\, da \\] Substituting our shifted birth rates with quantum \\[ TFR(t) = \\int_0^\\infty f_0(a - R(t)) \\left[1 - R&#39;(t)\\right]q(t) \\] gives? \\[ TFR(t) = TFR_0 \\left[1 - R&#39;(t)\\right] q(t) \\] WLG, define \\(TFR_0 = 1\\), then \\[ q(t) = TFR(t) \\over{1 - R&#39;(t)} \\equiv TFR^*(t) \\] Voila, the BF formula How do period schedules change? For homework \\[ f(a,t) = f_0(a - R(t)) \\left[1 - R&#39;(t)\\right] \\] What does \\[ {\\partial \\over \\partial t} \\log f(a,t) = ? \\] Let’s sketch Uniform shifts BF model assumes all ages shift by \\(R(t)\\). BF model assumes all ages rise or fall by same quantum \\(q(t)\\) Violating these assumptions means change in mean age will not just reflect “tempo”. Example: What happens if people have fewer higher order births? BF recommendation for achieving uniformity Separate estimates for each birth order, and then combine: \\[ TFR^*(t) = \\sum_i TFR_i^*(t) = \\sum_i {TFR_i(t) \\over 1 - r_i(t)} \\] This will protect against order-specific quantum effects. 7.4 An Application to the United States Tempo adjustment of US fertility using HFD data using Bongaarts-Feeney formula: Read in data and format into an array library(data.table) source(&quot;/hdir/0/fmenares/Book/bookdown-master/codes/tempo_functions.R&quot;) source(&quot;/hdir/0/fmenares/Book/bookdown-master/codes/utility_functions.R&quot;) ## age specific fertility rates by birth order for all countries and times ## RR means &quot;rectangles&quot; on Lexis surface dt &lt;- fread(&quot;/hdir/0/fmenares/Book/bookdown-master/data/zip_w/asfrRRbo.txt&quot;) dt &lt;- dt[Code == &quot;USA&quot;] ## keep only US ## keep only ages 15 to 49 dt &lt;- dt[Age %in% 15:49] print(dt) ## Code Year Age ASFR ASFR1 ASFR2 ASFR3 ASFR4 ASFR5p ## 1: USA 1933 15 0.00672 0.00647 0.00025 0.00000 0.00000 0.00000 ## 2: USA 1933 16 0.01875 0.01744 0.00121 0.00009 0.00000 0.00000 ## 3: USA 1933 17 0.03846 0.03337 0.00464 0.00038 0.00005 0.00002 ## 4: USA 1933 18 0.06586 0.05150 0.01256 0.00154 0.00021 0.00004 ## 5: USA 1933 19 0.08719 0.05946 0.02249 0.00446 0.00064 0.00014 ## --- ## 2971: USA 2017 45 0.00189 0.00048 0.00045 0.00032 0.00023 0.00041 ## 2972: USA 2017 46 0.00102 0.00028 0.00026 0.00016 0.00012 0.00019 ## 2973: USA 2017 47 0.00059 0.00019 0.00015 0.00009 0.00005 0.00010 ## 2974: USA 2017 48 0.00029 0.00010 0.00008 0.00004 0.00002 0.00005 ## 2975: USA 2017 49 0.00023 0.00008 0.00005 0.00004 0.00002 0.00003 ## put all order fertiility into a matrix fat &lt;- dt[, xtabs(ASFR ~ Age + Year)] fat &lt;- as.matrix(unclass(fat)) ## may cause problems, we&#39;ll see fat1 &lt;- dt[, xtabs(ASFR1 ~ Age + Year)] fat2 &lt;- dt[, xtabs(ASFR2 ~ Age + Year)] fat3 &lt;- dt[, xtabs(ASFR3 ~ Age + Year)] fat4 &lt;- dt[, xtabs(ASFR4 ~ Age + Year)] fat5p &lt;- dt[, xtabs(ASFR5p ~ Age + Year)] year.vec &lt;- colnames(fat) age.vec &lt;- rownames(fat) parity.vec &lt;- c(&quot;all&quot;, 1:5) fat.array &lt;- array(NA, dim = c(nrow(fat), ncol(fat), length(parity.vec))) dimnames(fat.array) &lt;- list(age.vec, year.vec, parity.vec) fat.array[,,&quot;all&quot;] &lt;- fat fat.array[,,&quot;1&quot;] &lt;- fat1 fat.array[,,&quot;2&quot;] &lt;- fat2 fat.array[,,&quot;3&quot;] &lt;- fat3 fat.array[,,&quot;4&quot;] &lt;- fat4 fat.array[,,&quot;5&quot;] &lt;- fat5p Fit bongaarts feeney without birth order tfr.vec &lt;- colSums(fat) ## (2a) by hand mu.vec &lt;- apply(fat, 2, get.mean) rt.vec &lt;- center.diff(mu.vec) adj.tfr.vec &lt;- tfr.vec / (1 - rt.vec) par(mfrow = c(3,1)) plot(names(mu.vec), mu.vec) plot(names(mu.vec), rt.vec) abline(h =0) plot(year.vec, tfr.vec, type = &quot;l&quot;) lines(year.vec, adj.tfr.vec, lty = 2) abline(v = c(1945, 2008)) We see fertility since 1980 has been depressed by postponment We see weird dynamics around end of WW2 and great recession. What’s going on? par(mfrow = c(1,1)) plot(year.vec, tfr.vec, type = &quot;l&quot;) lines(year.vec, adj.tfr.vec, lty = 2) abline(v = c(1945, 2008)) abline(h = seq(1.5, 4, .1), col = &quot;grey&quot;, lty = 3) ## can also use function to fit adj.tfr.vec.from.fun &lt;- bf.fit.simple(fat)$tfr.star lines(year.vec, adj.tfr.vec.from.fun, col = &quot;red&quot;) Now let’s look at turbulence around WW2 par(mfrow = c(2,2)) plot(age.vec, fat[,&quot;1944&quot;], type = &quot;l&quot;, ylim = c(0, .23), ylab = &quot;f(a)&quot;, xlab = &quot;age a&quot; ) lines(age.vec, fat[,&quot;1945&quot;], type = &quot;l&quot;, col = &quot;red&quot;) lines(age.vec, fat[,&quot;1946&quot;], type = &quot;l&quot;, col = &#39;orange&#39;) lines(age.vec, fat[,&quot;1947&quot;], type = &quot;l&quot;, col = &quot;blue&quot;) legend(&quot;topright&quot;, legend = 1944:1947, col = c(&quot;black&quot;, &quot;red&quot;, &quot;orange&quot;, &quot;blue&quot;), lty = 1) title(&quot;Age specific fertility&quot;) ## plot(1943:1947, mu.vec[paste(1943:1947)], ylab = &quot;mu(t)&quot;, xlab = &quot;t&quot;, col = c(&quot;black&quot;, &quot;black&quot;, &quot;red&quot;, &quot;orange&quot;, &quot;blue&quot;), pch = 19) title(&quot;Mean ages&quot;) ## plot(1943:1947, rt.vec[paste(1943:1947)], ylab = &quot;r(t)&quot;, xlab = &quot;t&quot;, col = c(&quot;black&quot;, &quot;black&quot;, &quot;red&quot;, &quot;orange&quot;, &quot;blue&quot;), pch = 19) title(&quot;Changes in mean, centered&quot;) ## plot(1943:1947, tfr.vec[paste(1943:1947)], ylab = &quot;tfr&quot;, xlab = &quot;t&quot;, ylim = c(1, 4), type = &quot;l&quot;) lines(1943:1947, adj.tfr.vec[paste(1943:1947)], lty = 2) title(&quot;TFR and adjTFR&quot;) From 1945 to 1946, fertility goes up a lot, but more at younger ages. So mean goes down. BF adjustment over-compensates, and has quantum declining. What’s happening from 1944-45? Fit bongaarts feeney with birth order out &lt;- bf.fit(fat.array) adj.tfr.bo.vec &lt;- out$tfr.star.out[, &quot;bf.tfr.star&quot;] ## pdf(&quot;usa_tempo_fig.pdf&quot;) par(mfrow = c(1,1)) plot(year.vec, tfr.vec, type = &quot;l&quot;, lwd = 2) lines(year.vec, adj.tfr.vec, lty = 2) lines(year.vec, adj.tfr.bo.vec, lty = 1, lwd = 2, col = &quot;red&quot;) ## let&#39;s check against hfd hfd.adj.dt &lt;- fread(&quot;/hdir/0/fmenares/Book/bookdown-master/data/zip_w/adjtfrRR.txt&quot;, skip = 2) hfd.adj.dt &lt;- hfd.adj.dt[Code == &quot;USA&quot;] hfd.adj.dt[, points(Year, adjTFR, col = &quot;red&quot;, cex = .8)] ## NULL legend(&quot;topright&quot;, c(&quot;tfr&quot;, &quot;tfr* (all parities)&quot;, &quot;tfr* (by parity)&quot;), col = c(&quot;black&quot;, &quot;black&quot;, &quot;red&quot;), lty = c(1, 2, 1), lwd = c(2,1,2)) hfd.adj.dt[, lines(Year, filter(adjTFR, rep(1/7, 7)), col = &quot;red&quot;, lwd = 4)] ## NULL 7.4.1 Questions Does taking birth order into account smooth WW2 turbulence? Does taking birth order into account smooth Recession turbulence? Does taking birth order into account, retell the baby boom? Does taking birth order into account, retell the baby bust? 7.4.2 Conclusions Baby boom smaller if we account for “pre-ponement”. Fertility lull in 1970s and 80s disappears if we account for “postponement”. Birth order disaggregation improves estimates of shifts from changes in mean age What happened with the recession? 7.5 Two Americas Let’s look at births (all orders). “Animation” of asfr change from about 2000 to about 2018 age specific fertility rates by birth order for all countries and times (RR means “rectangles” on Lexis surface) dt &lt;- fread(&quot;/hdir/0/fmenares/Book/bookdown-master/data/zip_w/asfrRRbo.txt&quot;) dt &lt;- dt[Code == &quot;USA&quot;] ## keep only US ## keep only ages 15 to 49 dt &lt;- dt[Age %in% 15:44] print(dt) ## Code Year Age ASFR ASFR1 ASFR2 ASFR3 ASFR4 ASFR5p ## 1: USA 1933 15 0.00672 0.00647 0.00025 0.00000 0.00000 0.00000 ## 2: USA 1933 16 0.01875 0.01744 0.00121 0.00009 0.00000 0.00000 ## 3: USA 1933 17 0.03846 0.03337 0.00464 0.00038 0.00005 0.00002 ## 4: USA 1933 18 0.06586 0.05150 0.01256 0.00154 0.00021 0.00004 ## 5: USA 1933 19 0.08719 0.05946 0.02249 0.00446 0.00064 0.00014 ## --- ## 2546: USA 2017 40 0.02252 0.00470 0.00640 0.00485 0.00298 0.00360 ## 2547: USA 2017 41 0.01575 0.00324 0.00437 0.00327 0.00207 0.00278 ## 2548: USA 2017 42 0.01004 0.00213 0.00267 0.00198 0.00133 0.00193 ## 2549: USA 2017 43 0.00610 0.00131 0.00154 0.00120 0.00079 0.00126 ## 2550: USA 2017 44 0.00341 0.00076 0.00087 0.00064 0.00044 0.00070 ## put all order fertiility into a matrix fat &lt;- dt[, xtabs(ASFR ~ Age + Year)] fat &lt;- as.matrix(unclass(fat)) ## may cause problems, we&#39;ll see fat1 &lt;- dt[, xtabs(ASFR1 ~ Age + Year)] fat1 &lt;- as.matrix(unclass(fat1)) ## may cause problems, we&#39;ll see year.vec &lt;- colnames(fat) age.vec &lt;- rownames(fat) my.year.vec &lt;- 1975:2017 #pdf(&quot;fat_movie.pdf&quot;) par(mar=c(1,1,1,1)) par(mfrow = c(11,4)) for (i in 1:length(my.year.vec)) { my.year &lt;- my.year.vec[i] plot(age.vec, fat[, paste(my.year)], ylim = c(0, .15), xlim = c(15,49), xlab = &quot;age&quot;, ylab = &quot;age-specific fertility rate&quot;, type = &quot;l&quot;) title(my.year) } #dev.off() Now fit mixing model and redo the animation if (0) { mu.mat &lt;- get.coefs.mixed(out.all$fert.fit.list.variable.sigma)$mu.mat lambda.mat &lt;- get.coefs.mixed(out.all$fert.fit.list.variable.sigma)$lambda.mat sigma.mat &lt;- get.coefs.mixed(out.all$fert.fit.list.variable.sigma)$sigma.mat } mu.mat &lt;- get.coefs.mixed(out.all$fert.fit.list)$mu.mat lambda.mat &lt;- get.coefs.mixed(out.all$fert.fit.list)$lambda.mat sigma.mat &lt;- get.coefs.mixed(out.all$fert.fit.list)$sigma.ma matplot(my.year.vec, t(mu.mat)) abline(v = 2015)## problem here points(c(2015, 2015), c(21.5, 30.3)) matplot(my.year.vec, t(lambda.mat)) abline(v = 2015)## problem here points(c(2015, 2015), c(21.5, 30.3)) ## interpolate 1915 colnames(lambda.mat) &lt;- my.year.vec colnames(mu.mat) &lt;- my.year.vec lambda.mat[,&quot;2015&quot;] &lt;- (lambda.mat[,&quot;2014&quot;] + lambda.mat[,&quot;2016&quot;])/2 mu.mat[,&quot;2015&quot;] &lt;- (mu.mat[,&quot;2014&quot;] + mu.mat[,&quot;2016&quot;])/2 Plot normalized plot with the normal distributions inside. plot.fun3 &lt;- function(last.year, A = Aall) { year.vec &lt;- colnames(A) fx &lt;- A[,paste(last.year)] fx &lt;- fx/sum(fx) x &lt;- as.numeric(names(fx)) ## par(mfrow = c(1,1)) plot(x, fx, ylim = c(0, .1), ylab = &quot;normalized fx&quot;) s &lt;- year.vec == last.year print(s) dim(mu.mat) length(s) print(x) print(mu.mat[1,s]) fx1.hat &lt;- dnorm(x, mean = mu.mat[1,s], sd = sigma.mat[1,s]) * lambda.mat[1,s] lines(x, fx1.hat, col = &quot;red&quot;) fx2.hat &lt;- dnorm(x, mean = mu.mat[2,s], sd = sigma.mat[2,s]) * lambda.mat[2,s] lines(x, fx2.hat, col = &quot;blue&quot;) lines(x, fx1.hat + fx2.hat) title(last.year) } plot.fun.nonorm.3 &lt;- function(last.year, A = Aall) { ## don&#39;t normalize, but this means we have to multiply mixture by TFR year.vec &lt;- colnames(A) fx &lt;- A[,paste(last.year)] ## fx &lt;- fx/sum(fx) x &lt;- as.numeric(names(fx)) ## par(mfrow = c(1,1)) plot(x, fx, ylim = c(0, .3), ylab = &quot;normalized fx&quot;) s &lt;- year.vec == last.year this.tfr &lt;- sum(fx) fx1.hat &lt;- dnorm(x, mean = mu.mat[1,s], sd = sigma.mat[1,s]) * lambda.mat[1,s]* this.tfr lines(x, fx1.hat, col = &quot;red&quot;) fx2.hat &lt;- dnorm(x, mean = mu.mat[2,s], sd = sigma.mat[2,s]) * lambda.mat[2,s] * this.tfr lines(x, fx2.hat, col = &quot;blue&quot;) lines(x, fx1.hat + fx2.hat) title(last.year) } Fat Mix Aall &lt;- my.fat #pdf(&quot;fat_mix_movie.pdf&quot;) par(mar=c(1,1,1,1)) par(mfrow = c(11,4)) for (i in 1:length(my.year.vec)) { my.year &lt;- my.year.vec[i] plot.fun.nonorm.3(my.year) } #dev.off() Let’s do tempo adjustment rt.mat &lt;- t(apply(mu.mat, 1, center.diff)) tfr.vec &lt;- apply(my.fat, 2, sum) tfr.mat &lt;- lambda.mat * tfr.vec par(mfrow = c(1,2)) matplot(my.year.vec, t(tfr.mat), ylim = c(0, 3)) tfr.star.mat &lt;- tfr.mat / (1 - rt.mat) matplot(my.year.vec, t(tfr.star.mat), ylim = c(0,3)) tfr.star.vec &lt;- colSums(tfr.star.mat) par(mfrow = c(1,1)) plot(my.year.vec, tfr.vec, type = &quot;l&quot;, ylim = c(1, 3)) lines(my.year.vec, tfr.star.vec, lty = 2) Let’s look at 1st births, again as if their are two latent groups: \\(A\\) and \\(B\\). (These could be “early moms” / “late moms”, non-college / college, pre-marital / marital, lower-class / upper class, \\(\\ldots\\)) library(mixtools) ## simulate 2 normals N &lt;- 1000 x1 &lt;- rnorm(N, mean = 22, sd = 3) ## x2 &lt;- rnorm(2*N, mean = 30, sd = 4) ## combine them x &lt;- c(x1,x2) ## use EM to infer mixture out &lt;- normalmixEM(x, lambda = c(.5, .5), mu = c(15, 35), sigma = c(5,5)) ## number of iterations= 371 print(out$mu) ## [1] 22.62401 30.73713 print(out$sigma) ## [1] 3.265651 3.645539 print(out$lambda) ## [1] 0.4259413 0.5740587 Seems to work great. ages &lt;- 10:49 dens1 &lt;- dnorm(x = ages, mean = out$mu[1], sd = out$sigma[1]) * out$lambda[1] dens2 &lt;- dnorm(x = ages, mean = out$mu[2], sd = out$sigma[2]) * out$lambda[2] par(mfrow = c(1,1)) hist(x, probability = T, col = &quot;grey&quot;) lines(ages, dens1, col = &quot;red&quot;, lwd = 2) lines(ages, dens2, col = &quot;blue&quot;, lwd = 2) lines(ages, dens1 + dens2, col = &quot;black&quot;, lwd = 2) 7.5.1 An algorithm for tempo adjustment of mixtures Fit normal mixture to each year. Refit using constant variance (average). This assures shape invariance of each component, fulfilling BF assumption. Estimate BF separately for \\(A\\) and \\(B\\), and combine. tempo_mixed_results_figure.pdf 7.6 Conclusions Postponement dilutes period births, lowers TFR Tempo-adjustment tries to ``put births back in’’ Changes in mean work fine if ``shape’’ doesn’t change Shape can change through heterogeneity With strong assumptions, we can identify heterogeneity Declining quantum for young and postponement for old appears to be the story 7.6.1 Caveats Who are these latent groups? Do you start out in one and end up in the other? Do you stay in one your whole life? How do we project forward? Can we use other indicators (e.g., social class, education, marriage) to get same results? "],
["branching-processes.html", "Chapter 8 Branching Processes 8.1 Outline 8.2 Motivation 8.3 Simulations 8.4 The Probability Generating Function: Our mathematical tool 8.5 Extinction 8.6 Good and bad set-ups for branching process 8.7 The distribution of offspring of all generations 8.8 Geometric offspring distribution 8.9 Branching Processes and Covid-19", " Chapter 8 Branching Processes 8.1 Outline The Galton-Watson-Bienaym'e Process: Motivation Simulating a branching process Moment generating functions Extinction probabilities The distribution of offspring of all generations A tractable offspring distribution 8.2 Motivation Until now, we’ve focused on the hidden structures of heterogeneity. Now, we’re switching gears: Stochastic not deterministic In small populations, randomness matters. (Even when risks are homogeneous.) branching processes (“parents producing children”), next Fisher-Wright (“children choosing parents”), and then historical reconstruction from contemporary diversity (“coalescent”). 8.2.1 Very brief history of Branching Processes Bienayme’s lost notes Old motivation - Galton and Watson’s: to see if elites were dying out because of “degeneration” Contemporary motivation: evolution and neutral genetic change. what is the chance that a mutant will survive? War-time motivation: to see how to build the bomb (chain reactions) Sociological: Anywhere “incipient dynamics” matter (will all of S. Korea be “Kim”?) Can we get variance of repro success from name disn? It will give us a headstart on other (less realistic but easier) “drift” models. 8.2.2 Applicability to the Coronavirus? Yes and no. Perhaps the beginning, with first few cases. But once scale gets large, we’ll see that deterministic dynamics take over. One lesson: beyond \\(R_0\\). 8.2.3 Simulated examples and the questions they raise Here are the chances that the first carrier passes on the virus to \\(k\\) people? \\(k\\) \\(p_k\\) digits 0 .3 0-2 1 .4 3-5 2 .3 6-9 What is \\(R_0\\), (aka \\(m\\))? Calculate. Let’s diagram one chance outcome, using my number “(xxx) xxx-9056” \\(k\\) \\(p_k\\) digits 0 .3 0-2 1 .4 3-5 2 .3 6-9 8.2.4 What is a (Bienayme)-Galton-Watson branching process? \\(p_k\\): Each individual in each generation reproduces independently, following same offspring distribution, with \\(p_k\\) as the probability of having \\(k\\) offspring. \\(Z_n\\): The si\\(Z\\)e of the \\(n\\)’th generation \\(Z_n\\). (\\(Z_1 \\equiv 1\\)) \\(p_0 &gt; 0\\): Some non-zero probability of no children. Variance: None of the \\(p_k\\) are 1 Galton’s original question Some questions What is the chance \\(d\\) of eventual extinction (no “outbreak”)? Or, what is the distribution of surviving family sizes? What are the aggregate properties of many branching processes? (Mean growth, variance, time-paths, eventual size)? 8.3 Simulations k = 0:2 p0 = .3; p1 = .3; p2 = .4; p_k = c(p0, p1, p2) Z1 = 1 set.seed(9) (kids.of.Z1 = sample(x = k, size = Z1, replace = T, prob = p_k)) ## [1] 2 (Z2 = sum(kids.of.Z1)) ## [1] 2 (kids.of.Z2 = sample(x = k, size = Z2, replace = T, prob = p_k)) ## [1] 2 2 (Z3 = sum(kids.of.Z2)) ## [1] 4 (kids.of.Z3 = sample(x = k, size = Z3, replace = T, prob = p_k)) ## [1] 2 1 2 2 (Z4 = sum(kids.of.Z3)) ## [1] 7 Let’s draw the tree. /\\ /\\/\\ /\\/ /\\ \\[ /\\\\ /\\\\/\\\\ /\\\\/ /\\\\ \\] #A function branch &lt;- function(n_max = 30, pk = c(p0, p1, p2), Z1 = 1) { Z.vec &lt;- rep(NA, n_max) Z.vec[1] &lt;- Z1 for (i in 1:(n_max-1)) { Z.vec[i+1] &lt;- sum(sample(x = k, size = Z.vec[i], replace = T, prob = p_k)) } return(Z.vec) } set.seed(19); branch() ## [1] 1 2 2 4 5 2 2 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 set.seed(99); branch() ## [1] 1 1 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Let’s see what happens with 20 trials (up to 30 generations) n_trials = 20; n_gen = 30 Z.mat &lt;- matrix(NA, n_trials, n_gen) set.seed(131) for (i in 1:n_trials) Z.mat[i,] &lt;- branch(n_max = n_gen) matplot(t(Z.mat), type = &quot;l&quot;, lty = 1, ylab = &quot;Zn&quot;, xlab = &quot;n&quot;) How many survive (out of 20)? log-scale suppressWarnings(matplot(t(Z.mat), log = &quot;y&quot;, type = &quot;l&quot;, lty = 1, ylab = &quot;Zn&quot;, xlab = &quot;n&quot;)) surviving = ifelse(Z.mat[,n_gen] == 0, &quot;extinct&quot;, &quot;survive&quot;) foo &lt;- prop.table(table(surviving)) print( prop.table(table(surviving)) ) ## surviving ## extinct survive ## 0.5 0.5 How would you discribe the time path of the surviving lines? Long term n_trials = 20; n_gen = 100 Z.mat &lt;- matrix(NA, n_trials, n_gen) set.seed(131) for (i in 1:n_trials) Z.mat[i,] &lt;- branch(n_max = n_gen) suppressWarnings(matplot(t(Z.mat), log = &quot;y&quot;, type = &quot;l&quot;, lty = 1, ylab = &quot;Zn&quot;, xlab = &quot;n&quot;)) What does this remind you of? (Hint: “Leslie”). (See Harris figure) 8.4 The Probability Generating Function: Our mathematical tool “Extinction” vs “breakout” We see that in a super-critical (\\(m &gt; 1\\)) branching process, if a line can survive a few generations and reach a large enough size, it will grow exponentially. What happens if \\(m &lt; 1\\), if \\(m = 1\\)? Discuss. \\[ h(z) = p_0 + p_1 z + p_2 z^2 + \\ldots \\] The PGF “keeps book” on the probabilities. The chance of \\(k\\) is the coefficient on \\(z^k\\). \\(h(0)=\\) \\(h(1)=\\) \\(h&#39;(1)=\\) The story of two brothers A father has two sons. The probability generating function of their children combined is: \\[ [h(z)]^2 = (p_0 + p_1 z + p_2 z^2) \\times (p_0 + p_1 z + p_2 z^2) \\] Multiply out, and tell me the coefficients on \\(z^0, z^1, \\ldots\\). What is the probability generating function for the distribution of grandsons? A man has two sons, with probability \\(p_2\\), so PGF in that case is $ p_2 [h(z)]^2 $. But let’s sum over all possible numbers of sons. \\[ p_0 + p_1 h(z) + p_2 [h(z)]^2 + p_3 [h(z)]^3 + \\ldots \\] Which is? (Hint: write a new argument for PGF) \\[ h(h(z)) \\] Can show PGF for the n’th generation is \\[ h(h(h ... \\mbox{$n$ times} h(z))) = h_n(z) \\] exercise: write out \\(h_2(z) = h(h(z))\\) for \\[ h(z) = p_0 + p_1 z + p_2 z^2. \\] 8.5 Extinction Extinction “Extinction is forever.”: So, the probability \\(d_n\\) of extinction by generation \\(n\\) can never decline over time. (Must it always rise?) Recursive extinction Is non-extinction “forever”?: If \\(\\lim_{n \\rightarrow \\infty} = d(\\infty) &lt; 1\\), then this says there’s a chance \\(1 - d(\\infty)\\) of eternal persistence. We’ll try to figure out more about what this means. If the probability of a female line going extinct in \\(n\\) generations is \\(d_n\\), then this is equivalent to her daughter(s) line(s) going extinct in \\(n-1\\) generations. With \\(p_k\\) chance of having \\(k\\) daughters, we have \\[ d_n = p_0 + p_1 d_{n-1} + \\mbox{What is next term in series?} \\] What can we do with \\[ d_n = h(d_{n-1})? \\] Well, remember that \\(d_n\\) is non-decreasing, and that it’s maximum can be no greater than \\(1.0\\). When \\(d_n\\) reaches it’s limit, say \\(d\\), we won’t need generational subscripts, \\(d\\) will be constant, and will obey \\[ d = h(d) \\] Thus, an amazing result: the probability of ultimate extinction is when the argument equals the PGF of the argument. Can \\(d = 1\\), can \\(d &lt; 1\\) Try \\(d = 1\\). What happens? If we were to find a solution less than 1.0, how would we interpret that? Three cases par(mfrow = c(1,3), pty = &quot;s&quot;) z = seq(0, 1.6, .01) pk = c(.3, .0, .7); names(pk) &lt;- 0:2 d &lt;- pk[&quot;0&quot;] for (i in 1:10) { d &lt;- pk[&quot;0&quot;] + pk[&quot;1&quot;]*d + pk[&quot;2&quot;]*d^2 } ## super-critical hz = pk[&quot;0&quot;] + pk[&quot;1&quot;]*z + pk[&quot;2&quot;]*z^2 plot.fun &lt;- function(z, hz) { plot(z, hz, type = &quot;l&quot;, ylim = c(0,1.6), ylab = &quot;h(z)&quot;, yaxs = &quot;i&quot;, xaxs = &quot;i&quot;, axes = F) axis(1, at = seq(0, 1.5, .5)) axis(2, at = seq(0, 1.5, .5)) abline(0,1, col = &quot;grey&quot;) lines(z, hz) axis(2, at = pk[&quot;0&quot;], labels = &quot;p0&quot;, col.axis = &quot;red&quot;, col = &quot;red&quot;, lwd = 1, las = 2) } plot.fun(z,hz) points(c(d, 1),c(d, 1)) title(&quot;Super-critical (m &gt; 1) \\n 2 roots&quot;) ## sub-critical pk = c(.3, .55, .15); names(pk) &lt;- 0:2 hz = pk[&quot;0&quot;] + pk[&quot;1&quot;]*z + pk[&quot;2&quot;]*z^2 plot.fun(z,hz) title(&quot;Sub-critical (m &lt; 1) \\n 1 root&quot;) points(1,1) ## critical pk = c(.3, .4, .3); names(pk) &lt;- 0:2 hz = pk[&quot;0&quot;] + pk[&quot;1&quot;]*z + pk[&quot;2&quot;]*z^2 plot.fun(z, hz) title(&quot;Critical (m = 1), \\n 1 root&quot;) points(1,1) We can prove by answering: What is \\(h&#39;(1)\\)? What is \\(h(0)\\)? Is \\(h&#39;&#39;(z) &gt; 0\\)? pk = c(.3, .0, .7); names(pk) &lt;- 0:2 z = seq(0, 1.6, .01) hz = pk[&quot;0&quot;] + pk[&quot;1&quot;]*z + pk[&quot;2&quot;]*z^2 plot.fun(z,hz) Where is \\(h(p_0)\\), \\(h(h(p_0))\\), \\(h(h(h(p_0)))\\), \\(\\ldots\\)? So how do we actually get \\(d\\)? Take the case where \\(p_0 = .3\\), \\(p_1 = 0\\), and \\(p_3 = .7\\) (the one I just plotted). Can do some algebra Or we can recursively iterate on the computer. Numerical recursion pk = c(.3, .0, .7); names(pk) &lt;- 0:2 ## our example d &lt;- pk[&quot;0&quot;] # initial value for (i in 1:20) { d &lt;- pk[&quot;0&quot;] + pk[&quot;1&quot;]*d + pk[&quot;2&quot;]*d^2 if (i %in% c(1,2,19,20)) print(paste(i, d)) } ## [1] &quot;1 0.363&quot; ## [1] &quot;2 0.3922383&quot; ## [1] &quot;19 0.428565882081349&quot; ## [1] &quot;20 0.428568100698915&quot; Did we get the right value? pk = c(.3, .0, .7); names(pk) &lt;- 0:2 z = seq(0, 1.6, .01) hz = pk[&quot;0&quot;] + pk[&quot;1&quot;]*z + pk[&quot;2&quot;]*z^2 plot.fun(z,hz) abline(h = d, col = &quot;green&quot;) abline(v = d, col = &quot;green&quot;) Extinction and non-extinction revisited If \\(m &gt; 1\\), there exists \\(d\\) bigger than 0 and less than unity. This means there’s some positive chance of extinction. But also some chance of never-extinction. (What form does never-extinction take?) suppressWarnings(matplot(t(Z.mat), log = &quot;y&quot;, type = &quot;l&quot;, lty = 1, ylab = &quot;Zn&quot;, xlab = &quot;n&quot;)) Relevance to Corona virus? 8.6 Good and bad set-ups for branching process .column-left{ float: left; width: 50%; text-align: left; } .column-right{ float: right; width: 50%; text-align: left; } Good Unrestricted growth (frontier, new disease, start of a reaction) A “null” model for understanding how apparent structure is just random outcomes. Families that die out didn’t have to have low \\(NRR\\). Just because most new viruses don’t break out, doesn’t mean they aren’t potentially dangerous (\\(R_0 &gt;&gt; 1.0\\)). A model that corresponds our mental model of running a generative process forward. (cf. Fisher-Wright) Bad When offspring of 1 depends on offspring of other (e.g., brothers inheriting a farm) When resource constraints slow growth rates (e.g., Malthus: fertility of next gen depends on fertility of last; SIR model in disease spread) Analysis. PGF is powerful but still we often have to deal with listing all possibilities. Big populations – law of large numbers means randomness doesn’t matter. a 8.7 The distribution of offspring of all generations Means of offspring in generation \\(n\\) Is it “meaningful”? (If we have a lot of zeros) We’ll show that unconditional mean \\[ \\mathbb{E} Z_n = m^n \\] What if \\(m = 1\\)? size of surviving lines? Total probability is sum of conditional probabilities, times the chance of each condition: \\[ \\mathbb{E} Z_n = \\mathbb{E}( Z_n | Z_n &gt; 0) P(Z_n &gt; 0) + \\mathbb{E}( Z_n | Z_n = 0) P(Z_n = 0) \\] What is mean size of surviving lines? Hint 1: \\(P(Z_n = 0) = d_n\\) Hint 2: \\(\\mathbb{E} Z_n = m^n\\) Let’s check our result using simulation Our set-up branch &lt;- function(n_max = 30, p_k = c(p0, p1, p2), Z1 = 1) { ## note: this returns 0s when extinct k &lt;- 0:(length(p_k)-1) Z.vec &lt;- rep(NA, n_max) Z.vec[1] &lt;- Z1 for (i in 1:(n_max-1)) { Z.vec[i+1] &lt;- sum(sample(x = k, size = Z.vec[i], replace = T, prob = p_k)) } return(Z.vec) } p0 = .3; p1 = .4; p2 = .3 ## what is m? 1000 trials, code n_trials = 1000; n_gen = 100 Z.mat &lt;- matrix(NA, n_trials, n_gen) set.seed(131) for (i in 1:n_trials) Z.mat[i,] &lt;- branch(n_max = n_gen) matplot(t(Z.mat), type = &quot;l&quot;, lty = 1, ylab = &quot;Zn&quot;, xlab = &quot;n&quot;) 1000 trials, means, picture Zn_bar = apply(Z.mat, 2, mean) n &lt;- 1:ncol(Z.mat) proportion.zero &lt;- function(x){prop.table(table(x == 0))[&quot;TRUE&quot;]} d_n = apply(Z.mat, 2, proportion.zero) Z.mat.na &lt;- Z.mat; Z.mat.na[Z.mat == 0] &lt;- NA Zn_surv_bar = apply(Z.mat.na, 2, mean, na.rm = T) par(mfrow = c(1,3)) plot(n, Zn_bar, main = &quot;Mean Zn&quot;) plot(n, d_n, main = &quot;Fraction extinct&quot;) plot(n, Zn_surv_bar) ## insert code here for Zn_surv_bar.hat and add a line Proving \\(\\mathbb{E} Z_n = m^n\\) Ingredients \\(h&#39;(1) = m = \\bar{Z}\\) \\(h_n&#39;(1) = \\bar{Z}_n\\) \\(h_{n+1}(z) = h(h_n(z))\\) Derivation Variance result. (Too much algebra to do here). For \\(m = 1\\), \\[ \\sigma_n^2 = n \\sigma^2 \\] Also a result for \\(m\\neq 1\\) What does increasing variance mean for critical case? (Does this make sense?) What happens to variance of lines that survive? Is it bigger or smaller than unconditional variance? Variance in our simulation var_Zn = apply(Z.mat, 2, var) n &lt;- 1:ncol(Z.mat) plot(n, var_Zn) Distribution of \\(Z_n\\) Z20 &lt;- table(table(Z.mat[,20])) Z5 &lt;- table(table(Z.mat[,5])) par(mfrow = c(2,2)) plot(Z20[Z20 &lt; 100]) plot(log(Z20[Z20 &lt; 100])) plot(Z5[Z5 &lt; 100]) plot(log(Z5[Z5 &lt; 100])) 8.8 Geometric offspring distribution For \\(k = 1, 2, \\ldots\\), \\[ p_k = b c^{k-1} \\] For \\(k = 0\\), \\[ p_0 = 1 - p_1 - p_2 - \\ldots . \\] Let’s solve for \\(p_0\\), using the geometric series sum, for \\(a &lt; 1\\), \\[ 1 + a + a^2 + \\ldots = 1 / (1-a) \\] A picture, Lotka’s parameters for 1920 b = 0.2126 ; c = 0.5893 kk = 1:10 ; p_kk = b * c^(kk-1) p0 = b/(1-c) k = c(0, kk) ; p_k = c(p0, p_kk) plot(k, p_k) Realism? See Table 10.3, p 386, Grinstead and Snell. 8.8.1 The Geometric Distribution’s simple PGF \\[ h(z) = p_0 + p_1 z + p_2 z^2 + \\ldots \\] With geometric \\(p_k\\) \\[ h(z) = p_0 + \\sum_{k= 1}^\\infty b c^{k-1} z^k. \\] Substituting for \\(p_0\\) and rewriting \\[ h(z) = \\left( 1 - {b / (1-c)}\\right) + bz \\sum_{k= 1}^\\infty (cz)^{k-1}. \\] Substituting \\(j = k-1\\), \\[ h(z) = \\left( 1 - {b / (1-c)}\\right) + bz \\sum_{j= 0}^\\infty (cz)^{j} = \\left( 1 - {b / (1-c)}\\right) + {bz \\over (1 - cz)} \\] The PGF is now ``tractable’’ \\(m\\) and extinction \\[ h(z) = \\left( 1 - {b / 1-c}\\right) + {bz \\over 1 - cz} \\] Please solve for \\(m\\). (Hint: \\(h&#39;(1)\\)). What is \\(m\\) with Lotka’s \\(b\\) and \\(c\\)? We solve \\(z = h(z)\\) with a bunch of algebra to get \\[ d = {1 - b - c \\over c(1-c)} \\] How does \\(d\\) depend on \\(b\\) and \\(c\\)? Big payoff: the full distribution of \\(Z_n\\)} See Grinstead and Snell p. 385 ### A plot of Keyfitz’s numbers for generations 1, 2, and 3. Is it exponential for \\(k &gt; 0\\)? ## b = 0.2126 ; c = 0.5893 ## lotka b = 0.3666; c = .5533 ## Keyfitz (from GS) m = b / (1-c)^2 ## [1] 1.260416 d = (1 - b - c) / (c * (1-c)) #[1] 0.8185088 par(mfrow = c(1,1)) for (i in 1:3) { n = i p0_n = d * (m^n - 1)/ (m^n -d) j = kk pj_n = m^n * ((1-d) / (m^n - d))^2 * ((m^n - 1)/(m^n - d))^(j-1) pk_n &lt;- c(p0_n, pj_n) if (i == 1) plot(k, pk_n, type = &quot;l&quot;, log = &quot;&quot;) if (i &gt; 1) lines(k, pk_n, col = i) } log scale ## b = 0.2126 ; c = 0.5893 ## lotka b = 0.3666; c = .5533 ## Keyfitz (from G&amp;S) m = b / (1-c)^2 ## [1] 1.260416 d = (1 - b - c) / (c * (1-c)) #[1] 0.8185088 par(mfrow = c(1,1)) for (i in 1:3) { n = i print(n) p0_n = d * (m^n - 1)/ (m^n -d) j = kk pj_n = m^n * ((1-d) / (m^n - d))^2 * ((m^n - 1)/(m^n - d))^(j-1) pk_n &lt;- c(p0_n, pj_n) if (i == 1) plot(k, pk_n, type = &quot;l&quot;, log = &quot;y&quot;) if (i &gt; 1) lines(k, pk_n, col = i) } ## [1] 1 ## [1] 2 ## [1] 3 Applications We have exponential distribution with a few very large lines, and a lot of small lines. Distribution of neutral alleles Distribution of family lines (Y-chromosome, mtDNA, last names) Our result With geometric \\(p_k\\), we get geometric \\(Z_n\\), for all \\(n\\). Conjecture: geometric is to BP as gamma is to frailty? 8.9 Branching Processes and Covid-19 What is the BP that they are studying? Is it contagion, social contacts, or ? What do they assume about the BP? Do they use any analytical results or just simulation? Why? Best feature of paper? Worst feature of paper? Inspire any other approaches? "],
["fisher-wright.html", "Chapter 9 Fisher-Wright 9.1 Outline 9.2 Parallel 9.3 Mutation 9.4 Fixation 9.5 Baby Names 9.6 Now we can simulate babyynmes 9.7 Conclusions", " Chapter 9 Fisher-Wright 9.1 Outline Fisher Wright vs Galton Branching Process FW with mutation Extinction Application: Baby Names 9.2 Parallel .column-left{ float: left; width: 50%; text-align: left; } .column-right{ float: right; width: 50%; text-align: left; } Fisher-Wright Children picking their parents (not “generative”) Total population size is constant Qualitatively similar to BP. Extinction and fixation. Flexible: mutation, selection, even changes in pop size. With apologies, biologists take FW “seriously” even if they don’t take it “literally”. Galton-Watson-Bienaym'e Branching Processe Branching process models independent parents randomly producing offspring. “Generative” Total population size can vary, and has a random component and deterministic one \\(m\\) Qualitative result when \\(m = 1\\) is that there is one longest surviving line. This is “fixation”, when one type becomes universal. 9.2.1 Another cell phone example Let’s simulate and draw lines Gen 1 0 1 2 3 4 5 6 7 8 9 Gen 2 Gen 3 What will happen? 9.3 Mutation Simulation fwm &lt;- function(N, n_gen, mu = 0) ## mu != 4/N { ## simulate fisher-wright (with mutations) x &lt;- paste(1:N) ## starting types A &lt;- matrix(NA, nrow = n_gen, ncol = N) for (i in 1:n_gen) { A[i,] &lt;- x x &lt;- sample(x, size = N, replace = T) x &lt;- mut(x, mu) x } return(A) ## matrix of types, each line a generation. } mut &lt;- function(x, mu) { ## m, the individuals that mutate m &lt;- which(rbinom(length(x), 1, mu) == 1) if (length(m) == 0) ## if no-one mutates return(x) ## add a suffix to their ID, so it will be unique (infinite alleles) suffix &lt;- 10000*round(runif(length(m)),4) x[m] &lt;- paste0(x[m], &quot;.&quot;, suffix) x } Trying it out set.seed(1) fwm(N = 10, n_gen = 2, mu = 0) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; &quot;8&quot; &quot;9&quot; &quot;10&quot; ## [2,] &quot;9&quot; &quot;4&quot; &quot;7&quot; &quot;1&quot; &quot;2&quot; &quot;7&quot; &quot;2&quot; &quot;3&quot; &quot;1&quot; &quot;5&quot; fwm(N = 10, n_gen = 2, mu = 0) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; &quot;8&quot; &quot;9&quot; &quot;10&quot; ## [2,] &quot;5&quot; &quot;5&quot; &quot;2&quot; &quot;10&quot; &quot;9&quot; &quot;1&quot; &quot;4&quot; &quot;3&quot; &quot;6&quot; &quot;10&quot; Trying it out some more set.seed(1) A &lt;- fwm(N = 10, n_gen = 20, mu = 0) tt &lt;- table(A, row(A)) ## count types by row ptt &lt;- prop.table(tt, 2) ## proportions matplot(t(ptt), type = &#39;l&#39;, lty = 1, main = &quot;FW simu&quot;) text(x = 4, y = jitter(ptt[,4]), rownames(ptt), col = 1:6) Questions: What happens at time 15? Why does line 5 rise and fall? What happens at time 2? What is \\(E(p_i(t) | p_i(t-1))\\)? Bigger pop and more time set.seed(1) A &lt;- fwm(N = 100, n_gen = 200, mu = 0) tt &lt;- table(A, row(A)) ## count types by row ptt &lt;- prop.table(tt, 2) ## proportions matplot(t(ptt), type = &#39;l&#39;, lty = 1) What does this remind you of? What will happen in long run? What other questions could we ask? 9.4 Fixation Questions we can ask What is probability that line \\(i\\) will ``fix’’? (Hint: easy) What is expected time until some line fixes? (We’ll demo the result) How can we describe the path to fixation? (We’ll derive the result) Probability that a particular line will “fix” set.seed(1) A &lt;- fwm(N = 10, n_gen = 20, mu = 0) tt &lt;- table(A, row(A)) ## count types by row ptt &lt;- prop.table(tt, 2) ## proportions matplot(t(ptt), type = &#39;l&#39;, lty = 1, main = &quot;FW simu&quot;) text(x = 4, y = jitter(ptt[,4]), rownames(ptt), col = 1:6) Expected time until fixation? Answer for us is \\[ \\bar{T}_{fixed} = 2 \\cdot N \\] Note: Biologists say \\(4 N_e\\). See Wikipedia “Genetic drift” Simulation of time to fixation T.vec &lt;- NULL all.the.same &lt;- function(x){length(unique(x)) == 1} set.seed(10) for (i in 1:100) { A &lt;- fwm(N = 100, n_gen = 1000,mu = 0) extinction_time = min(row(A)[apply(A, 1, all.the.same)]) T.vec[i] &lt;- extinction_time } mean(T.vec) ## [1] 202.89 9.4.1 Path to fixation: a measure of homogeneity/heterogeneity Chance that two randomly drawn individuals are of same type. \\[ G = \\sum_i p_i^2 \\] If we have two types, \\(p_1 = \\pi\\) , \\(p_2 = 1-\\pi\\)? What is G if \\(\\pi = 0, .5, 1\\)? Let’s derive time path of G Let’s assume just two types, \\(\\pi(t)\\) Chance two indiv are of same type \\[ G_{t+1} = P(\\mbox{same parent})\\cdot 1 + P(\\mbox{different parent})\\cdot G_{t} \\] Notation: I’m going use \\(K\\) for pop size. Bio uses \\(2N\\). \\[ G_{t+1} = {1 \\over K} \\cdot 1 + (1 - {1\\over K}) \\cdot G_{t} \\] Easier to solve letting \\(H = 1 - G\\). Some algebra gives \\[ H_{t+1} = H_{t} (1 - 1/K) \\] Or, \\[ H_{t} = H_0 (1 - 1/K)^t % \\rightarrow H_0 e^{-t/K} \\] So, H goes to 0 exponentially, just as G goes to 1. 9.5 Baby Names “Drift as a mechanism for cultural change: an example from baby names” by Matthew W. Hahn and R. Alexander Bentley Proc. R. Soc. Lond. B 2003 270, S120-S123 9.5.1 What’s the basic idea? How is naming a baby like Fisher-Wright? How is it not? Applying Like Fisher-Wright people choose from existing set (?) names are “neutral” (?) draw proportionally (?) They test to see if they can reject FW compare observed histograms to FW simulation They include mutation to get a stationary disn Note: failing to reject FW doesn’t mean it’s correct Their picture Baby Names by Matthew W. Hahn and R. Alexander Bentley Proc. R.Soc. Lond. B 2003 270, S120-S123 9.5.2 Fisher-Wright simulation of Baby Names (Hahn and Bentley) Drwaing their Picture Data prep download.file(url= &quot;https://www.ssa.gov/oact/babynames/names.zip&quot;, &quot;./names.zip&quot;) unzip(&quot;names.zip&quot;, exdir = &quot;./names&quot;) library(data.table) filenames &lt;- system(&quot;ls ./names/*.txt&quot;, intern = T) mylist &lt;- vector(&quot;list&quot;, length(filenames)) names(mylist) &lt;- gsub(pattern = &quot;[^0-9]&quot;, replace = &quot;&quot;, filenames) for (i in 1:length(filenames)) { myfile &lt;- filenames[i] mylist[[i]] &lt;- fread(myfile) } dt &lt;- rbindlist(mylist, idcol = &quot;year&quot;) names(dt) &lt;- c(&quot;year&quot;, &quot;name&quot;, &quot;sex&quot;, &quot;N&quot;) ok, we have the data now Plot observed frequencies ## male 1900-1909 my.dt &lt;- dt[sex == &quot;M&quot; &amp; year %in% 1900:1909] foo &lt;- my.dt[, .(N = sum(N)), by = name] foo &lt;- foo[order(N, decreasing = T)] bar &lt;- foo[1:1000,] ## 1000 top names now let’s do a power law plot my.breaks &lt;- c(0, 2^(0:11)/10000) bar[, p := round(prop.table(N),5)] bar[, pcat := cut(p, breaks = my.breaks, right = F, include.lowest = T)] out &lt;- unclass(prop.table(table(bar$pcat))) my.x &lt;- my.breaks[-length(my.breaks)] + diff(my.breaks)/2 plot(my.x, out, log = &quot;xy&quot;) ## Warning in xy.coords(x, y, xlabel, ylabel, log): 1 y value &lt;= 0 omitted from logarithmic plot 9.5.3 Drawing their picture with simulation FW simulation mut &lt;- function(x, mu) { ## m, the individuals that mutate m &lt;- which(rbinom(length(x), 1, mu) == 1) if (length(m) == 0) return(x) suffix &lt;- 10000*round(runif(length(m)),4) x[m] &lt;- paste0(x[m], &quot;.&quot;, suffix) x } fwm &lt;- function(N, n_gen, mu = 0) { x &lt;- paste(1:N) A &lt;- matrix(NA, nrow = n_gen, ncol = N) for (i in 1:n_gen) { A[i,] &lt;- x x &lt;- sample(x, size = N, replace = T) x &lt;- mut(x, mu) x } return(A) } Let’s look at evolution over time of G: chance that two individuals are of same type get.G &lt;- function(x) { tt &lt;- table(x) p &lt;- prop.table(tt) sum(p^2) } without mutation A &lt;- fwm(1000, n_gen = 4000, mu = 0) G.vec &lt;- apply(A, 1, get.G) plot(G.vec) with mutation, 1 trial N = 1000 A &lt;- fwm(N, n_gen = 3000, mu = 4/N) G.vec &lt;- apply(A, 1, get.G) plot(G.vec) average over 100 trials n_gen = 2000 n_trials = 100 G.mat &lt;- matrix(NA, n_trials, n_gen) for (i in 1:n_trials) { N = 1000 A &lt;- fwm(N, n_gen, mu = 4/N) G.vec &lt;- apply(A, 1, get.G) G.mat[i,] &lt;- G.vec } matplot(t(G.mat), type = &quot;l&quot;) G.bar &lt;- apply(G.mat, 2, mean) lines(G.bar, lwd = 4) abline(h = 1/9, lty = 3, col = &quot;yellow&quot;, lwd = 5) cool plot, why is it about .11? 1/(1 + 8) ## [1] 0.1111111 Gillespie tells us that Gbar is supposed to be 1 / (1 + 4Nemu) How does 4Nemu = 8? Well, we have \\(K*mu = 4\\) and since \\(K = 2*Ne\\), \\(Ne = = K/2\\) (maybe) 9.5.4 FW babyname simulation of equilibrium frequencies N = 1000 ## Not sure if this is (w)right :) mu = 4/N ## [1] 0.004 theta = N*mu ## [1] 4 ## H&amp;B&#39;s &quot;best fit&quot; 9.6 Now we can simulate babyynmes n_gen = 1001 N = 1000 ## set.seed(1) ## A &lt;- fwm2(N, n_gen, mu = 4/N) #A &lt;- fwm2(N, n_gen, mu = 8/N) ############### #What about the fwm2 function? ####################### A &lt;- fwm(N, n_gen, mu = 8/N) ## ok, lets do power law plot of this x &lt;- A[1001,] tt &lt;- table(x) ptt &lt;- prop.table(tt) my.breaks &lt;- c(0, 2^(0:11)/10000) p &lt;- ptt ## bar[, p := round(prop.table(N),5)] ##bar[, pcat := cut(p, breaks = my.breaks, right = F, include.lowest = T)] pcat = cut(p, breaks = my.breaks, right = F, include.lowest = T) out &lt;- unclass(prop.table(table(bar$pcat))) out.hat &lt;- unclass(prop.table(table(pcat))) my.x &lt;- my.breaks[-length(my.breaks)] + diff(my.breaks)/2 plot(my.x, out, log = &quot;xy&quot;) ## Warning in xy.coords(x, y, xlabel, ylabel, log): 1 y value &lt;= 0 omitted from logarithmic plot lines(my.x, out.hat) 9.7 Conclusions Fisher-Wright an alternative to branching processes It reverses logic of reproduction, but gives similar quantitative and qualitative results A neutral model for other processes? Starting point for coalescent 9.7.1 Some potential criticism While we can’t reject that there’s some parameterization of FW that gives us similar disn, this doesn’t mean that we’ve found the right mechanism. (Just that we can’t reject it). What are some other tests of this mechanism? Markov assumption. We could see if each frequency really followed random walk. Perhaps we could see if variances were scaled to frequencies correctly. "],
["coalescent.html", "Chapter 10 Coalescent 10.1 Outline 10.2 Big picture: The Coalescent: Expectations of the Past 10.3 Our first question: When was MRCA? 10.4 Mutation and inference of TMRCA and \\(N\\) 10.5 Inference of population size, simulation 10.6 Conclusions 10.7 An application of coalescent theory 10.8 Inference from MRCA times: \\(n &gt; 2\\) comparisons and relative branch lengths 10.9 Reconstruction Ancient European Population Sizes using Batini’s sample of Mitochondrial DNA&quot; 10.10 Some exercises", " Chapter 10 Coalescent 10.1 Outline Big picture: What is “coalescent theory”? Time to (T)MRCA Simulation: Inferring population size An application of Coalescent Theory 10.2 Big picture: The Coalescent: Expectations of the Past Coalescent theory is not a theory. It’s a model for the probability of different histories “the” coalescent is a bit confusing. We’re not inferring the actual history of common ancestry, just the probabilities An actual “picture” Top panel is a Fisher-Wright instance, ordered so that lines don’t cross. Haplotype is a sequence (we are diploids, each contributing 2 haplotypes). But let’s just think of each line as an individual, for now. We can find The Most Recent Common Ancestor (TMRCA) of sample (dark purple). Who and when would the MRCA of the top two individuals be? Our sample \\(\\neq\\) even all extant descendants of the MRCA. What does this mean? Our sample \\(\\neq\\) all of the descendants of the MRCA. What does this mean? If we chose two descendants at random, would we always get same MRCA? When we model coalescence we are thinking backwards in time. 10.3 Our first question: When was MRCA? If we sample two individuals (today), how long ago was their MRCA?\\ (Note: question is not “who”) Our answer will in terms of the probability of MRCA being 1 generation ago, 2 generations ago, etc. We’ll assume Fisher-Wright (constant N, each gen randomly picks parents) The answer is surprisingly simple Let’s assume we have \\(N\\) lines in Fisher-Wright (Note: I’m not using \\(2N\\).) The chance that two sampled people have same parent is \\(1/N\\), right? Thus \\(P(T_{MRCA} = 1) = 1/N\\). What is $P(T_{MRCA} = 2) = $? What is $P(T_{MRCA} = n) = $? Let’s go to continuous time (reasonable if pop is big and time scale is long). Hazard of coalescence = \\(c = 1/N\\). Probability of coalescence at time \\(t\\) = \\(\\ell(t) h(t) = e^{-ct} c\\) What is expected time of coalescence? Think life expectancy. \\(E(T_{MRCA})\\) if two samples: \\(1/c = 1/(1/N) = N\\) Let’s simulate 1 time, without random seed, letting N = 40, ngen = 200, mu = 0 Average over 100 FW simulations What is variance of outcome? Is it what we would expect from exponential? 10.4 Mutation and inference of TMRCA and \\(N\\) Say mutations occur at a constant rate \\(\\mu\\) (\\(10^{-8}\\)?) Each year we would expect \\(\\mu\\) mutations, and over \\(T\\) years we would expect \\(T\\mu\\) mutations. Say we observe that two people differ at \\(k\\) sites of the genome. When was TMRCA? How big is the population? Picture (\\(\\Lambda\\)) Tree length = \\(2T\\) Expected number of mutations: \\[ E(k) = E(2T\\mu) = \\bar{T} 2 \\mu \\] Since, \\[ \\bar{T} = E(TMRCA) = N \\] If we observe on average \\(\\bar{k}\\) mutations, then \\[ E(k) = N 2 \\mu \\rightarrow \\hat{N} = {\\bar{k} \\over 2 \\mu} \\] 10.5 Inference of population size, simulation We do FW with mutations Average pairwise differences Divide by \\(2\\mu\\) to get our estimate We can repeat a bunch of times and see average estimate converges to the truth Coalescence of a sample of \\(n\\) individuals This is covered on pages 42 and 43 of Gillespie We’ll just do one quick example, accepting the result A sample of 3: Note we’re using \\(N\\) (instead of \\(2N\\)) Question: If we sample 4, how much of time to TMRCA is do we have 4 branches, 3 branches, and 2 branches? 10.6 Conclusions We defined the coalescent as the stochastic process going back in time to common ancestors For constant population size, we proved that time to coalescence for a sample pair is exponential. We showed (math and simulation) that \\(E(T) = N\\). We showed that we could estimate \\(N\\) from observed mutations if we knew the mutation rate \\end{frame} 10.7 An application of coalescent theory Application to making inferences about the real history of human populations. Caveat: We’re still using \\(N\\) (not \\(2N\\)) as the number of haploids 10.7.1 Coalesence when population is changing Ee said hazard of coalescence was \\(h = c = 1/N\\). What is hazard of coalesence in one generation for two different populations: \\(N = 1000\\)? \\(N = 2000\\)? What if within the same population \\(N(t) = 1000\\) and \\(N(t+1) = 2000\\)? (Hint: we still follow FW in allowing children to choose their parents.) If the population size changes over time \\(N(t)\\), then hazards of coalescence in will change too: \\(h(t) = 1/N(t)\\). N_recent = 5000 ## population last T_thresh years T_thresh = 1000 N_ancient = 500 ## earlier population n = 1000 ## sampled individuals set.seed(0.4886) T1 &lt;- rexp(n, rate = 1/N_recent) ## give everyone a chance to coalesce T1[T1 &gt; T_thresh] &lt;- NA ## if they don&#39;t in 1st 1000 years, resample them n2 &lt;- sum(is.na(T1)) T2 &lt;- T_thresh + rexp(n2, rate = 1/N_ancient) ## at ancient rate T.vec &lt;- c(T1, T2) hist(T.vec, breaks = seq(0, 5000, 250)) Q: How could we estimate population sizes from this histogram? T.vec &lt;- sort(T.vec) St = (n:1)/n par(mfrow = c(1,2)) plot(T.vec, St); abline(v = T_thresh); plot(T.vec, log(St)); abline(v = T_thresh) Q: How can we estimate hazards from this histogram? Our approach Say we have \\(i\\) pairs of haploids We then compute how many pairwise differences there are, but instead of computing \\(\\bar{k}\\), we keep the distributional information \\(k_i\\). Each \\(k_i\\) implies a \\(T_i\\) We then have a set of ``death times’’ (coalescence times), can build a life table, estimate the hazards, and infer \\(N(t)\\). 10.8 Inference from MRCA times: \\(n &gt; 2\\) comparisons and relative branch lengths Detour to length of branches A sample of 3: Note we’re using \\(N\\) (not \\(2N\\)) Intuition: when we have more individuals, there’s more chance that some pair of them will coalesce. Question: If we sample 4, how much of time to TMRCA do we have 4 branches, 3 branches, and 2 branches? 10.9 Reconstruction Ancient European Population Sizes using Batini’s sample of Mitochondrial DNA&quot; We use real sequences of mitochondrial DNA to estimate ancient population sizes. The sequences were made available by Batini et al, who analyzed sub-populations in their paper using software for Bayesian inference for comparing groups of individuals. Our approach here is to use a simpler, but less powerful approach. We will simply look at pairwise differences of random pairs of individuals. For this we are not going to do subgroups such as the Greeks or Irish, but are going to use the entire European sample. The population sizes we estimate are for the entire population represented by the 328 individuals. Special thanks to Ken Wachter, who taught me this approach and whose R-code forms the basis of this application 10.9.1 Summary of Batini et al. Before we begin our own analysis, let’s look at the inputs to Batini’s analysis – the mtDNA haplotype sequences, and then at the resulting population estimates. 10.9.1.1 The mitochondrial DNA Data preparation begins. There are 380 individuals grouped into regional sub-populations. I select out the Greeks, whose labels begin with “gre”. x &lt;- scan(&quot;/hdir/0/fmenares/Book/bookdown-master/data/mtdna.csv&quot;, what = character()) nchar(x) ## [1] 4 3 4 2 5 11 1 15 16577 16577 16577 16577 16577 16577 16577 ## [16] 16577 16577 16577 16577 16577 16577 16577 16577 16577 16577 16577 16574 16575 16575 16575 ## [31] 16575 16575 16575 16575 16575 16575 16575 16574 16575 16574 16574 16574 16574 16574 16574 ## [46] 16574 16575 16575 16575 16575 16575 16575 16575 16575 16575 16575 16575 16575 16575 16575 ## [61] 16575 16575 16575 16575 16575 16574 16576 16576 16576 16576 16576 16576 16576 16576 16576 ## [76] 16576 16576 16576 16576 16576 16575 16575 16575 16578 16578 16575 16575 16575 16576 16577 ## [91] 16577 16577 16577 16577 16577 16577 16577 16577 16577 16577 16577 16577 16577 16577 16577 ## [106] 16577 16577 16577 16577 16575 16574 16575 16575 16575 16575 16575 16574 16574 16574 16574 ## [121] 16575 16575 16575 16575 16575 16576 16576 16576 16575 16575 16576 16576 16574 16574 16575 ## [136] 16575 16575 16575 16575 16574 16575 16575 16575 16575 16575 16575 16575 16575 16575 16575 ## [151] 16574 16574 16575 16575 16575 16575 16575 16575 16574 16575 16575 16575 16575 16575 16575 ## [166] 16575 16575 16575 16574 16574 16574 16574 16580 16580 16580 16580 16580 16580 16580 16580 ## [181] 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 ## [196] 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 ## [211] 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 ## [226] 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 ## [241] 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16580 16575 16576 16576 ## [256] 16576 16576 16577 16577 16577 16576 16576 16576 16576 16576 16576 16576 16576 16576 16576 ## [271] 16576 16576 16576 16576 16576 16576 16576 16576 16576 16576 16576 16577 16577 16577 16577 ## [286] 16577 16577 16577 16577 16577 16577 16577 16577 16577 16577 16576 16577 16577 16576 16575 ## [301] 16577 16575 16575 16577 16574 16575 16575 16575 16575 16574 16575 16575 16575 16575 16575 ## [316] 16575 16575 16574 16575 16574 16574 16574 16574 16574 16575 16575 16574 16575 16575 16575 ## [331] 16576 16575 16575 16575 16575 16575 16575 16575 16575 16576 16575 16576 16575 16575 16574 ## [346] 16575 16575 16575 16575 16575 16575 16575 16575 16575 16575 16574 16575 16574 16574 16574 ## [361] 16574 16574 16574 16574 16574 16575 16575 16575 16575 16575 16575 16575 16575 16575 16575 ## [376] 16574 16575 16574 16574 16574 16574 16574 16574 16574 16576 16576 16576 16576 ## note the strings have different length ## because there is some header information ## and then because the labels are mixed with the sequences ## separate out the sequences xx = x[nchar(x) &gt; 10000] ## elements that contain both label and sequences xx.list = strsplit(xx, split = &quot;,&quot;) ## list of elements, split into label and sequences ## now split up this list into a vector of labels and a vector of sequences get.first.element = function(x) {x[1]} get.second.element = function(x) {x[2]} labels = unlist(lapply(xx.list, get.first.element)) seqs = unlist(lapply(xx.list, get.second.element)) ## Now use labels to select out the 20 Greeks s &lt;- grepl(&quot;^gre&quot;, labels) my.labels = labels[s] my.seqs = seqs[s] nchar(my.seqs) ## note the sequences all have same number of bases. ## [1] 16568 16568 16568 16568 16568 16568 16568 16568 16568 16568 16568 16568 16568 16568 16568 ## [16] 16568 16568 16568 16568 16568 ## now put the bases in a matrix, with each column an indiviual and ## each row a base. my.list &lt;- strsplit(my.seqs, &quot;&quot;) A &lt;- do.call(cbind, my.list) dim(A) ## [1] 16568 20 ## coding region sequences, 576-16023 (according to &quot;Tree construction ## and haplogroup prediction&quot; section, but not clear if this was used for ## Intrapopulation diversity B &lt;- A[576:16023,] haps &lt;- seqs Let’s inspect just a bit of one of these sequences print(nchar(haps[213])) ## [1] 16568 a_segment = substr(haps[213], 1, 100) print(a_segment) ## [1] &quot;GATCACAGGTCTATCACCCTATTAACCACTCACGGGAGCTCTCCATGCATTTGGTATTTTCGTCTGGGGGGTGTGCACGCGATAGCATTGCGAGACGCTG&quot; ## tip: don&#39;t try to print the 16,000 character whole string. it will clog up your computer. Let’s put the haps in a matrix my.list &lt;- strsplit(haps, &quot;&quot;) H &lt;- do.call(cbind, my.list) print(H[1:10, 1:4]) ## all the same ## [,1] [,2] [,3] [,4] ## [1,] &quot;G&quot; &quot;G&quot; &quot;G&quot; &quot;G&quot; ## [2,] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ## [3,] &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; ## [4,] &quot;C&quot; &quot;C&quot; &quot;C&quot; &quot;C&quot; ## [5,] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ## [6,] &quot;C&quot; &quot;C&quot; &quot;C&quot; &quot;C&quot; ## [7,] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ## [8,] &quot;G&quot; &quot;G&quot; &quot;G&quot; &quot;G&quot; ## [9,] &quot;G&quot; &quot;G&quot; &quot;G&quot; &quot;G&quot; ## [10,] &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; Let’s find a site where there’s polymorphism hap1 = H[,1] hap2 = H[,2] s &lt;- min(which(hap1 != hap2)) head(H[s + -2:2, 1:4]) ## the polymorphic site in context ## [,1] [,2] [,3] [,4] ## [1,] &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; ## [2,] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ## [3,] &quot;A&quot; &quot;G&quot; &quot;G&quot; &quot;G&quot; ## [4,] &quot;G&quot; &quot;G&quot; &quot;G&quot; &quot;G&quot; ## [5,] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; Let’s see if that’s hap1 is the only “A” table(H[s,]) ## ## A G ## 19 361 We see that there are 19 individuals with this “A” instead of “G”. Q: How many pairwise differences in total are there between hap1 and hap2? These are the kind of comparisons we will be doing. 10.9.2 Ancient population estimates Let’s look at Figure 2 on page 5. Q. What was effective population size in Ireland 1 thousand years ago (according to mtDNA)? Q. What was effective population size in Ireland 50 thousand years ago (according to mtDNA)? Q. For the “Irish”, what is the annual population growth rate? What’s the NRR? The order of magnitude for each these populations appears to be about 10^4 in last few KYA and 10^3 50 KYA. Together, perhaps the size is 10 fold. So we’re looking at European effective population sizes on the order of 100,000 the last few thousand years and on the order of 10,000 tens of thousands of years ago. 10.9.2.1 Using the Coalescent to estimate changing population size Our procedure will involve a four steps: Pick 100 pairs of people at random and count their pairwise differences. set.seed(1) hap_ids = 1:ncol(H) hap_id_sample = sample(hap_ids, size = 200, replace = FALSE) hap_id.mat &lt;- matrix(hap_id_sample, 100, 2) pairwise_diff_fun &lt;- function(hap1, hap2) { h1 &lt;- hap1 h2 &lt;- hap2 ## h1 &lt;- unlist(strsplit(hap1, &quot;&quot;)) ## h2 &lt;- unlist(strsplit(hap2, &quot;&quot;)) h1[h1 == &quot;N&quot;] &lt;- NA ## note &quot;N&quot; means missing h2[h2 == &quot;N&quot;] &lt;- NA ## making these NA avoids counting as polymorphism k = sum(h1 != h2, na.rm = T) n_valid = sum(!is.na(h1) &amp; !is.na(h2)) return(list(k = k, n_valid = n_valid)) } pairwise_diff_fun(H[,1], H[,2]) ## $k ## [1] 45 ## ## $n_valid ## [1] 16565 Now we’re ready to do pairwise comparisons of all 100 pairs of haplotypes. We’ll define the fraction of locii that have mutated (the pairwise differences) as \\[ \\bar{Y} = P/C \\] P.vec = NULL C.vec = NULL for (i in 1:nrow(hap_id.mat)) { hap_id.1 = hap_id.mat[i,1] hap_id.2 = hap_id.mat[i,2] hap1 = H[,hap_id.1] hap2 = H[,hap_id.2] out = pairwise_diff_fun(hap1, hap2) P.vec[i] = out$k C.vec[i] = out$n_valid } Y.bar = P.vec/C.vec head(P.vec) ## [1] 19 36 13 39 5 84 head(C.vec) ## [1] 16566 16484 16539 16565 16565 16544 head(Y.bar) ## [1] 0.0011469274 0.0021839359 0.0007860209 0.0023543616 0.0003018412 0.0050773694 Estimate 100 different times of MRCA (\\(T\\)) using assumed mutation rate. And now we’ll use the mutation rate \\(\\theta_m\\) given by Batini to compute time back to MRCA. First, some background: Let \\(a\\) index sites and write \\(Y_a = 1\\) if the letters are different, and $Y_a = 0 otherwise. For 1 site, the probability that it there has been a mutation, is 1 minus the chance that there has been no mutation. \\[ P( Y_a = 1 ) = 1 - e^{-T\\theta} \\] The mean \\(\\bar{Y}\\) across the segment is the proportion of \\(Y_a\\) that equal 1. So, in expectation for the fraction of sites that mutate is the same as the probability that 1 site mutates (assuming independence of mutation probabilities by site). This allows us to write \\[ E{\\bar{Y}} = 1 - e^{-2T\\theta}, \\] where we’ve added a “2” in order to account that either one of the pairwise branched could have had a mutation, so we our “exposure” is twice the time to MRCA. Rearranging we get an estimate $ of \\(T\\) to be \\[ \\hat{T} = {-\\log (1 - \\bar{Y} ) \\over \\theta} \\] Now we’re ready to estimate the MRCAs theta_m = 2.21 * 10^(-8) ## Batini page 6 (TMRCA estimation) T.vec &lt;- -(1/2) * (1/theta_m) * log(1 - Y.bar) ## TMRCAs in years ago head(T.vec, n = 10) ## [1] 25963.477 49464.349 17790.271 53328.902 6830.018 115165.228 56610.650 12294.775 ## [9] 21863.319 54701.270 Let’s visualize these hist(T.vec) We see a lot of coalescence about 50 KYA, which is as far back as Batini’s estimates go. This means the population was small back then. Estimate \\(h(t)\\), the time-varying hazard of coalescence We’ll do this in two ways. First we’ll compute the slope of the logarithm of the survival curve, but we’ll see that it is noisy and needs to be smoothed. Second, we’ll construct a “life table” of coalescence with discrete periods of time. Let’s start with the more continuous version of estimating slopes. ## Plot survival curve by order of T St = (100:1)/100 ## or more generally (length(T.vec):1)/length(T.vec) t = kya = sort(T.vec)/1000 plot(kya, St, type = &quot;l&quot;, xlab = &quot;Kilo years ago&quot;, ylab = &quot;Fraction of pairs without common ancestor&quot;, main = &quot;Estimated probability of not coalescing&quot;) plot(kya, log(St), type = &quot;l&quot;, xlab = &quot;Kilo years ago&quot;, ylab = &quot;Log fraction of pairs without common ancestor&quot;, main = &quot;Etimatated probability of not coalescing, log scale&quot;) Q: What is happening to slope in first from 1,000 to 50,000 years ago? Q: What does this imply about hazard of coalescence? Q: What does this imply about effective population size? Estimating hazards from smoothed survival curve First we smooth. out = lowess(x = kya, y = St, f = 1/5) St_smooth = out$y kya_smooth = out$x plot(kya, St, cex = .5) lines(kya_smooth, St_smooth, type = &#39;l&#39;) Q. Is f=1/5 a decent fit? Try a different value. Hazards as minus the slope of log haz_hat = -diff(St_smooth)/diff(kya_smooth) plot(kya_smooth[-1], haz_hat, type = &#39;l&#39;) Q. Does this plot tell us anything about uncertainty? Life table appraoch Now let’s estimate the hazards using a “life table”, where again “death” is coalescence and “survival” is still not having a common ancestor. ## we choose these time boundaries arbitrarily ... not sure if ## we&#39;ll be able to see the &quot;expansion&quot; after ice age ... ## x = c(0, 12, 20, 40, 65, 180 )*1000 # time interval boundaries x = c(0,2, 5, 10, 20, 30, 40, 65, 180) * 1000 ## time interval boundaries Define a function to count “exposure” by those pairs that have MRCA in time intervals get_nax &lt;- function(Ti, x) { ## get person years lived in interval by those who die nax &lt;- NULL for (i in 1:(length(x)-1)) { s &lt;- Ti &gt;= x[i] &amp; Ti &lt; x[i+1] if (length(Ti[s]) != 0) { nax[i] = mean(Ti[s] - x[i]) } nax[is.na(nax)] &lt;- 0 } return(nax) } Construct the life table n &lt;- diff(x) T.vec.by.cat &lt;- cut(T.vec, x, include.lowest = T, right = F) ndx = table(T.vec.by.cat) lx = rev(cumsum(rev(ndx))) lxpn = c(lx[-1], 0) nax = get_nax(Ti = T.vec, x = x) nLx = n*lxpn + nax * ndx ## exposure nmx = ndx/nLx ## hazard lt &lt;- cbind(x = x[-length(x)], n, ndx, lx, nax, nLx, nmx) print(lt) ## x n ndx lx nax nLx nmx ## [0,2e+03) 0 2000 0 100 0.000 200000.0 0.000000e+00 ## [2e+03,5e+03) 2000 3000 0 100 0.000 300000.0 0.000000e+00 ## [5e+03,1e+04) 5000 5000 3 100 3651.934 495955.8 6.048926e-06 ## [1e+04,2e+04) 10000 10000 7 97 6416.957 944918.7 7.408045e-06 ## [2e+04,3e+04) 20000 10000 7 90 3662.324 855636.3 8.181046e-06 ## [3e+04,4e+04) 30000 10000 19 83 6798.251 769166.8 2.470206e-05 ## [4e+04,6.5e+04) 40000 25000 54 64 11619.224 877438.1 6.154280e-05 ## [6.5e+04,1.8e+05] 65000 115000 10 10 24611.455 246114.6 4.063149e-05 Let’s compare the two estimates x.mid = x[-length(x)] + n/2 plot(x.mid, nmx, type = &#39;o&#39;) axis(2) lines(kya_smooth[-1] * 1000, haz_hat/1000, type = &quot;l&quot;) We’re getting basically the same thing, with a little more hint of rising hazards (shrinking pop size) in first 20 kya. Nearly the same thing estimate 40 kya ago, and very little signal before that. Estimate the population size \\(N_e(t)\\) In order to estimate the population size, we have to think for a minute about units. Our hazards are per year, but our logic for why hazards are related to population size is per generation. Remember, the chance of coalescence per generation was \\(1/N\\). This means we will want to multiply the annual hazard by generation length in order to get hazards per generation unit of time. Second, mtDNA is inherited only through mothers. So the coalescent that we are thinking of is only for women. And the effective population size we’re estimating is for females only. We can get a rough estimate of both sexes by doubling the number of females. Putting these two considerations together, we have \\[ \\hat{N_e(both sexes)} = 2 \\times {1 \\over 25 \\cdot h(t)}, \\] where the 2 inflates to both sexes, and the 25 inflates the annual hazard into geneations of 25 years in length. Ne_smooth = 2 / (haz_hat/1000 * 25) Ne_lifetable = 2 / (nmx * 25) ## create step function for plotting Ne_lifetable_step = rep(Ne_lifetable, n/1000) kya_step = 1:(max(x)/1000) Plotting the results plot(kya_smooth[-1], Ne_smooth, type = &#39;l&#39;, ylim = c(1000, 60000), log = &#39;y&#39;, lty = 2) lines(kya_step, Ne_lifetable_step, type = &#39;l&#39;, lwd = 2) Uncertainty Q. How could we evaluate undercertainty? (Hint: resampling) Q. What does this estimate leave out? (We probably won’t do this in class. If we don’t give it a try at home.) Let’s loop through and do the whole estimation 40 times n_trials = 40 Ne.mat &lt;- matrix(NA, nrow = n_trials, ncol = max(x)/1000) set.seed(1) for (r in 1:n_trials) { #r = 1 print(r) ## sample hap_id_sample = sample(hap_ids, size = 200, replace = FALSE) hap_id.mat &lt;- matrix(hap_id_sample, 100, 2) ## estimate MRCA distribution P.vec = NULL C.vec = NULL for (i in 1:nrow(hap_id.mat)) { hap_id.1 = hap_id.mat[i,1] hap_id.2 = hap_id.mat[i,2] hap1 = H[,hap_id.1] hap2 = H[,hap_id.2] out = pairwise_diff_fun(hap1, hap2) P.vec[i] = out$k C.vec[i] = out$n_valid } Y.bar = P.vec/C.vec T.vec &lt;- -(1/2) * (1/theta_m) * log(1 - Y.bar) ## TMRCAs in years ago ## estimate Ne T.vec.by.cat &lt;- cut(T.vec, x, include.lowest = T, right = F) ndx = table(T.vec.by.cat) lx = rev(cumsum(rev(ndx))) lxpn = c(lx[-1], 0) nax = get_nax(Ti = T.vec, x = x) nLx = n*lxpn + nax * ndx ## exposure nmx = ndx/nLx ## hazard Ne_lifetable = 2 / (nmx * 25) ## create step function for plotting Ne_lifetable_step = rep(Ne_lifetable, n/1000) kya_step = 1:(max(x)/1000) ## save result Ne.mat[r,] &lt;- Ne_lifetable_step } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 ## [1] 7 ## [1] 8 ## [1] 9 ## [1] 10 ## [1] 11 ## [1] 12 ## [1] 13 ## [1] 14 ## [1] 15 ## [1] 16 ## [1] 17 ## [1] 18 ## [1] 19 ## [1] 20 ## [1] 21 ## [1] 22 ## [1] 23 ## [1] 24 ## [1] 25 ## [1] 26 ## [1] 27 ## [1] 28 ## [1] 29 ## [1] 30 ## [1] 31 ## [1] 32 ## [1] 33 ## [1] 34 ## [1] 35 ## [1] 36 ## [1] 37 ## [1] 38 ## [1] 39 ## [1] 40 Ne.interval &lt;- apply(Ne.mat, 2, quantile, c(.1,.5, .9)) matplot(t(Ne.interval), type = &#39;l&#39;, log = &#39;y&#39;, col = &quot;grey&quot;, lty = 1, lwd = 2) lines(Ne.interval[&quot;50%&quot;,], lwd = 4) So it seems fairly clear that effective population size has been growing the last 50 thousand years, from a low of a few thousand to a few tens of thousand. The general trend in growth is consistent with Batini but Our total population size seems smaller by a factor of about 4 or 5. We don’t have the resolution to see increase between 10 and 20 kya, the end of the Last Glacial Maximum or the more recent Bronze Age steppe expansion 2 to 5 kya. In order to get more resolution and study sub-group differences, we would want to turn to methods that do more than pair-wise comparisons, giving us more detailed information about the effective population sizes of the past. 10.10 Some exercises Try doing 150 pairwise comparisons (instead of 100) and see what happens. Try doing 50 pairwise comparisons (instead of 100) and see what happens. Try changing the interval sizes (or the smoothing parameter) to see if you can see either the post-glaciation population increase or the Bronze Age increase? (I don’t know if it’s possible with our methods.) Figure out how to use BEAST or some other software and reproduce their results for one sub-population and tell us what you learned. "]
]
